{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: torchaudio in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: gradio in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (5.39.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.1.2)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.10.3)\n",
            "Requirement already satisfied: filelock in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.11.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (1.11.0)\n",
            "Requirement already satisfied: groovy~=0.1 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.34.3)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: orjson~=3.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (3.11.1)\n",
            "Requirement already satisfied: packaging in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.3.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.12.7)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.47.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio-client==1.11.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: requests in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: click>=8.0.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (14.1.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\rayan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install torch torchvision torchaudio gradio numpy matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device utilis√©: cuda\n",
            "GPU: NVIDIA GeForce RTX 4080\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import re\n",
        "import random\n",
        "import pickle\n",
        "import os\n",
        "from collections import Counter\n",
        "import gradio as gr\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device utilis√©: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Livre 1 charg√©: 444296 caract√®res\n",
            "Livre 2 charg√©: 496523 caract√®res\n",
            "Livre 3 charg√©: 618633 caract√®res\n",
            "Livre 4 charg√©: 1117233 caract√®res\n",
            "Livre 5 charg√©: 1515465 caract√®res\n",
            "Livre 6 charg√©: 994867 caract√®res\n",
            "Livre 7 charg√©: 1137446 caract√®res\n",
            "\n",
            "Texte total charg√©: 6324470 caract√®res\n",
            "Aper√ßu: THE BOY WHO LIVED  Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you'd expect to be involved in ...\n"
          ]
        }
      ],
      "source": [
        "def load_hp_books():\n",
        "    \"\"\"Charge tous les livres Harry Potter et les combine en un seul texte\"\"\"\n",
        "    books_dir = \"Books/\"\n",
        "    all_text = \"\"\n",
        "    \n",
        "    for i in range(1, 8):\n",
        "        file_path = f\"{books_dir}HPBook{i}.txt\"\n",
        "        if os.path.exists(file_path):\n",
        "            try:\n",
        "                with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                    content = f.read()\n",
        "                    lines = content.split('\\n')\n",
        "                    clean_lines = []\n",
        "                    for line in lines:\n",
        "                        if line.strip() and not line.startswith('\"Text\"@\"Chapter\"@\"Book\"'):\n",
        "                            if line.startswith('\"') and line.endswith('\"'):\n",
        "                                clean_line = line[1:-1]\n",
        "                            elif line.startswith('\"'):\n",
        "                                clean_line = line[1:]\n",
        "                            else:\n",
        "                                clean_line = line\n",
        "                            \n",
        "                            clean_lines.append(clean_line.strip())\n",
        "                    \n",
        "                    clean_content = ' '.join(clean_lines)\n",
        "                    all_text += clean_content + \" \"\n",
        "                    print(f\"Livre {i} charg√©: {len(clean_content)} caract√®res\")\n",
        "            except Exception as e:\n",
        "                print(f\"Erreur lors du chargement du livre {i}: {e}\")\n",
        "    \n",
        "    return all_text\n",
        "\n",
        "raw_text = load_hp_books()\n",
        "print(f\"\\nTexte total charg√©: {len(raw_text)} caract√®res\")\n",
        "print(f\"Aper√ßu: {raw_text[:200]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Texte apr√®s pr√©processing: 6251614 caract√®res\n",
            "Aper√ßu: the boy who lived mr. and mrs. dursley, of number four, privet drive, were proud to say that they were perfectly normal, thank you very much. they were the last people you'd expect to be involved in a...\n"
          ]
        }
      ],
      "source": [
        "def preprocess_text(text):\n",
        "    \"\"\"Nettoie et pr√©processe le texte\"\"\"\n",
        "    \n",
        "    text = re.sub(r'[^a-zA-Z\\s\\.,!?;:\\'\\\"\\-]', ' ', text)\n",
        "    \n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    \n",
        "    text = text.lower()\n",
        "    \n",
        "    return text.strip()\n",
        "\n",
        "processed_text = preprocess_text(raw_text)\n",
        "print(f\"Texte apr√®s pr√©processing: {len(processed_text)} caract√®res\")\n",
        "print(f\"Aper√ßu: {processed_text[:200]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulaire cr√©√©: 20098 mots\n",
            "Mots les plus fr√©quents: ['!', '\"', '\"\\'', '\"\\'and', '\"\\'arry,', '\"\\'choo', '\"\\'course', '\"\\'course,', '\"\\'harry', '\"\\'ow']\n",
            "\n",
            "Texte encod√©: 1127457 tokens\n",
            "Exemple d'encodage: [17651, 3176, 19504, 10712, 11750, 1802, 11752, 6069, 12366, 12272, 7561, 13697, 5960, 19385, 13802, 18008, 15027, 17636, 17722, 19385]\n",
            "D√©codage: the boy who lived mr. and mrs. dursley, of number four, privet drive, were proud to say that they were\n"
          ]
        }
      ],
      "source": [
        "class TextTokenizer:\n",
        "    def __init__(self, min_freq=5):\n",
        "        self.min_freq = min_freq\n",
        "        self.word_to_idx = {}\n",
        "        self.idx_to_word = {}\n",
        "        self.vocab_size = 0\n",
        "        \n",
        "    def fit(self, text):\n",
        "        \"\"\"Cr√©e le vocabulaire √† partir du texte\"\"\"\n",
        "        \n",
        "        words = text.split()\n",
        "        \n",
        "        word_counts = Counter(words)\n",
        "        \n",
        "        filtered_words = [word for word, count in word_counts.items() if count >= self.min_freq]\n",
        "        \n",
        "        special_tokens = ['<PAD>', '<UNK>', '<START>', '<END>']\n",
        "        vocab = special_tokens + sorted(filtered_words)\n",
        "        \n",
        "        self.word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
        "        self.idx_to_word = {idx: word for idx, word in enumerate(vocab)}\n",
        "        self.vocab_size = len(vocab)\n",
        "        \n",
        "        print(f\"Vocabulaire cr√©√©: {self.vocab_size} mots\")\n",
        "        print(f\"Mots les plus fr√©quents: {list(vocab[4:14])}\")\n",
        "        \n",
        "    def encode(self, text):\n",
        "        \"\"\"Convertit le texte en indices\"\"\"\n",
        "        words = text.split()\n",
        "        return [self.word_to_idx.get(word, self.word_to_idx['<UNK>']) for word in words]\n",
        "    \n",
        "    def decode(self, indices):\n",
        "        \"\"\"Convertit les indices en texte\"\"\"\n",
        "        return ' '.join([self.idx_to_word.get(idx, '<UNK>') for idx in indices])\n",
        "\n",
        "tokenizer = TextTokenizer(min_freq=3)\n",
        "tokenizer.fit(processed_text)\n",
        "\n",
        "encoded_text = tokenizer.encode(processed_text)\n",
        "print(f\"\\nTexte encod√©: {len(encoded_text)} tokens\")\n",
        "print(f\"Exemple d'encodage: {encoded_text[:20]}\")\n",
        "print(f\"D√©codage: {tokenizer.decode(encoded_text[:20])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset cr√©√©: 1127427 √©chantillons\n",
            "Train: 1014684, Validation: 112743\n",
            "Batches par √©poque: 15855\n"
          ]
        }
      ],
      "source": [
        "class HPTextDataset(Dataset):\n",
        "    def __init__(self, encoded_text, sequence_length=50):\n",
        "        self.encoded_text = encoded_text\n",
        "        self.sequence_length = sequence_length\n",
        "        \n",
        "        self.sequences = []\n",
        "        self.targets = []\n",
        "        \n",
        "        for i in range(len(encoded_text) - sequence_length):\n",
        "            seq = encoded_text[i:i + sequence_length]\n",
        "            target = encoded_text[i + sequence_length]\n",
        "            self.sequences.append(seq)\n",
        "            self.targets.append(target)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.sequences[idx]), torch.tensor(self.targets[idx])\n",
        "\n",
        "SEQUENCE_LENGTH = 30\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "dataset = HPTextDataset(encoded_text, SEQUENCE_LENGTH)\n",
        "print(f\"Dataset cr√©√©: {len(dataset)} √©chantillons\")\n",
        "\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(f\"Train: {len(train_dataset)}, Validation: {len(val_dataset)}\")\n",
        "print(f\"Batches par √©poque: {len(train_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mod√®le cr√©√© avec 8659330 param√®tres\n",
            "HPTextGenerator(\n",
            "  (embedding): Embedding(20098, 128)\n",
            "  (lstm): LSTM(128, 256, num_layers=2, batch_first=True, dropout=0.3)\n",
            "  (fc): Linear(in_features=256, out_features=20098, bias=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class HPTextGenerator(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=256, num_layers=2, dropout=0.3):\n",
        "        super(HPTextGenerator, self).__init__()\n",
        "        \n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, \n",
        "                           dropout=dropout, batch_first=True)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x, hidden=None):\n",
        "        embedded = self.embedding(x)\n",
        "        \n",
        "        lstm_out, hidden = self.lstm(embedded, hidden)\n",
        "        \n",
        "        last_output = lstm_out[:, -1, :]\n",
        "        \n",
        "        output = self.dropout(last_output)\n",
        "        output = self.fc(output)\n",
        "        \n",
        "        return output, hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        \"\"\"Initialise les √©tats cach√©s\"\"\"\n",
        "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n",
        "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n",
        "        return (h0, c0)\n",
        "\n",
        "model = HPTextGenerator(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    embedding_dim=128,\n",
        "    hidden_dim=256,\n",
        "    num_layers=2,\n",
        "    dropout=0.3\n",
        ").to(device)\n",
        "\n",
        "print(f\"Mod√®le cr√©√© avec {sum(p.numel() for p in model.parameters())} param√®tres\")\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üßô‚Äç‚ôÇÔ∏è G√©n√©ration de texte NETTOY√âE :\n",
            "\n",
            "'harry' ‚Üí harry had been able to get rid of the dark mark to make a horcrux on the dark arts, and what had happened to the\n",
            "\n",
            "'hermione' ‚Üí hermione was and i know what you can do with the rest of the school and a bit of a bit of the first time\n",
            "\n",
            "'magic' ‚Üí magic - \" harry looked up at the top of the room, and he heard the door behind him. harry was still sure he knew\n",
            "\n",
            "'wand' ‚Üí wand and the same - \" harry looked down at the staff table and the door of the class had been a few feet from\n",
            "\n",
            "'hogwarts' ‚Üí hogwarts - \" \"i think i don't know what you can do with the death eaters. \" said hermione in a low voice. \"i don't\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def generate_text(model, tokenizer, start_word, max_length=50, temperature=1.0):\n",
        "    \"\"\"G√©n√®re du texte √† partir d'un mot de d√©part\"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    start_word = start_word.lower()\n",
        "    if start_word not in tokenizer.word_to_idx:\n",
        "        start_word = '<UNK>'\n",
        "    \n",
        "    sequence = [tokenizer.word_to_idx['<PAD>']] * (SEQUENCE_LENGTH - 1) + [tokenizer.word_to_idx[start_word]]\n",
        "    generated = [start_word]\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        hidden = None\n",
        "        \n",
        "        for _ in range(max_length - 1):\n",
        "            input_seq = torch.tensor(sequence).unsqueeze(0).to(device)\n",
        "            output, hidden = model(input_seq, hidden)\n",
        "            output = output / temperature\n",
        "            probabilities = torch.softmax(output, dim=1)\n",
        "            \n",
        "            unwanted_tokens = ['<UNK>', '<PAD>', '<START>', '<END>']\n",
        "            for token in unwanted_tokens:\n",
        "                if token in tokenizer.word_to_idx:\n",
        "                    token_idx = tokenizer.word_to_idx[token]\n",
        "                    probabilities[0, token_idx] = 0\n",
        "            \n",
        "            probabilities = probabilities / probabilities.sum()\n",
        "            \n",
        "            next_word_idx = torch.multinomial(probabilities, 1).item()\n",
        "            next_word = tokenizer.idx_to_word[next_word_idx]\n",
        "            \n",
        "            if next_word in unwanted_tokens:\n",
        "                break\n",
        "            \n",
        "            generated.append(next_word)\n",
        "            sequence = sequence[1:] + [next_word_idx]\n",
        "    \n",
        "    text = ' '.join(generated)\n",
        "    \n",
        "    import re\n",
        "    text = re.sub(r'(\\s*\\.\\s*){2,}', '...', text)\n",
        "    text = re.sub(r'\\.{4,}', '...', text)\n",
        "    \n",
        "    text = re.sub(r'\\s+([,.!?;:])', r'\\1', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = text.strip()\n",
        "    \n",
        "    return text\n",
        "\n",
        "test_words = ['harry', 'hermione', 'magic', 'wand', 'hogwarts']\n",
        "\n",
        "print(\"üßô‚Äç‚ôÇÔ∏è G√©n√©ration de texte NETTOY√âE :\\n\")\n",
        "for word in test_words:\n",
        "    generated = generate_text(model, tokenizer, word, max_length=25, temperature=0.3)\n",
        "    print(f\"'{word}' ‚Üí {generated}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "D√©but de l'entra√Ænement...\n",
            "Epoch 1/8, Batch 0/15855, Loss: 9.9101\n",
            "Epoch 1/8, Batch 50/15855, Loss: 7.6850\n",
            "Epoch 1/8, Batch 100/15855, Loss: 7.7201\n",
            "Epoch 1/8, Batch 150/15855, Loss: 7.6621\n",
            "Epoch 1/8, Batch 200/15855, Loss: 7.5436\n",
            "Epoch 1/8, Batch 250/15855, Loss: 7.2519\n",
            "Epoch 1/8, Batch 300/15855, Loss: 7.0514\n",
            "Epoch 1/8, Batch 350/15855, Loss: 6.6550\n",
            "Epoch 1/8, Batch 400/15855, Loss: 7.0459\n",
            "Epoch 1/8, Batch 450/15855, Loss: 7.5464\n",
            "Epoch 1/8, Batch 500/15855, Loss: 6.6986\n",
            "Epoch 1/8, Batch 550/15855, Loss: 7.7288\n",
            "Epoch 1/8, Batch 600/15855, Loss: 7.1406\n",
            "Epoch 1/8, Batch 650/15855, Loss: 7.1730\n",
            "Epoch 1/8, Batch 700/15855, Loss: 7.0868\n",
            "Epoch 1/8, Batch 750/15855, Loss: 7.9222\n",
            "Epoch 1/8, Batch 800/15855, Loss: 6.8161\n",
            "Epoch 1/8, Batch 850/15855, Loss: 7.3814\n",
            "Epoch 1/8, Batch 900/15855, Loss: 7.5049\n",
            "Epoch 1/8, Batch 950/15855, Loss: 6.3541\n",
            "Epoch 1/8, Batch 1000/15855, Loss: 7.3597\n",
            "Epoch 1/8, Batch 1050/15855, Loss: 6.2614\n",
            "Epoch 1/8, Batch 1100/15855, Loss: 6.9595\n",
            "Epoch 1/8, Batch 1150/15855, Loss: 6.5721\n",
            "Epoch 1/8, Batch 1200/15855, Loss: 6.7201\n",
            "Epoch 1/8, Batch 1250/15855, Loss: 6.8301\n",
            "Epoch 1/8, Batch 1300/15855, Loss: 6.6480\n",
            "Epoch 1/8, Batch 1350/15855, Loss: 5.9844\n",
            "Epoch 1/8, Batch 1400/15855, Loss: 7.2447\n",
            "Epoch 1/8, Batch 1450/15855, Loss: 6.7978\n",
            "Epoch 1/8, Batch 1500/15855, Loss: 5.9306\n",
            "Epoch 1/8, Batch 1550/15855, Loss: 6.6560\n",
            "Epoch 1/8, Batch 1600/15855, Loss: 6.8368\n",
            "Epoch 1/8, Batch 1650/15855, Loss: 6.2695\n",
            "Epoch 1/8, Batch 1700/15855, Loss: 6.4376\n",
            "Epoch 1/8, Batch 1750/15855, Loss: 6.5264\n",
            "Epoch 1/8, Batch 1800/15855, Loss: 6.1817\n",
            "Epoch 1/8, Batch 1850/15855, Loss: 6.4218\n",
            "Epoch 1/8, Batch 1900/15855, Loss: 6.0298\n",
            "Epoch 1/8, Batch 1950/15855, Loss: 6.6380\n",
            "Epoch 1/8, Batch 2000/15855, Loss: 7.2549\n",
            "Epoch 1/8, Batch 2050/15855, Loss: 6.0220\n",
            "Epoch 1/8, Batch 2100/15855, Loss: 7.0233\n",
            "Epoch 1/8, Batch 2150/15855, Loss: 7.0216\n",
            "Epoch 1/8, Batch 2200/15855, Loss: 6.9866\n",
            "Epoch 1/8, Batch 2250/15855, Loss: 6.8825\n",
            "Epoch 1/8, Batch 2300/15855, Loss: 6.5273\n",
            "Epoch 1/8, Batch 2350/15855, Loss: 6.5628\n",
            "Epoch 1/8, Batch 2400/15855, Loss: 6.3983\n",
            "Epoch 1/8, Batch 2450/15855, Loss: 6.1542\n",
            "Epoch 1/8, Batch 2500/15855, Loss: 6.2642\n",
            "Epoch 1/8, Batch 2550/15855, Loss: 6.7809\n",
            "Epoch 1/8, Batch 2600/15855, Loss: 6.1190\n",
            "Epoch 1/8, Batch 2650/15855, Loss: 6.2104\n",
            "Epoch 1/8, Batch 2700/15855, Loss: 6.8389\n",
            "Epoch 1/8, Batch 2750/15855, Loss: 6.7620\n",
            "Epoch 1/8, Batch 2800/15855, Loss: 6.9142\n",
            "Epoch 1/8, Batch 2850/15855, Loss: 5.7125\n",
            "Epoch 1/8, Batch 2900/15855, Loss: 6.4083\n",
            "Epoch 1/8, Batch 2950/15855, Loss: 6.8146\n",
            "Epoch 1/8, Batch 3000/15855, Loss: 6.8891\n",
            "Epoch 1/8, Batch 3050/15855, Loss: 6.3214\n",
            "Epoch 1/8, Batch 3100/15855, Loss: 6.8768\n",
            "Epoch 1/8, Batch 3150/15855, Loss: 5.6082\n",
            "Epoch 1/8, Batch 3200/15855, Loss: 6.3323\n",
            "Epoch 1/8, Batch 3250/15855, Loss: 6.7509\n",
            "Epoch 1/8, Batch 3300/15855, Loss: 6.6521\n",
            "Epoch 1/8, Batch 3350/15855, Loss: 6.0596\n",
            "Epoch 1/8, Batch 3400/15855, Loss: 6.9431\n",
            "Epoch 1/8, Batch 3450/15855, Loss: 5.2244\n",
            "Epoch 1/8, Batch 3500/15855, Loss: 7.1412\n",
            "Epoch 1/8, Batch 3550/15855, Loss: 6.5275\n",
            "Epoch 1/8, Batch 3600/15855, Loss: 6.6932\n",
            "Epoch 1/8, Batch 3650/15855, Loss: 6.8232\n",
            "Epoch 1/8, Batch 3700/15855, Loss: 6.6047\n",
            "Epoch 1/8, Batch 3750/15855, Loss: 6.1760\n",
            "Epoch 1/8, Batch 3800/15855, Loss: 6.7396\n",
            "Epoch 1/8, Batch 3850/15855, Loss: 5.9822\n",
            "Epoch 1/8, Batch 3900/15855, Loss: 5.9740\n",
            "Epoch 1/8, Batch 3950/15855, Loss: 6.2746\n",
            "Epoch 1/8, Batch 4000/15855, Loss: 7.1331\n",
            "Epoch 1/8, Batch 4050/15855, Loss: 6.8740\n",
            "Epoch 1/8, Batch 4100/15855, Loss: 6.2427\n",
            "Epoch 1/8, Batch 4150/15855, Loss: 6.2137\n",
            "Epoch 1/8, Batch 4200/15855, Loss: 6.8001\n",
            "Epoch 1/8, Batch 4250/15855, Loss: 5.9207\n",
            "Epoch 1/8, Batch 4300/15855, Loss: 5.6864\n",
            "Epoch 1/8, Batch 4350/15855, Loss: 5.7033\n",
            "Epoch 1/8, Batch 4400/15855, Loss: 6.0042\n",
            "Epoch 1/8, Batch 4450/15855, Loss: 6.9132\n",
            "Epoch 1/8, Batch 4500/15855, Loss: 5.9408\n",
            "Epoch 1/8, Batch 4550/15855, Loss: 6.5077\n",
            "Epoch 1/8, Batch 4600/15855, Loss: 6.0986\n",
            "Epoch 1/8, Batch 4650/15855, Loss: 5.6133\n",
            "Epoch 1/8, Batch 4700/15855, Loss: 6.4271\n",
            "Epoch 1/8, Batch 4750/15855, Loss: 7.5486\n",
            "Epoch 1/8, Batch 4800/15855, Loss: 5.9666\n",
            "Epoch 1/8, Batch 4850/15855, Loss: 5.9622\n",
            "Epoch 1/8, Batch 4900/15855, Loss: 5.8966\n",
            "Epoch 1/8, Batch 4950/15855, Loss: 6.6626\n",
            "Epoch 1/8, Batch 5000/15855, Loss: 5.8786\n",
            "Epoch 1/8, Batch 5050/15855, Loss: 6.7093\n",
            "Epoch 1/8, Batch 5100/15855, Loss: 6.1557\n",
            "Epoch 1/8, Batch 5150/15855, Loss: 6.1596\n",
            "Epoch 1/8, Batch 5200/15855, Loss: 6.1979\n",
            "Epoch 1/8, Batch 5250/15855, Loss: 6.6594\n",
            "Epoch 1/8, Batch 5300/15855, Loss: 6.2779\n",
            "Epoch 1/8, Batch 5350/15855, Loss: 6.7281\n",
            "Epoch 1/8, Batch 5400/15855, Loss: 5.9514\n",
            "Epoch 1/8, Batch 5450/15855, Loss: 6.8355\n",
            "Epoch 1/8, Batch 5500/15855, Loss: 5.7781\n",
            "Epoch 1/8, Batch 5550/15855, Loss: 5.7209\n",
            "Epoch 1/8, Batch 5600/15855, Loss: 5.9939\n",
            "Epoch 1/8, Batch 5650/15855, Loss: 6.3204\n",
            "Epoch 1/8, Batch 5700/15855, Loss: 6.1638\n",
            "Epoch 1/8, Batch 5750/15855, Loss: 6.7245\n",
            "Epoch 1/8, Batch 5800/15855, Loss: 6.0352\n",
            "Epoch 1/8, Batch 5850/15855, Loss: 5.8389\n",
            "Epoch 1/8, Batch 5900/15855, Loss: 6.5109\n",
            "Epoch 1/8, Batch 5950/15855, Loss: 5.5962\n",
            "Epoch 1/8, Batch 6000/15855, Loss: 6.4574\n",
            "Epoch 1/8, Batch 6050/15855, Loss: 5.8890\n",
            "Epoch 1/8, Batch 6100/15855, Loss: 5.9647\n",
            "Epoch 1/8, Batch 6150/15855, Loss: 6.1873\n",
            "Epoch 1/8, Batch 6200/15855, Loss: 6.3974\n",
            "Epoch 1/8, Batch 6250/15855, Loss: 6.2670\n",
            "Epoch 1/8, Batch 6300/15855, Loss: 6.2422\n",
            "Epoch 1/8, Batch 6350/15855, Loss: 6.1737\n",
            "Epoch 1/8, Batch 6400/15855, Loss: 6.7688\n",
            "Epoch 1/8, Batch 6450/15855, Loss: 6.8946\n",
            "Epoch 1/8, Batch 6500/15855, Loss: 6.2873\n",
            "Epoch 1/8, Batch 6550/15855, Loss: 6.4732\n",
            "Epoch 1/8, Batch 6600/15855, Loss: 7.2553\n",
            "Epoch 1/8, Batch 6650/15855, Loss: 6.2340\n",
            "Epoch 1/8, Batch 6700/15855, Loss: 6.1269\n",
            "Epoch 1/8, Batch 6750/15855, Loss: 6.4122\n",
            "Epoch 1/8, Batch 6800/15855, Loss: 5.6170\n",
            "Epoch 1/8, Batch 6850/15855, Loss: 5.3739\n",
            "Epoch 1/8, Batch 6900/15855, Loss: 5.6801\n",
            "Epoch 1/8, Batch 6950/15855, Loss: 5.8113\n",
            "Epoch 1/8, Batch 7000/15855, Loss: 6.0314\n",
            "Epoch 1/8, Batch 7050/15855, Loss: 6.3329\n",
            "Epoch 1/8, Batch 7100/15855, Loss: 5.8467\n",
            "Epoch 1/8, Batch 7150/15855, Loss: 6.5490\n",
            "Epoch 1/8, Batch 7200/15855, Loss: 5.9513\n",
            "Epoch 1/8, Batch 7250/15855, Loss: 6.1116\n",
            "Epoch 1/8, Batch 7300/15855, Loss: 6.5456\n",
            "Epoch 1/8, Batch 7350/15855, Loss: 6.4188\n",
            "Epoch 1/8, Batch 7400/15855, Loss: 6.1607\n",
            "Epoch 1/8, Batch 7450/15855, Loss: 5.8977\n",
            "Epoch 1/8, Batch 7500/15855, Loss: 6.5005\n",
            "Epoch 1/8, Batch 7550/15855, Loss: 5.4660\n",
            "Epoch 1/8, Batch 7600/15855, Loss: 5.8127\n",
            "Epoch 1/8, Batch 7650/15855, Loss: 6.1033\n",
            "Epoch 1/8, Batch 7700/15855, Loss: 5.9772\n",
            "Epoch 1/8, Batch 7750/15855, Loss: 5.6545\n",
            "Epoch 1/8, Batch 7800/15855, Loss: 6.1594\n",
            "Epoch 1/8, Batch 7850/15855, Loss: 6.2152\n",
            "Epoch 1/8, Batch 7900/15855, Loss: 6.1578\n",
            "Epoch 1/8, Batch 7950/15855, Loss: 6.6178\n",
            "Epoch 1/8, Batch 8000/15855, Loss: 6.1219\n",
            "Epoch 1/8, Batch 8050/15855, Loss: 6.9170\n",
            "Epoch 1/8, Batch 8100/15855, Loss: 6.6620\n",
            "Epoch 1/8, Batch 8150/15855, Loss: 6.8812\n",
            "Epoch 1/8, Batch 8200/15855, Loss: 6.0402\n",
            "Epoch 1/8, Batch 8250/15855, Loss: 5.9827\n",
            "Epoch 1/8, Batch 8300/15855, Loss: 5.8023\n",
            "Epoch 1/8, Batch 8350/15855, Loss: 5.9088\n",
            "Epoch 1/8, Batch 8400/15855, Loss: 6.2057\n",
            "Epoch 1/8, Batch 8450/15855, Loss: 6.6670\n",
            "Epoch 1/8, Batch 8500/15855, Loss: 6.1210\n",
            "Epoch 1/8, Batch 8550/15855, Loss: 5.7814\n",
            "Epoch 1/8, Batch 8600/15855, Loss: 6.4171\n",
            "Epoch 1/8, Batch 8650/15855, Loss: 6.7030\n",
            "Epoch 1/8, Batch 8700/15855, Loss: 5.2982\n",
            "Epoch 1/8, Batch 8750/15855, Loss: 6.1406\n",
            "Epoch 1/8, Batch 8800/15855, Loss: 6.8021\n",
            "Epoch 1/8, Batch 8850/15855, Loss: 7.0377\n",
            "Epoch 1/8, Batch 8900/15855, Loss: 5.6174\n",
            "Epoch 1/8, Batch 8950/15855, Loss: 6.0643\n",
            "Epoch 1/8, Batch 9000/15855, Loss: 6.7118\n",
            "Epoch 1/8, Batch 9050/15855, Loss: 6.2788\n",
            "Epoch 1/8, Batch 9100/15855, Loss: 6.0894\n",
            "Epoch 1/8, Batch 9150/15855, Loss: 5.9155\n",
            "Epoch 1/8, Batch 9200/15855, Loss: 5.0937\n",
            "Epoch 1/8, Batch 9250/15855, Loss: 5.7060\n",
            "Epoch 1/8, Batch 9300/15855, Loss: 6.5194\n",
            "Epoch 1/8, Batch 9350/15855, Loss: 5.6315\n",
            "Epoch 1/8, Batch 9400/15855, Loss: 6.1738\n",
            "Epoch 1/8, Batch 9450/15855, Loss: 5.6375\n",
            "Epoch 1/8, Batch 9500/15855, Loss: 5.7189\n",
            "Epoch 1/8, Batch 9550/15855, Loss: 5.7111\n",
            "Epoch 1/8, Batch 9600/15855, Loss: 6.4205\n",
            "Epoch 1/8, Batch 9650/15855, Loss: 6.0405\n",
            "Epoch 1/8, Batch 9700/15855, Loss: 5.6457\n",
            "Epoch 1/8, Batch 9750/15855, Loss: 6.1102\n",
            "Epoch 1/8, Batch 9800/15855, Loss: 5.9832\n",
            "Epoch 1/8, Batch 9850/15855, Loss: 5.9278\n",
            "Epoch 1/8, Batch 9900/15855, Loss: 6.6220\n",
            "Epoch 1/8, Batch 9950/15855, Loss: 5.6818\n",
            "Epoch 1/8, Batch 10000/15855, Loss: 6.0107\n",
            "Epoch 1/8, Batch 10050/15855, Loss: 5.2947\n",
            "Epoch 1/8, Batch 10100/15855, Loss: 6.1108\n",
            "Epoch 1/8, Batch 10150/15855, Loss: 5.3808\n",
            "Epoch 1/8, Batch 10200/15855, Loss: 5.8716\n",
            "Epoch 1/8, Batch 10250/15855, Loss: 6.6045\n",
            "Epoch 1/8, Batch 10300/15855, Loss: 5.7657\n",
            "Epoch 1/8, Batch 10350/15855, Loss: 5.3144\n",
            "Epoch 1/8, Batch 10400/15855, Loss: 7.2445\n",
            "Epoch 1/8, Batch 10450/15855, Loss: 6.0671\n",
            "Epoch 1/8, Batch 10500/15855, Loss: 6.6610\n",
            "Epoch 1/8, Batch 10550/15855, Loss: 6.0220\n",
            "Epoch 1/8, Batch 10600/15855, Loss: 6.1006\n",
            "Epoch 1/8, Batch 10650/15855, Loss: 5.7869\n",
            "Epoch 1/8, Batch 10700/15855, Loss: 5.8752\n",
            "Epoch 1/8, Batch 10750/15855, Loss: 6.0562\n",
            "Epoch 1/8, Batch 10800/15855, Loss: 6.1606\n",
            "Epoch 1/8, Batch 10850/15855, Loss: 6.0687\n",
            "Epoch 1/8, Batch 10900/15855, Loss: 6.6948\n",
            "Epoch 1/8, Batch 10950/15855, Loss: 5.8139\n",
            "Epoch 1/8, Batch 11000/15855, Loss: 6.0359\n",
            "Epoch 1/8, Batch 11050/15855, Loss: 6.0432\n",
            "Epoch 1/8, Batch 11100/15855, Loss: 5.4513\n",
            "Epoch 1/8, Batch 11150/15855, Loss: 5.4869\n",
            "Epoch 1/8, Batch 11200/15855, Loss: 5.5398\n",
            "Epoch 1/8, Batch 11250/15855, Loss: 4.9407\n",
            "Epoch 1/8, Batch 11300/15855, Loss: 5.6365\n",
            "Epoch 1/8, Batch 11350/15855, Loss: 6.0193\n",
            "Epoch 1/8, Batch 11400/15855, Loss: 5.4815\n",
            "Epoch 1/8, Batch 11450/15855, Loss: 6.7953\n",
            "Epoch 1/8, Batch 11500/15855, Loss: 5.4230\n",
            "Epoch 1/8, Batch 11550/15855, Loss: 6.2763\n",
            "Epoch 1/8, Batch 11600/15855, Loss: 5.7619\n",
            "Epoch 1/8, Batch 11650/15855, Loss: 6.0326\n",
            "Epoch 1/8, Batch 11700/15855, Loss: 5.8283\n",
            "Epoch 1/8, Batch 11750/15855, Loss: 6.2734\n",
            "Epoch 1/8, Batch 11800/15855, Loss: 5.8566\n",
            "Epoch 1/8, Batch 11850/15855, Loss: 5.6617\n",
            "Epoch 1/8, Batch 11900/15855, Loss: 6.0995\n",
            "Epoch 1/8, Batch 11950/15855, Loss: 5.5724\n",
            "Epoch 1/8, Batch 12000/15855, Loss: 6.2644\n",
            "Epoch 1/8, Batch 12050/15855, Loss: 5.9357\n",
            "Epoch 1/8, Batch 12100/15855, Loss: 6.1497\n",
            "Epoch 1/8, Batch 12150/15855, Loss: 5.7578\n",
            "Epoch 1/8, Batch 12200/15855, Loss: 6.4251\n",
            "Epoch 1/8, Batch 12250/15855, Loss: 5.5493\n",
            "Epoch 1/8, Batch 12300/15855, Loss: 6.1743\n",
            "Epoch 1/8, Batch 12350/15855, Loss: 5.6107\n",
            "Epoch 1/8, Batch 12400/15855, Loss: 5.2649\n",
            "Epoch 1/8, Batch 12450/15855, Loss: 6.1650\n",
            "Epoch 1/8, Batch 12500/15855, Loss: 6.3385\n",
            "Epoch 1/8, Batch 12550/15855, Loss: 5.9803\n",
            "Epoch 1/8, Batch 12600/15855, Loss: 6.1840\n",
            "Epoch 1/8, Batch 12650/15855, Loss: 6.3818\n",
            "Epoch 1/8, Batch 12700/15855, Loss: 5.5291\n",
            "Epoch 1/8, Batch 12750/15855, Loss: 5.8371\n",
            "Epoch 1/8, Batch 12800/15855, Loss: 5.1605\n",
            "Epoch 1/8, Batch 12850/15855, Loss: 5.9562\n",
            "Epoch 1/8, Batch 12900/15855, Loss: 6.0387\n",
            "Epoch 1/8, Batch 12950/15855, Loss: 5.4165\n",
            "Epoch 1/8, Batch 13000/15855, Loss: 6.1874\n",
            "Epoch 1/8, Batch 13050/15855, Loss: 5.5108\n",
            "Epoch 1/8, Batch 13100/15855, Loss: 5.6310\n",
            "Epoch 1/8, Batch 13150/15855, Loss: 5.6004\n",
            "Epoch 1/8, Batch 13200/15855, Loss: 5.7856\n",
            "Epoch 1/8, Batch 13250/15855, Loss: 6.4903\n",
            "Epoch 1/8, Batch 13300/15855, Loss: 6.2021\n",
            "Epoch 1/8, Batch 13350/15855, Loss: 6.0888\n",
            "Epoch 1/8, Batch 13400/15855, Loss: 5.5388\n",
            "Epoch 1/8, Batch 13450/15855, Loss: 6.1568\n",
            "Epoch 1/8, Batch 13500/15855, Loss: 5.6019\n",
            "Epoch 1/8, Batch 13550/15855, Loss: 5.8853\n",
            "Epoch 1/8, Batch 13600/15855, Loss: 5.4757\n",
            "Epoch 1/8, Batch 13650/15855, Loss: 6.2525\n",
            "Epoch 1/8, Batch 13700/15855, Loss: 5.7449\n",
            "Epoch 1/8, Batch 13750/15855, Loss: 5.3281\n",
            "Epoch 1/8, Batch 13800/15855, Loss: 5.9506\n",
            "Epoch 1/8, Batch 13850/15855, Loss: 4.5749\n",
            "Epoch 1/8, Batch 13900/15855, Loss: 5.7829\n",
            "Epoch 1/8, Batch 13950/15855, Loss: 5.9819\n",
            "Epoch 1/8, Batch 14000/15855, Loss: 6.1763\n",
            "Epoch 1/8, Batch 14050/15855, Loss: 6.1736\n",
            "Epoch 1/8, Batch 14100/15855, Loss: 5.6693\n",
            "Epoch 1/8, Batch 14150/15855, Loss: 6.0104\n",
            "Epoch 1/8, Batch 14200/15855, Loss: 5.7179\n",
            "Epoch 1/8, Batch 14250/15855, Loss: 5.5997\n",
            "Epoch 1/8, Batch 14300/15855, Loss: 5.9927\n",
            "Epoch 1/8, Batch 14350/15855, Loss: 6.0535\n",
            "Epoch 1/8, Batch 14400/15855, Loss: 5.6015\n",
            "Epoch 1/8, Batch 14450/15855, Loss: 5.9778\n",
            "Epoch 1/8, Batch 14500/15855, Loss: 5.6079\n",
            "Epoch 1/8, Batch 14550/15855, Loss: 5.5048\n",
            "Epoch 1/8, Batch 14600/15855, Loss: 5.5953\n",
            "Epoch 1/8, Batch 14650/15855, Loss: 5.6355\n",
            "Epoch 1/8, Batch 14700/15855, Loss: 5.2628\n",
            "Epoch 1/8, Batch 14750/15855, Loss: 6.0523\n",
            "Epoch 1/8, Batch 14800/15855, Loss: 5.6955\n",
            "Epoch 1/8, Batch 14850/15855, Loss: 5.6728\n",
            "Epoch 1/8, Batch 14900/15855, Loss: 5.9878\n",
            "Epoch 1/8, Batch 14950/15855, Loss: 5.8258\n",
            "Epoch 1/8, Batch 15000/15855, Loss: 5.7862\n",
            "Epoch 1/8, Batch 15050/15855, Loss: 5.6989\n",
            "Epoch 1/8, Batch 15100/15855, Loss: 5.8921\n",
            "Epoch 1/8, Batch 15150/15855, Loss: 5.8484\n",
            "Epoch 1/8, Batch 15200/15855, Loss: 5.9112\n",
            "Epoch 1/8, Batch 15250/15855, Loss: 6.2309\n",
            "Epoch 1/8, Batch 15300/15855, Loss: 5.9807\n",
            "Epoch 1/8, Batch 15350/15855, Loss: 6.1310\n",
            "Epoch 1/8, Batch 15400/15855, Loss: 5.6907\n",
            "Epoch 1/8, Batch 15450/15855, Loss: 5.6707\n",
            "Epoch 1/8, Batch 15500/15855, Loss: 5.2889\n",
            "Epoch 1/8, Batch 15550/15855, Loss: 5.4633\n",
            "Epoch 1/8, Batch 15600/15855, Loss: 6.0334\n",
            "Epoch 1/8, Batch 15650/15855, Loss: 5.8974\n",
            "Epoch 1/8, Batch 15700/15855, Loss: 6.2794\n",
            "Epoch 1/8, Batch 15750/15855, Loss: 6.7673\n",
            "Epoch 1/8, Batch 15800/15855, Loss: 6.4429\n",
            "Epoch 1/8, Batch 15850/15855, Loss: 6.0295\n",
            "Epoch 1/8 - Train Loss: 6.1804, Val Loss: 5.6249\n",
            "Epoch 2/8, Batch 0/15855, Loss: 5.7233\n",
            "Epoch 2/8, Batch 50/15855, Loss: 4.8539\n",
            "Epoch 2/8, Batch 100/15855, Loss: 5.5992\n",
            "Epoch 2/8, Batch 150/15855, Loss: 5.4035\n",
            "Epoch 2/8, Batch 200/15855, Loss: 5.5744\n",
            "Epoch 2/8, Batch 250/15855, Loss: 5.2416\n",
            "Epoch 2/8, Batch 300/15855, Loss: 5.4176\n",
            "Epoch 2/8, Batch 350/15855, Loss: 6.0441\n",
            "Epoch 2/8, Batch 400/15855, Loss: 5.5122\n",
            "Epoch 2/8, Batch 450/15855, Loss: 5.3793\n",
            "Epoch 2/8, Batch 500/15855, Loss: 5.1627\n",
            "Epoch 2/8, Batch 550/15855, Loss: 5.7363\n",
            "Epoch 2/8, Batch 600/15855, Loss: 5.7152\n",
            "Epoch 2/8, Batch 650/15855, Loss: 5.0491\n",
            "Epoch 2/8, Batch 700/15855, Loss: 5.3700\n",
            "Epoch 2/8, Batch 750/15855, Loss: 5.3279\n",
            "Epoch 2/8, Batch 800/15855, Loss: 5.5011\n",
            "Epoch 2/8, Batch 850/15855, Loss: 5.2403\n",
            "Epoch 2/8, Batch 900/15855, Loss: 5.2018\n",
            "Epoch 2/8, Batch 950/15855, Loss: 5.4570\n",
            "Epoch 2/8, Batch 1000/15855, Loss: 5.7218\n",
            "Epoch 2/8, Batch 1050/15855, Loss: 6.3988\n",
            "Epoch 2/8, Batch 1100/15855, Loss: 5.9906\n",
            "Epoch 2/8, Batch 1150/15855, Loss: 4.9616\n",
            "Epoch 2/8, Batch 1200/15855, Loss: 5.2647\n",
            "Epoch 2/8, Batch 1250/15855, Loss: 4.9777\n",
            "Epoch 2/8, Batch 1300/15855, Loss: 5.3379\n",
            "Epoch 2/8, Batch 1350/15855, Loss: 5.6587\n",
            "Epoch 2/8, Batch 1400/15855, Loss: 5.6470\n",
            "Epoch 2/8, Batch 1450/15855, Loss: 6.2557\n",
            "Epoch 2/8, Batch 1500/15855, Loss: 4.9956\n",
            "Epoch 2/8, Batch 1550/15855, Loss: 5.5975\n",
            "Epoch 2/8, Batch 1600/15855, Loss: 5.8875\n",
            "Epoch 2/8, Batch 1650/15855, Loss: 5.2346\n",
            "Epoch 2/8, Batch 1700/15855, Loss: 6.1003\n",
            "Epoch 2/8, Batch 1750/15855, Loss: 5.1578\n",
            "Epoch 2/8, Batch 1800/15855, Loss: 5.8067\n",
            "Epoch 2/8, Batch 1850/15855, Loss: 5.2663\n",
            "Epoch 2/8, Batch 1900/15855, Loss: 6.0011\n",
            "Epoch 2/8, Batch 1950/15855, Loss: 6.0160\n",
            "Epoch 2/8, Batch 2000/15855, Loss: 5.3407\n",
            "Epoch 2/8, Batch 2050/15855, Loss: 5.6347\n",
            "Epoch 2/8, Batch 2100/15855, Loss: 5.4751\n",
            "Epoch 2/8, Batch 2150/15855, Loss: 5.4198\n",
            "Epoch 2/8, Batch 2200/15855, Loss: 5.3099\n",
            "Epoch 2/8, Batch 2250/15855, Loss: 5.7244\n",
            "Epoch 2/8, Batch 2300/15855, Loss: 4.8548\n",
            "Epoch 2/8, Batch 2350/15855, Loss: 5.9627\n",
            "Epoch 2/8, Batch 2400/15855, Loss: 4.9203\n",
            "Epoch 2/8, Batch 2450/15855, Loss: 4.7400\n",
            "Epoch 2/8, Batch 2500/15855, Loss: 5.2586\n",
            "Epoch 2/8, Batch 2550/15855, Loss: 5.8689\n",
            "Epoch 2/8, Batch 2600/15855, Loss: 5.8585\n",
            "Epoch 2/8, Batch 2650/15855, Loss: 5.7454\n",
            "Epoch 2/8, Batch 2700/15855, Loss: 5.9985\n",
            "Epoch 2/8, Batch 2750/15855, Loss: 5.2260\n",
            "Epoch 2/8, Batch 2800/15855, Loss: 5.5419\n",
            "Epoch 2/8, Batch 2850/15855, Loss: 5.9568\n",
            "Epoch 2/8, Batch 2900/15855, Loss: 6.0491\n",
            "Epoch 2/8, Batch 2950/15855, Loss: 5.7602\n",
            "Epoch 2/8, Batch 3000/15855, Loss: 5.0298\n",
            "Epoch 2/8, Batch 3050/15855, Loss: 5.4522\n",
            "Epoch 2/8, Batch 3100/15855, Loss: 5.6648\n",
            "Epoch 2/8, Batch 3150/15855, Loss: 5.5707\n",
            "Epoch 2/8, Batch 3200/15855, Loss: 5.8772\n",
            "Epoch 2/8, Batch 3250/15855, Loss: 5.8418\n",
            "Epoch 2/8, Batch 3300/15855, Loss: 5.1808\n",
            "Epoch 2/8, Batch 3350/15855, Loss: 5.8580\n",
            "Epoch 2/8, Batch 3400/15855, Loss: 5.5113\n",
            "Epoch 2/8, Batch 3450/15855, Loss: 4.8494\n",
            "Epoch 2/8, Batch 3500/15855, Loss: 5.6945\n",
            "Epoch 2/8, Batch 3550/15855, Loss: 5.5849\n",
            "Epoch 2/8, Batch 3600/15855, Loss: 5.6934\n",
            "Epoch 2/8, Batch 3650/15855, Loss: 6.0250\n",
            "Epoch 2/8, Batch 3700/15855, Loss: 5.7888\n",
            "Epoch 2/8, Batch 3750/15855, Loss: 5.5164\n",
            "Epoch 2/8, Batch 3800/15855, Loss: 5.1674\n",
            "Epoch 2/8, Batch 3850/15855, Loss: 5.4610\n",
            "Epoch 2/8, Batch 3900/15855, Loss: 5.7840\n",
            "Epoch 2/8, Batch 3950/15855, Loss: 5.8337\n",
            "Epoch 2/8, Batch 4000/15855, Loss: 6.6591\n",
            "Epoch 2/8, Batch 4050/15855, Loss: 4.9089\n",
            "Epoch 2/8, Batch 4100/15855, Loss: 5.6930\n",
            "Epoch 2/8, Batch 4150/15855, Loss: 5.6707\n",
            "Epoch 2/8, Batch 4200/15855, Loss: 5.6475\n",
            "Epoch 2/8, Batch 4250/15855, Loss: 6.3621\n",
            "Epoch 2/8, Batch 4300/15855, Loss: 5.6211\n",
            "Epoch 2/8, Batch 4350/15855, Loss: 4.6466\n",
            "Epoch 2/8, Batch 4400/15855, Loss: 6.1394\n",
            "Epoch 2/8, Batch 4450/15855, Loss: 6.6733\n",
            "Epoch 2/8, Batch 4500/15855, Loss: 6.3752\n",
            "Epoch 2/8, Batch 4550/15855, Loss: 5.2703\n",
            "Epoch 2/8, Batch 4600/15855, Loss: 5.9291\n",
            "Epoch 2/8, Batch 4650/15855, Loss: 5.2701\n",
            "Epoch 2/8, Batch 4700/15855, Loss: 5.6684\n",
            "Epoch 2/8, Batch 4750/15855, Loss: 5.1873\n",
            "Epoch 2/8, Batch 4800/15855, Loss: 5.6831\n",
            "Epoch 2/8, Batch 4850/15855, Loss: 5.2871\n",
            "Epoch 2/8, Batch 4900/15855, Loss: 5.4763\n",
            "Epoch 2/8, Batch 4950/15855, Loss: 6.3868\n",
            "Epoch 2/8, Batch 5000/15855, Loss: 5.4238\n",
            "Epoch 2/8, Batch 5050/15855, Loss: 4.9487\n",
            "Epoch 2/8, Batch 5100/15855, Loss: 5.7578\n",
            "Epoch 2/8, Batch 5150/15855, Loss: 5.0975\n",
            "Epoch 2/8, Batch 5200/15855, Loss: 5.7216\n",
            "Epoch 2/8, Batch 5250/15855, Loss: 5.6649\n",
            "Epoch 2/8, Batch 5300/15855, Loss: 6.3232\n",
            "Epoch 2/8, Batch 5350/15855, Loss: 5.8739\n",
            "Epoch 2/8, Batch 5400/15855, Loss: 5.8945\n",
            "Epoch 2/8, Batch 5450/15855, Loss: 6.0190\n",
            "Epoch 2/8, Batch 5500/15855, Loss: 5.5278\n",
            "Epoch 2/8, Batch 5550/15855, Loss: 5.3619\n",
            "Epoch 2/8, Batch 5600/15855, Loss: 5.2096\n",
            "Epoch 2/8, Batch 5650/15855, Loss: 5.1950\n",
            "Epoch 2/8, Batch 5700/15855, Loss: 5.6085\n",
            "Epoch 2/8, Batch 5750/15855, Loss: 6.4585\n",
            "Epoch 2/8, Batch 5800/15855, Loss: 5.5788\n",
            "Epoch 2/8, Batch 5850/15855, Loss: 5.8742\n",
            "Epoch 2/8, Batch 5900/15855, Loss: 5.3052\n",
            "Epoch 2/8, Batch 5950/15855, Loss: 5.5995\n",
            "Epoch 2/8, Batch 6000/15855, Loss: 5.0860\n",
            "Epoch 2/8, Batch 6050/15855, Loss: 6.4034\n",
            "Epoch 2/8, Batch 6100/15855, Loss: 5.8515\n",
            "Epoch 2/8, Batch 6150/15855, Loss: 5.0396\n",
            "Epoch 2/8, Batch 6200/15855, Loss: 5.5115\n",
            "Epoch 2/8, Batch 6250/15855, Loss: 5.7571\n",
            "Epoch 2/8, Batch 6300/15855, Loss: 5.5124\n",
            "Epoch 2/8, Batch 6350/15855, Loss: 5.8843\n",
            "Epoch 2/8, Batch 6400/15855, Loss: 5.6197\n",
            "Epoch 2/8, Batch 6450/15855, Loss: 5.6260\n",
            "Epoch 2/8, Batch 6500/15855, Loss: 6.0631\n",
            "Epoch 2/8, Batch 6550/15855, Loss: 5.9494\n",
            "Epoch 2/8, Batch 6600/15855, Loss: 5.8391\n",
            "Epoch 2/8, Batch 6650/15855, Loss: 5.7996\n",
            "Epoch 2/8, Batch 6700/15855, Loss: 5.1399\n",
            "Epoch 2/8, Batch 6750/15855, Loss: 5.3924\n",
            "Epoch 2/8, Batch 6800/15855, Loss: 6.1397\n",
            "Epoch 2/8, Batch 6850/15855, Loss: 5.8829\n",
            "Epoch 2/8, Batch 6900/15855, Loss: 6.4103\n",
            "Epoch 2/8, Batch 6950/15855, Loss: 5.6104\n",
            "Epoch 2/8, Batch 7000/15855, Loss: 5.0440\n",
            "Epoch 2/8, Batch 7050/15855, Loss: 5.6131\n",
            "Epoch 2/8, Batch 7100/15855, Loss: 4.9634\n",
            "Epoch 2/8, Batch 7150/15855, Loss: 5.0652\n",
            "Epoch 2/8, Batch 7200/15855, Loss: 5.7290\n",
            "Epoch 2/8, Batch 7250/15855, Loss: 5.5946\n",
            "Epoch 2/8, Batch 7300/15855, Loss: 5.6666\n",
            "Epoch 2/8, Batch 7350/15855, Loss: 5.1551\n",
            "Epoch 2/8, Batch 7400/15855, Loss: 5.8063\n",
            "Epoch 2/8, Batch 7450/15855, Loss: 5.7732\n",
            "Epoch 2/8, Batch 7500/15855, Loss: 5.5521\n",
            "Epoch 2/8, Batch 7550/15855, Loss: 4.6433\n",
            "Epoch 2/8, Batch 7600/15855, Loss: 4.7611\n",
            "Epoch 2/8, Batch 7650/15855, Loss: 5.1249\n",
            "Epoch 2/8, Batch 7700/15855, Loss: 5.8996\n",
            "Epoch 2/8, Batch 7750/15855, Loss: 5.6064\n",
            "Epoch 2/8, Batch 7800/15855, Loss: 5.3656\n",
            "Epoch 2/8, Batch 7850/15855, Loss: 4.9351\n",
            "Epoch 2/8, Batch 7900/15855, Loss: 5.8794\n",
            "Epoch 2/8, Batch 7950/15855, Loss: 5.1126\n",
            "Epoch 2/8, Batch 8000/15855, Loss: 5.4993\n",
            "Epoch 2/8, Batch 8050/15855, Loss: 5.4569\n",
            "Epoch 2/8, Batch 8100/15855, Loss: 5.1845\n",
            "Epoch 2/8, Batch 8150/15855, Loss: 5.1492\n",
            "Epoch 2/8, Batch 8200/15855, Loss: 5.5186\n",
            "Epoch 2/8, Batch 8250/15855, Loss: 5.5550\n",
            "Epoch 2/8, Batch 8300/15855, Loss: 5.4495\n",
            "Epoch 2/8, Batch 8350/15855, Loss: 5.3336\n",
            "Epoch 2/8, Batch 8400/15855, Loss: 5.8124\n",
            "Epoch 2/8, Batch 8450/15855, Loss: 5.0790\n",
            "Epoch 2/8, Batch 8500/15855, Loss: 5.5916\n",
            "Epoch 2/8, Batch 8550/15855, Loss: 5.4902\n",
            "Epoch 2/8, Batch 8600/15855, Loss: 5.8039\n",
            "Epoch 2/8, Batch 8650/15855, Loss: 5.2724\n",
            "Epoch 2/8, Batch 8700/15855, Loss: 5.1149\n",
            "Epoch 2/8, Batch 8750/15855, Loss: 4.9268\n",
            "Epoch 2/8, Batch 8800/15855, Loss: 4.7547\n",
            "Epoch 2/8, Batch 8850/15855, Loss: 5.5569\n",
            "Epoch 2/8, Batch 8900/15855, Loss: 6.0613\n",
            "Epoch 2/8, Batch 8950/15855, Loss: 5.6889\n",
            "Epoch 2/8, Batch 9000/15855, Loss: 5.5784\n",
            "Epoch 2/8, Batch 9050/15855, Loss: 5.6672\n",
            "Epoch 2/8, Batch 9100/15855, Loss: 5.3945\n",
            "Epoch 2/8, Batch 9150/15855, Loss: 6.3219\n",
            "Epoch 2/8, Batch 9200/15855, Loss: 5.3258\n",
            "Epoch 2/8, Batch 9250/15855, Loss: 5.5874\n",
            "Epoch 2/8, Batch 9300/15855, Loss: 6.3662\n",
            "Epoch 2/8, Batch 9350/15855, Loss: 6.0430\n",
            "Epoch 2/8, Batch 9400/15855, Loss: 5.5539\n",
            "Epoch 2/8, Batch 9450/15855, Loss: 5.1565\n",
            "Epoch 2/8, Batch 9500/15855, Loss: 5.9125\n",
            "Epoch 2/8, Batch 9550/15855, Loss: 6.3514\n",
            "Epoch 2/8, Batch 9600/15855, Loss: 5.0523\n",
            "Epoch 2/8, Batch 9650/15855, Loss: 5.4071\n",
            "Epoch 2/8, Batch 9700/15855, Loss: 5.2996\n",
            "Epoch 2/8, Batch 9750/15855, Loss: 5.4224\n",
            "Epoch 2/8, Batch 9800/15855, Loss: 5.0416\n",
            "Epoch 2/8, Batch 9850/15855, Loss: 4.9018\n",
            "Epoch 2/8, Batch 9900/15855, Loss: 5.9963\n",
            "Epoch 2/8, Batch 9950/15855, Loss: 5.1500\n",
            "Epoch 2/8, Batch 10000/15855, Loss: 5.4916\n",
            "Epoch 2/8, Batch 10050/15855, Loss: 5.3304\n",
            "Epoch 2/8, Batch 10100/15855, Loss: 5.8773\n",
            "Epoch 2/8, Batch 10150/15855, Loss: 5.3336\n",
            "Epoch 2/8, Batch 10200/15855, Loss: 5.1932\n",
            "Epoch 2/8, Batch 10250/15855, Loss: 5.5102\n",
            "Epoch 2/8, Batch 10300/15855, Loss: 5.1070\n",
            "Epoch 2/8, Batch 10350/15855, Loss: 5.5320\n",
            "Epoch 2/8, Batch 10400/15855, Loss: 5.5733\n",
            "Epoch 2/8, Batch 10450/15855, Loss: 4.5666\n",
            "Epoch 2/8, Batch 10500/15855, Loss: 5.2576\n",
            "Epoch 2/8, Batch 10550/15855, Loss: 5.1887\n",
            "Epoch 2/8, Batch 10600/15855, Loss: 5.6152\n",
            "Epoch 2/8, Batch 10650/15855, Loss: 5.6071\n",
            "Epoch 2/8, Batch 10700/15855, Loss: 5.3152\n",
            "Epoch 2/8, Batch 10750/15855, Loss: 5.4860\n",
            "Epoch 2/8, Batch 10800/15855, Loss: 5.1756\n",
            "Epoch 2/8, Batch 10850/15855, Loss: 5.6515\n",
            "Epoch 2/8, Batch 10900/15855, Loss: 5.9322\n",
            "Epoch 2/8, Batch 10950/15855, Loss: 4.8784\n",
            "Epoch 2/8, Batch 11000/15855, Loss: 5.8841\n",
            "Epoch 2/8, Batch 11050/15855, Loss: 4.7220\n",
            "Epoch 2/8, Batch 11100/15855, Loss: 5.8936\n",
            "Epoch 2/8, Batch 11150/15855, Loss: 5.7960\n",
            "Epoch 2/8, Batch 11200/15855, Loss: 5.4004\n",
            "Epoch 2/8, Batch 11250/15855, Loss: 5.7117\n",
            "Epoch 2/8, Batch 11300/15855, Loss: 5.5038\n",
            "Epoch 2/8, Batch 11350/15855, Loss: 5.1363\n",
            "Epoch 2/8, Batch 11400/15855, Loss: 5.3126\n",
            "Epoch 2/8, Batch 11450/15855, Loss: 5.6555\n",
            "Epoch 2/8, Batch 11500/15855, Loss: 5.5724\n",
            "Epoch 2/8, Batch 11550/15855, Loss: 5.4775\n",
            "Epoch 2/8, Batch 11600/15855, Loss: 5.6219\n",
            "Epoch 2/8, Batch 11650/15855, Loss: 6.1614\n",
            "Epoch 2/8, Batch 11700/15855, Loss: 6.5370\n",
            "Epoch 2/8, Batch 11750/15855, Loss: 5.6752\n",
            "Epoch 2/8, Batch 11800/15855, Loss: 5.1776\n",
            "Epoch 2/8, Batch 11850/15855, Loss: 6.2382\n",
            "Epoch 2/8, Batch 11900/15855, Loss: 5.3670\n",
            "Epoch 2/8, Batch 11950/15855, Loss: 5.3507\n",
            "Epoch 2/8, Batch 12000/15855, Loss: 5.7007\n",
            "Epoch 2/8, Batch 12050/15855, Loss: 6.3533\n",
            "Epoch 2/8, Batch 12100/15855, Loss: 5.9271\n",
            "Epoch 2/8, Batch 12150/15855, Loss: 5.3191\n",
            "Epoch 2/8, Batch 12200/15855, Loss: 5.8823\n",
            "Epoch 2/8, Batch 12250/15855, Loss: 5.1371\n",
            "Epoch 2/8, Batch 12300/15855, Loss: 5.2218\n",
            "Epoch 2/8, Batch 12350/15855, Loss: 5.5210\n",
            "Epoch 2/8, Batch 12400/15855, Loss: 5.5663\n",
            "Epoch 2/8, Batch 12450/15855, Loss: 5.4392\n",
            "Epoch 2/8, Batch 12500/15855, Loss: 6.6285\n",
            "Epoch 2/8, Batch 12550/15855, Loss: 5.0549\n",
            "Epoch 2/8, Batch 12600/15855, Loss: 5.9119\n",
            "Epoch 2/8, Batch 12650/15855, Loss: 5.4662\n",
            "Epoch 2/8, Batch 12700/15855, Loss: 5.9721\n",
            "Epoch 2/8, Batch 12750/15855, Loss: 5.2801\n",
            "Epoch 2/8, Batch 12800/15855, Loss: 4.9210\n",
            "Epoch 2/8, Batch 12850/15855, Loss: 5.4762\n",
            "Epoch 2/8, Batch 12900/15855, Loss: 5.1128\n",
            "Epoch 2/8, Batch 12950/15855, Loss: 5.0555\n",
            "Epoch 2/8, Batch 13000/15855, Loss: 5.8786\n",
            "Epoch 2/8, Batch 13050/15855, Loss: 5.0465\n",
            "Epoch 2/8, Batch 13100/15855, Loss: 6.0538\n",
            "Epoch 2/8, Batch 13150/15855, Loss: 5.8227\n",
            "Epoch 2/8, Batch 13200/15855, Loss: 5.7931\n",
            "Epoch 2/8, Batch 13250/15855, Loss: 5.1925\n",
            "Epoch 2/8, Batch 13300/15855, Loss: 5.2603\n",
            "Epoch 2/8, Batch 13350/15855, Loss: 5.0545\n",
            "Epoch 2/8, Batch 13400/15855, Loss: 5.6528\n",
            "Epoch 2/8, Batch 13450/15855, Loss: 5.6705\n",
            "Epoch 2/8, Batch 13500/15855, Loss: 5.2007\n",
            "Epoch 2/8, Batch 13550/15855, Loss: 5.3725\n",
            "Epoch 2/8, Batch 13600/15855, Loss: 5.9831\n",
            "Epoch 2/8, Batch 13650/15855, Loss: 5.5815\n",
            "Epoch 2/8, Batch 13700/15855, Loss: 5.4621\n",
            "Epoch 2/8, Batch 13750/15855, Loss: 5.9775\n",
            "Epoch 2/8, Batch 13800/15855, Loss: 5.0615\n",
            "Epoch 2/8, Batch 13850/15855, Loss: 5.4696\n",
            "Epoch 2/8, Batch 13900/15855, Loss: 5.8804\n",
            "Epoch 2/8, Batch 13950/15855, Loss: 5.0778\n",
            "Epoch 2/8, Batch 14000/15855, Loss: 4.2585\n",
            "Epoch 2/8, Batch 14050/15855, Loss: 5.5714\n",
            "Epoch 2/8, Batch 14100/15855, Loss: 5.5374\n",
            "Epoch 2/8, Batch 14150/15855, Loss: 5.3279\n",
            "Epoch 2/8, Batch 14200/15855, Loss: 5.4385\n",
            "Epoch 2/8, Batch 14250/15855, Loss: 4.9267\n",
            "Epoch 2/8, Batch 14300/15855, Loss: 5.8262\n",
            "Epoch 2/8, Batch 14350/15855, Loss: 4.8569\n",
            "Epoch 2/8, Batch 14400/15855, Loss: 5.8338\n",
            "Epoch 2/8, Batch 14450/15855, Loss: 6.1020\n",
            "Epoch 2/8, Batch 14500/15855, Loss: 5.1455\n",
            "Epoch 2/8, Batch 14550/15855, Loss: 5.9234\n",
            "Epoch 2/8, Batch 14600/15855, Loss: 6.1025\n",
            "Epoch 2/8, Batch 14650/15855, Loss: 5.4293\n",
            "Epoch 2/8, Batch 14700/15855, Loss: 5.1552\n",
            "Epoch 2/8, Batch 14750/15855, Loss: 5.8622\n",
            "Epoch 2/8, Batch 14800/15855, Loss: 5.6480\n",
            "Epoch 2/8, Batch 14850/15855, Loss: 5.7646\n",
            "Epoch 2/8, Batch 14900/15855, Loss: 5.1692\n",
            "Epoch 2/8, Batch 14950/15855, Loss: 5.4940\n",
            "Epoch 2/8, Batch 15000/15855, Loss: 5.5198\n",
            "Epoch 2/8, Batch 15050/15855, Loss: 6.4461\n",
            "Epoch 2/8, Batch 15100/15855, Loss: 6.2154\n",
            "Epoch 2/8, Batch 15150/15855, Loss: 5.5172\n",
            "Epoch 2/8, Batch 15200/15855, Loss: 5.5186\n",
            "Epoch 2/8, Batch 15250/15855, Loss: 5.7453\n",
            "Epoch 2/8, Batch 15300/15855, Loss: 4.9770\n",
            "Epoch 2/8, Batch 15350/15855, Loss: 5.9239\n",
            "Epoch 2/8, Batch 15400/15855, Loss: 5.4692\n",
            "Epoch 2/8, Batch 15450/15855, Loss: 5.1829\n",
            "Epoch 2/8, Batch 15500/15855, Loss: 5.0717\n",
            "Epoch 2/8, Batch 15550/15855, Loss: 5.8899\n",
            "Epoch 2/8, Batch 15600/15855, Loss: 6.0318\n",
            "Epoch 2/8, Batch 15650/15855, Loss: 5.3530\n",
            "Epoch 2/8, Batch 15700/15855, Loss: 6.5587\n",
            "Epoch 2/8, Batch 15750/15855, Loss: 5.6100\n",
            "Epoch 2/8, Batch 15800/15855, Loss: 5.5340\n",
            "Epoch 2/8, Batch 15850/15855, Loss: 5.1721\n",
            "Epoch 2/8 - Train Loss: 5.5619, Val Loss: 5.3815\n",
            "Exemple g√©n√©r√©: \"harry wanted to be <UNK> with the strange of his hands, was the shock of the ink vast, time to\"\n",
            "\n",
            "Epoch 3/8, Batch 0/15855, Loss: 5.9155\n",
            "Epoch 3/8, Batch 50/15855, Loss: 5.1155\n",
            "Epoch 3/8, Batch 100/15855, Loss: 5.5912\n",
            "Epoch 3/8, Batch 150/15855, Loss: 5.2754\n",
            "Epoch 3/8, Batch 200/15855, Loss: 5.4391\n",
            "Epoch 3/8, Batch 250/15855, Loss: 4.7034\n",
            "Epoch 3/8, Batch 300/15855, Loss: 6.2949\n",
            "Epoch 3/8, Batch 350/15855, Loss: 5.2457\n",
            "Epoch 3/8, Batch 400/15855, Loss: 5.8238\n",
            "Epoch 3/8, Batch 450/15855, Loss: 5.2163\n",
            "Epoch 3/8, Batch 500/15855, Loss: 4.3853\n",
            "Epoch 3/8, Batch 550/15855, Loss: 5.1808\n",
            "Epoch 3/8, Batch 600/15855, Loss: 5.7620\n",
            "Epoch 3/8, Batch 650/15855, Loss: 5.3988\n",
            "Epoch 3/8, Batch 700/15855, Loss: 5.5170\n",
            "Epoch 3/8, Batch 750/15855, Loss: 5.6054\n",
            "Epoch 3/8, Batch 800/15855, Loss: 5.2781\n",
            "Epoch 3/8, Batch 850/15855, Loss: 5.5192\n",
            "Epoch 3/8, Batch 900/15855, Loss: 5.6890\n",
            "Epoch 3/8, Batch 950/15855, Loss: 4.5537\n",
            "Epoch 3/8, Batch 1000/15855, Loss: 5.3558\n",
            "Epoch 3/8, Batch 1050/15855, Loss: 4.7899\n",
            "Epoch 3/8, Batch 1100/15855, Loss: 5.9690\n",
            "Epoch 3/8, Batch 1150/15855, Loss: 5.3176\n",
            "Epoch 3/8, Batch 1200/15855, Loss: 5.5755\n",
            "Epoch 3/8, Batch 1250/15855, Loss: 5.0391\n",
            "Epoch 3/8, Batch 1300/15855, Loss: 4.7756\n",
            "Epoch 3/8, Batch 1350/15855, Loss: 5.5238\n",
            "Epoch 3/8, Batch 1400/15855, Loss: 5.0409\n",
            "Epoch 3/8, Batch 1450/15855, Loss: 5.2510\n",
            "Epoch 3/8, Batch 1500/15855, Loss: 4.7242\n",
            "Epoch 3/8, Batch 1550/15855, Loss: 5.3076\n",
            "Epoch 3/8, Batch 1600/15855, Loss: 5.6750\n",
            "Epoch 3/8, Batch 1650/15855, Loss: 5.3133\n",
            "Epoch 3/8, Batch 1700/15855, Loss: 5.0978\n",
            "Epoch 3/8, Batch 1750/15855, Loss: 4.5944\n",
            "Epoch 3/8, Batch 1800/15855, Loss: 5.5289\n",
            "Epoch 3/8, Batch 1850/15855, Loss: 5.1201\n",
            "Epoch 3/8, Batch 1900/15855, Loss: 5.5109\n",
            "Epoch 3/8, Batch 1950/15855, Loss: 4.7927\n",
            "Epoch 3/8, Batch 2000/15855, Loss: 5.1694\n",
            "Epoch 3/8, Batch 2050/15855, Loss: 5.5003\n",
            "Epoch 3/8, Batch 2100/15855, Loss: 6.2020\n",
            "Epoch 3/8, Batch 2150/15855, Loss: 5.1116\n",
            "Epoch 3/8, Batch 2200/15855, Loss: 5.5828\n",
            "Epoch 3/8, Batch 2250/15855, Loss: 5.5514\n",
            "Epoch 3/8, Batch 2300/15855, Loss: 5.4527\n",
            "Epoch 3/8, Batch 2350/15855, Loss: 6.0652\n",
            "Epoch 3/8, Batch 2400/15855, Loss: 5.1390\n",
            "Epoch 3/8, Batch 2450/15855, Loss: 5.0145\n",
            "Epoch 3/8, Batch 2500/15855, Loss: 5.4990\n",
            "Epoch 3/8, Batch 2550/15855, Loss: 5.1167\n",
            "Epoch 3/8, Batch 2600/15855, Loss: 4.9238\n",
            "Epoch 3/8, Batch 2650/15855, Loss: 5.3612\n",
            "Epoch 3/8, Batch 2700/15855, Loss: 5.6754\n",
            "Epoch 3/8, Batch 2750/15855, Loss: 5.5097\n",
            "Epoch 3/8, Batch 2800/15855, Loss: 5.2727\n",
            "Epoch 3/8, Batch 2850/15855, Loss: 4.8406\n",
            "Epoch 3/8, Batch 2900/15855, Loss: 4.8674\n",
            "Epoch 3/8, Batch 2950/15855, Loss: 5.1942\n",
            "Epoch 3/8, Batch 3000/15855, Loss: 5.8404\n",
            "Epoch 3/8, Batch 3050/15855, Loss: 5.1998\n",
            "Epoch 3/8, Batch 3100/15855, Loss: 5.9031\n",
            "Epoch 3/8, Batch 3150/15855, Loss: 5.6992\n",
            "Epoch 3/8, Batch 3200/15855, Loss: 5.3170\n",
            "Epoch 3/8, Batch 3250/15855, Loss: 5.2554\n",
            "Epoch 3/8, Batch 3300/15855, Loss: 5.9198\n",
            "Epoch 3/8, Batch 3350/15855, Loss: 5.1088\n",
            "Epoch 3/8, Batch 3400/15855, Loss: 6.2431\n",
            "Epoch 3/8, Batch 3450/15855, Loss: 5.3013\n",
            "Epoch 3/8, Batch 3500/15855, Loss: 5.8218\n",
            "Epoch 3/8, Batch 3550/15855, Loss: 5.6980\n",
            "Epoch 3/8, Batch 3600/15855, Loss: 5.6145\n",
            "Epoch 3/8, Batch 3650/15855, Loss: 5.8299\n",
            "Epoch 3/8, Batch 3700/15855, Loss: 5.6822\n",
            "Epoch 3/8, Batch 3750/15855, Loss: 5.1844\n",
            "Epoch 3/8, Batch 3800/15855, Loss: 5.3570\n",
            "Epoch 3/8, Batch 3850/15855, Loss: 4.9098\n",
            "Epoch 3/8, Batch 3900/15855, Loss: 5.0329\n",
            "Epoch 3/8, Batch 3950/15855, Loss: 5.1656\n",
            "Epoch 3/8, Batch 4000/15855, Loss: 5.9542\n",
            "Epoch 3/8, Batch 4050/15855, Loss: 5.5243\n",
            "Epoch 3/8, Batch 4100/15855, Loss: 5.4258\n",
            "Epoch 3/8, Batch 4150/15855, Loss: 5.1835\n",
            "Epoch 3/8, Batch 4200/15855, Loss: 5.3441\n",
            "Epoch 3/8, Batch 4250/15855, Loss: 4.5149\n",
            "Epoch 3/8, Batch 4300/15855, Loss: 5.6997\n",
            "Epoch 3/8, Batch 4350/15855, Loss: 5.2026\n",
            "Epoch 3/8, Batch 4400/15855, Loss: 5.3371\n",
            "Epoch 3/8, Batch 4450/15855, Loss: 5.1518\n",
            "Epoch 3/8, Batch 4500/15855, Loss: 6.1552\n",
            "Epoch 3/8, Batch 4550/15855, Loss: 5.5162\n",
            "Epoch 3/8, Batch 4600/15855, Loss: 5.6205\n",
            "Epoch 3/8, Batch 4650/15855, Loss: 5.4896\n",
            "Epoch 3/8, Batch 4700/15855, Loss: 5.5642\n",
            "Epoch 3/8, Batch 4750/15855, Loss: 5.3649\n",
            "Epoch 3/8, Batch 4800/15855, Loss: 5.2589\n",
            "Epoch 3/8, Batch 4850/15855, Loss: 5.3927\n",
            "Epoch 3/8, Batch 4900/15855, Loss: 5.1198\n",
            "Epoch 3/8, Batch 4950/15855, Loss: 5.6263\n",
            "Epoch 3/8, Batch 5000/15855, Loss: 5.1095\n",
            "Epoch 3/8, Batch 5050/15855, Loss: 5.4866\n",
            "Epoch 3/8, Batch 5100/15855, Loss: 5.6682\n",
            "Epoch 3/8, Batch 5150/15855, Loss: 5.0636\n",
            "Epoch 3/8, Batch 5200/15855, Loss: 5.8613\n",
            "Epoch 3/8, Batch 5250/15855, Loss: 5.9741\n",
            "Epoch 3/8, Batch 5300/15855, Loss: 5.1502\n",
            "Epoch 3/8, Batch 5350/15855, Loss: 5.6903\n",
            "Epoch 3/8, Batch 5400/15855, Loss: 5.4670\n",
            "Epoch 3/8, Batch 5450/15855, Loss: 5.3893\n",
            "Epoch 3/8, Batch 5500/15855, Loss: 5.2843\n",
            "Epoch 3/8, Batch 5550/15855, Loss: 5.3132\n",
            "Epoch 3/8, Batch 5600/15855, Loss: 5.6257\n",
            "Epoch 3/8, Batch 5650/15855, Loss: 5.8922\n",
            "Epoch 3/8, Batch 5700/15855, Loss: 5.1004\n",
            "Epoch 3/8, Batch 5750/15855, Loss: 5.1662\n",
            "Epoch 3/8, Batch 5800/15855, Loss: 5.6883\n",
            "Epoch 3/8, Batch 5850/15855, Loss: 5.3622\n",
            "Epoch 3/8, Batch 5900/15855, Loss: 5.3706\n",
            "Epoch 3/8, Batch 5950/15855, Loss: 5.2022\n",
            "Epoch 3/8, Batch 6000/15855, Loss: 5.2605\n",
            "Epoch 3/8, Batch 6050/15855, Loss: 5.9508\n",
            "Epoch 3/8, Batch 6100/15855, Loss: 5.0612\n",
            "Epoch 3/8, Batch 6150/15855, Loss: 4.8495\n",
            "Epoch 3/8, Batch 6200/15855, Loss: 5.8166\n",
            "Epoch 3/8, Batch 6250/15855, Loss: 5.1977\n",
            "Epoch 3/8, Batch 6300/15855, Loss: 5.7019\n",
            "Epoch 3/8, Batch 6350/15855, Loss: 5.8689\n",
            "Epoch 3/8, Batch 6400/15855, Loss: 6.0579\n",
            "Epoch 3/8, Batch 6450/15855, Loss: 5.0990\n",
            "Epoch 3/8, Batch 6500/15855, Loss: 5.9999\n",
            "Epoch 3/8, Batch 6550/15855, Loss: 5.8651\n",
            "Epoch 3/8, Batch 6600/15855, Loss: 5.3928\n",
            "Epoch 3/8, Batch 6650/15855, Loss: 5.6928\n",
            "Epoch 3/8, Batch 6700/15855, Loss: 5.9933\n",
            "Epoch 3/8, Batch 6750/15855, Loss: 4.8977\n",
            "Epoch 3/8, Batch 6800/15855, Loss: 5.6721\n",
            "Epoch 3/8, Batch 6850/15855, Loss: 5.1625\n",
            "Epoch 3/8, Batch 6900/15855, Loss: 5.2501\n",
            "Epoch 3/8, Batch 6950/15855, Loss: 5.1024\n",
            "Epoch 3/8, Batch 7000/15855, Loss: 6.1309\n",
            "Epoch 3/8, Batch 7050/15855, Loss: 5.9444\n",
            "Epoch 3/8, Batch 7100/15855, Loss: 4.8732\n",
            "Epoch 3/8, Batch 7150/15855, Loss: 4.8749\n",
            "Epoch 3/8, Batch 7200/15855, Loss: 5.3058\n",
            "Epoch 3/8, Batch 7250/15855, Loss: 5.4215\n",
            "Epoch 3/8, Batch 7300/15855, Loss: 4.6513\n",
            "Epoch 3/8, Batch 7350/15855, Loss: 5.0236\n",
            "Epoch 3/8, Batch 7400/15855, Loss: 5.2998\n",
            "Epoch 3/8, Batch 7450/15855, Loss: 5.0288\n",
            "Epoch 3/8, Batch 7500/15855, Loss: 5.6047\n",
            "Epoch 3/8, Batch 7550/15855, Loss: 5.1972\n",
            "Epoch 3/8, Batch 7600/15855, Loss: 5.2526\n",
            "Epoch 3/8, Batch 7650/15855, Loss: 4.7180\n",
            "Epoch 3/8, Batch 7700/15855, Loss: 5.7426\n",
            "Epoch 3/8, Batch 7750/15855, Loss: 5.6679\n",
            "Epoch 3/8, Batch 7800/15855, Loss: 5.9507\n",
            "Epoch 3/8, Batch 7850/15855, Loss: 5.7910\n",
            "Epoch 3/8, Batch 7900/15855, Loss: 5.7019\n",
            "Epoch 3/8, Batch 7950/15855, Loss: 4.9232\n",
            "Epoch 3/8, Batch 8000/15855, Loss: 5.3352\n",
            "Epoch 3/8, Batch 8050/15855, Loss: 5.5135\n",
            "Epoch 3/8, Batch 8100/15855, Loss: 5.3182\n",
            "Epoch 3/8, Batch 8150/15855, Loss: 5.5638\n",
            "Epoch 3/8, Batch 8200/15855, Loss: 4.2105\n",
            "Epoch 3/8, Batch 8250/15855, Loss: 5.2201\n",
            "Epoch 3/8, Batch 8300/15855, Loss: 6.1274\n",
            "Epoch 3/8, Batch 8350/15855, Loss: 6.0491\n",
            "Epoch 3/8, Batch 8400/15855, Loss: 5.7838\n",
            "Epoch 3/8, Batch 8450/15855, Loss: 4.7170\n",
            "Epoch 3/8, Batch 8500/15855, Loss: 5.9477\n",
            "Epoch 3/8, Batch 8550/15855, Loss: 5.6269\n",
            "Epoch 3/8, Batch 8600/15855, Loss: 5.4453\n",
            "Epoch 3/8, Batch 8650/15855, Loss: 5.4208\n",
            "Epoch 3/8, Batch 8700/15855, Loss: 5.1820\n",
            "Epoch 3/8, Batch 8750/15855, Loss: 5.1208\n",
            "Epoch 3/8, Batch 8800/15855, Loss: 4.7939\n",
            "Epoch 3/8, Batch 8850/15855, Loss: 4.9109\n",
            "Epoch 3/8, Batch 8900/15855, Loss: 5.4117\n",
            "Epoch 3/8, Batch 8950/15855, Loss: 5.4160\n",
            "Epoch 3/8, Batch 9000/15855, Loss: 4.6416\n",
            "Epoch 3/8, Batch 9050/15855, Loss: 5.7057\n",
            "Epoch 3/8, Batch 9100/15855, Loss: 4.5530\n",
            "Epoch 3/8, Batch 9150/15855, Loss: 4.8236\n",
            "Epoch 3/8, Batch 9200/15855, Loss: 5.5650\n",
            "Epoch 3/8, Batch 9250/15855, Loss: 5.3088\n",
            "Epoch 3/8, Batch 9300/15855, Loss: 5.8260\n",
            "Epoch 3/8, Batch 9350/15855, Loss: 5.3565\n",
            "Epoch 3/8, Batch 9400/15855, Loss: 5.6929\n",
            "Epoch 3/8, Batch 9450/15855, Loss: 4.5181\n",
            "Epoch 3/8, Batch 9500/15855, Loss: 5.1064\n",
            "Epoch 3/8, Batch 9550/15855, Loss: 5.6092\n",
            "Epoch 3/8, Batch 9600/15855, Loss: 5.3257\n",
            "Epoch 3/8, Batch 9650/15855, Loss: 6.1721\n",
            "Epoch 3/8, Batch 9700/15855, Loss: 4.6701\n",
            "Epoch 3/8, Batch 9750/15855, Loss: 5.7261\n",
            "Epoch 3/8, Batch 9800/15855, Loss: 5.3533\n",
            "Epoch 3/8, Batch 9850/15855, Loss: 5.3599\n",
            "Epoch 3/8, Batch 9900/15855, Loss: 5.2796\n",
            "Epoch 3/8, Batch 9950/15855, Loss: 5.8860\n",
            "Epoch 3/8, Batch 10000/15855, Loss: 5.0408\n",
            "Epoch 3/8, Batch 10050/15855, Loss: 4.3750\n",
            "Epoch 3/8, Batch 10100/15855, Loss: 5.6961\n",
            "Epoch 3/8, Batch 10150/15855, Loss: 4.6825\n",
            "Epoch 3/8, Batch 10200/15855, Loss: 5.0705\n",
            "Epoch 3/8, Batch 10250/15855, Loss: 5.4117\n",
            "Epoch 3/8, Batch 10300/15855, Loss: 6.1669\n",
            "Epoch 3/8, Batch 10350/15855, Loss: 5.4874\n",
            "Epoch 3/8, Batch 10400/15855, Loss: 6.0065\n",
            "Epoch 3/8, Batch 10450/15855, Loss: 5.5779\n",
            "Epoch 3/8, Batch 10500/15855, Loss: 5.7021\n",
            "Epoch 3/8, Batch 10550/15855, Loss: 5.8267\n",
            "Epoch 3/8, Batch 10600/15855, Loss: 5.1221\n",
            "Epoch 3/8, Batch 10650/15855, Loss: 4.8923\n",
            "Epoch 3/8, Batch 10700/15855, Loss: 5.6047\n",
            "Epoch 3/8, Batch 10750/15855, Loss: 5.1841\n",
            "Epoch 3/8, Batch 10800/15855, Loss: 5.1348\n",
            "Epoch 3/8, Batch 10850/15855, Loss: 5.4688\n",
            "Epoch 3/8, Batch 10900/15855, Loss: 5.3194\n",
            "Epoch 3/8, Batch 10950/15855, Loss: 5.1012\n",
            "Epoch 3/8, Batch 11000/15855, Loss: 4.7007\n",
            "Epoch 3/8, Batch 11050/15855, Loss: 5.3983\n",
            "Epoch 3/8, Batch 11100/15855, Loss: 5.1221\n",
            "Epoch 3/8, Batch 11150/15855, Loss: 6.0569\n",
            "Epoch 3/8, Batch 11200/15855, Loss: 4.8534\n",
            "Epoch 3/8, Batch 11250/15855, Loss: 4.7185\n",
            "Epoch 3/8, Batch 11300/15855, Loss: 4.9299\n",
            "Epoch 3/8, Batch 11350/15855, Loss: 5.1664\n",
            "Epoch 3/8, Batch 11400/15855, Loss: 5.9601\n",
            "Epoch 3/8, Batch 11450/15855, Loss: 4.3557\n",
            "Epoch 3/8, Batch 11500/15855, Loss: 4.9281\n",
            "Epoch 3/8, Batch 11550/15855, Loss: 5.2989\n",
            "Epoch 3/8, Batch 11600/15855, Loss: 5.4499\n",
            "Epoch 3/8, Batch 11650/15855, Loss: 5.0790\n",
            "Epoch 3/8, Batch 11700/15855, Loss: 5.4031\n",
            "Epoch 3/8, Batch 11750/15855, Loss: 5.0514\n",
            "Epoch 3/8, Batch 11800/15855, Loss: 5.6206\n",
            "Epoch 3/8, Batch 11850/15855, Loss: 5.4483\n",
            "Epoch 3/8, Batch 11900/15855, Loss: 4.9933\n",
            "Epoch 3/8, Batch 11950/15855, Loss: 5.0022\n",
            "Epoch 3/8, Batch 12000/15855, Loss: 5.2890\n",
            "Epoch 3/8, Batch 12050/15855, Loss: 5.7610\n",
            "Epoch 3/8, Batch 12100/15855, Loss: 5.5840\n",
            "Epoch 3/8, Batch 12150/15855, Loss: 5.5250\n",
            "Epoch 3/8, Batch 12200/15855, Loss: 4.8644\n",
            "Epoch 3/8, Batch 12250/15855, Loss: 5.6679\n",
            "Epoch 3/8, Batch 12300/15855, Loss: 4.7520\n",
            "Epoch 3/8, Batch 12350/15855, Loss: 4.8501\n",
            "Epoch 3/8, Batch 12400/15855, Loss: 5.6644\n",
            "Epoch 3/8, Batch 12450/15855, Loss: 5.7320\n",
            "Epoch 3/8, Batch 12500/15855, Loss: 5.1768\n",
            "Epoch 3/8, Batch 12550/15855, Loss: 5.0745\n",
            "Epoch 3/8, Batch 12600/15855, Loss: 5.7572\n",
            "Epoch 3/8, Batch 12650/15855, Loss: 5.4079\n",
            "Epoch 3/8, Batch 12700/15855, Loss: 4.9519\n",
            "Epoch 3/8, Batch 12750/15855, Loss: 5.4020\n",
            "Epoch 3/8, Batch 12800/15855, Loss: 6.1579\n",
            "Epoch 3/8, Batch 12850/15855, Loss: 5.3071\n",
            "Epoch 3/8, Batch 12900/15855, Loss: 4.3266\n",
            "Epoch 3/8, Batch 12950/15855, Loss: 4.9244\n",
            "Epoch 3/8, Batch 13000/15855, Loss: 5.8706\n",
            "Epoch 3/8, Batch 13050/15855, Loss: 5.4959\n",
            "Epoch 3/8, Batch 13100/15855, Loss: 5.3406\n",
            "Epoch 3/8, Batch 13150/15855, Loss: 6.0138\n",
            "Epoch 3/8, Batch 13200/15855, Loss: 5.9865\n",
            "Epoch 3/8, Batch 13250/15855, Loss: 6.1064\n",
            "Epoch 3/8, Batch 13300/15855, Loss: 5.8360\n",
            "Epoch 3/8, Batch 13350/15855, Loss: 4.8062\n",
            "Epoch 3/8, Batch 13400/15855, Loss: 6.2535\n",
            "Epoch 3/8, Batch 13450/15855, Loss: 5.3880\n",
            "Epoch 3/8, Batch 13500/15855, Loss: 5.4177\n",
            "Epoch 3/8, Batch 13550/15855, Loss: 5.1250\n",
            "Epoch 3/8, Batch 13600/15855, Loss: 5.8240\n",
            "Epoch 3/8, Batch 13650/15855, Loss: 5.1263\n",
            "Epoch 3/8, Batch 13700/15855, Loss: 5.4333\n",
            "Epoch 3/8, Batch 13750/15855, Loss: 5.5410\n",
            "Epoch 3/8, Batch 13800/15855, Loss: 5.4105\n",
            "Epoch 3/8, Batch 13850/15855, Loss: 5.9767\n",
            "Epoch 3/8, Batch 13900/15855, Loss: 5.8057\n",
            "Epoch 3/8, Batch 13950/15855, Loss: 5.4281\n",
            "Epoch 3/8, Batch 14000/15855, Loss: 5.2675\n",
            "Epoch 3/8, Batch 14050/15855, Loss: 5.2465\n",
            "Epoch 3/8, Batch 14100/15855, Loss: 5.9469\n",
            "Epoch 3/8, Batch 14150/15855, Loss: 5.5930\n",
            "Epoch 3/8, Batch 14200/15855, Loss: 5.1721\n",
            "Epoch 3/8, Batch 14250/15855, Loss: 5.0869\n",
            "Epoch 3/8, Batch 14300/15855, Loss: 5.4142\n",
            "Epoch 3/8, Batch 14350/15855, Loss: 5.6471\n",
            "Epoch 3/8, Batch 14400/15855, Loss: 5.6428\n",
            "Epoch 3/8, Batch 14450/15855, Loss: 5.0918\n",
            "Epoch 3/8, Batch 14500/15855, Loss: 5.5834\n",
            "Epoch 3/8, Batch 14550/15855, Loss: 5.1593\n",
            "Epoch 3/8, Batch 14600/15855, Loss: 5.0453\n",
            "Epoch 3/8, Batch 14650/15855, Loss: 5.7107\n",
            "Epoch 3/8, Batch 14700/15855, Loss: 5.5184\n",
            "Epoch 3/8, Batch 14750/15855, Loss: 5.4623\n",
            "Epoch 3/8, Batch 14800/15855, Loss: 5.6046\n",
            "Epoch 3/8, Batch 14850/15855, Loss: 5.8249\n",
            "Epoch 3/8, Batch 14900/15855, Loss: 4.9158\n",
            "Epoch 3/8, Batch 14950/15855, Loss: 5.1124\n",
            "Epoch 3/8, Batch 15000/15855, Loss: 5.1124\n",
            "Epoch 3/8, Batch 15050/15855, Loss: 5.3241\n",
            "Epoch 3/8, Batch 15100/15855, Loss: 5.1442\n",
            "Epoch 3/8, Batch 15150/15855, Loss: 4.9856\n",
            "Epoch 3/8, Batch 15200/15855, Loss: 4.8296\n",
            "Epoch 3/8, Batch 15250/15855, Loss: 4.8696\n",
            "Epoch 3/8, Batch 15300/15855, Loss: 5.4293\n",
            "Epoch 3/8, Batch 15350/15855, Loss: 5.1847\n",
            "Epoch 3/8, Batch 15400/15855, Loss: 5.3163\n",
            "Epoch 3/8, Batch 15450/15855, Loss: 5.4368\n",
            "Epoch 3/8, Batch 15500/15855, Loss: 5.7091\n",
            "Epoch 3/8, Batch 15550/15855, Loss: 5.6584\n",
            "Epoch 3/8, Batch 15600/15855, Loss: 5.6060\n",
            "Epoch 3/8, Batch 15650/15855, Loss: 5.5114\n",
            "Epoch 3/8, Batch 15700/15855, Loss: 5.2467\n",
            "Epoch 3/8, Batch 15750/15855, Loss: 5.5729\n",
            "Epoch 3/8, Batch 15800/15855, Loss: 6.0870\n",
            "Epoch 3/8, Batch 15850/15855, Loss: 5.2087\n",
            "Epoch 3/8 - Train Loss: 5.3746, Val Loss: 5.2691\n",
            "Epoch 4/8, Batch 0/15855, Loss: 4.7773\n",
            "Epoch 4/8, Batch 50/15855, Loss: 5.2049\n",
            "Epoch 4/8, Batch 100/15855, Loss: 5.5596\n",
            "Epoch 4/8, Batch 150/15855, Loss: 5.7788\n",
            "Epoch 4/8, Batch 200/15855, Loss: 5.3111\n",
            "Epoch 4/8, Batch 250/15855, Loss: 4.0191\n",
            "Epoch 4/8, Batch 300/15855, Loss: 5.0502\n",
            "Epoch 4/8, Batch 350/15855, Loss: 5.5188\n",
            "Epoch 4/8, Batch 400/15855, Loss: 6.0449\n",
            "Epoch 4/8, Batch 450/15855, Loss: 4.3754\n",
            "Epoch 4/8, Batch 500/15855, Loss: 5.3048\n",
            "Epoch 4/8, Batch 550/15855, Loss: 5.3387\n",
            "Epoch 4/8, Batch 600/15855, Loss: 5.6477\n",
            "Epoch 4/8, Batch 650/15855, Loss: 5.3831\n",
            "Epoch 4/8, Batch 700/15855, Loss: 5.8396\n",
            "Epoch 4/8, Batch 750/15855, Loss: 5.6629\n",
            "Epoch 4/8, Batch 800/15855, Loss: 5.5021\n",
            "Epoch 4/8, Batch 850/15855, Loss: 5.5316\n",
            "Epoch 4/8, Batch 900/15855, Loss: 4.4693\n",
            "Epoch 4/8, Batch 950/15855, Loss: 5.5132\n",
            "Epoch 4/8, Batch 1000/15855, Loss: 4.9016\n",
            "Epoch 4/8, Batch 1050/15855, Loss: 4.6941\n",
            "Epoch 4/8, Batch 1100/15855, Loss: 5.1661\n",
            "Epoch 4/8, Batch 1150/15855, Loss: 5.0242\n",
            "Epoch 4/8, Batch 1200/15855, Loss: 5.2708\n",
            "Epoch 4/8, Batch 1250/15855, Loss: 4.8269\n",
            "Epoch 4/8, Batch 1300/15855, Loss: 5.3603\n",
            "Epoch 4/8, Batch 1350/15855, Loss: 5.8635\n",
            "Epoch 4/8, Batch 1400/15855, Loss: 5.8350\n",
            "Epoch 4/8, Batch 1450/15855, Loss: 4.9975\n",
            "Epoch 4/8, Batch 1500/15855, Loss: 5.9738\n",
            "Epoch 4/8, Batch 1550/15855, Loss: 4.7445\n",
            "Epoch 4/8, Batch 1600/15855, Loss: 5.1241\n",
            "Epoch 4/8, Batch 1650/15855, Loss: 5.0599\n",
            "Epoch 4/8, Batch 1700/15855, Loss: 5.6240\n",
            "Epoch 4/8, Batch 1750/15855, Loss: 5.0392\n",
            "Epoch 4/8, Batch 1800/15855, Loss: 5.5614\n",
            "Epoch 4/8, Batch 1850/15855, Loss: 5.0079\n",
            "Epoch 4/8, Batch 1900/15855, Loss: 6.5774\n",
            "Epoch 4/8, Batch 1950/15855, Loss: 4.8867\n",
            "Epoch 4/8, Batch 2000/15855, Loss: 5.0362\n",
            "Epoch 4/8, Batch 2050/15855, Loss: 6.0778\n",
            "Epoch 4/8, Batch 2100/15855, Loss: 4.8302\n",
            "Epoch 4/8, Batch 2150/15855, Loss: 5.1972\n",
            "Epoch 4/8, Batch 2200/15855, Loss: 5.0188\n",
            "Epoch 4/8, Batch 2250/15855, Loss: 5.5243\n",
            "Epoch 4/8, Batch 2300/15855, Loss: 4.8488\n",
            "Epoch 4/8, Batch 2350/15855, Loss: 5.2307\n",
            "Epoch 4/8, Batch 2400/15855, Loss: 4.9055\n",
            "Epoch 4/8, Batch 2450/15855, Loss: 5.0038\n",
            "Epoch 4/8, Batch 2500/15855, Loss: 5.0261\n",
            "Epoch 4/8, Batch 2550/15855, Loss: 4.7714\n",
            "Epoch 4/8, Batch 2600/15855, Loss: 5.5791\n",
            "Epoch 4/8, Batch 2650/15855, Loss: 5.4829\n",
            "Epoch 4/8, Batch 2700/15855, Loss: 5.0511\n",
            "Epoch 4/8, Batch 2750/15855, Loss: 5.0724\n",
            "Epoch 4/8, Batch 2800/15855, Loss: 5.0673\n",
            "Epoch 4/8, Batch 2850/15855, Loss: 5.5183\n",
            "Epoch 4/8, Batch 2900/15855, Loss: 5.6825\n",
            "Epoch 4/8, Batch 2950/15855, Loss: 5.6813\n",
            "Epoch 4/8, Batch 3000/15855, Loss: 5.3024\n",
            "Epoch 4/8, Batch 3050/15855, Loss: 5.0418\n",
            "Epoch 4/8, Batch 3100/15855, Loss: 5.5030\n",
            "Epoch 4/8, Batch 3150/15855, Loss: 5.5695\n",
            "Epoch 4/8, Batch 3200/15855, Loss: 5.9318\n",
            "Epoch 4/8, Batch 3250/15855, Loss: 5.6761\n",
            "Epoch 4/8, Batch 3300/15855, Loss: 5.1782\n",
            "Epoch 4/8, Batch 3350/15855, Loss: 4.5447\n",
            "Epoch 4/8, Batch 3400/15855, Loss: 5.5999\n",
            "Epoch 4/8, Batch 3450/15855, Loss: 4.7835\n",
            "Epoch 4/8, Batch 3500/15855, Loss: 4.7537\n",
            "Epoch 4/8, Batch 3550/15855, Loss: 5.7432\n",
            "Epoch 4/8, Batch 3600/15855, Loss: 4.8716\n",
            "Epoch 4/8, Batch 3650/15855, Loss: 5.4853\n",
            "Epoch 4/8, Batch 3700/15855, Loss: 5.4132\n",
            "Epoch 4/8, Batch 3750/15855, Loss: 5.2804\n",
            "Epoch 4/8, Batch 3800/15855, Loss: 5.2172\n",
            "Epoch 4/8, Batch 3850/15855, Loss: 4.9139\n",
            "Epoch 4/8, Batch 3900/15855, Loss: 5.0259\n",
            "Epoch 4/8, Batch 3950/15855, Loss: 5.1292\n",
            "Epoch 4/8, Batch 4000/15855, Loss: 5.8575\n",
            "Epoch 4/8, Batch 4050/15855, Loss: 5.4590\n",
            "Epoch 4/8, Batch 4100/15855, Loss: 5.5678\n",
            "Epoch 4/8, Batch 4150/15855, Loss: 5.5492\n",
            "Epoch 4/8, Batch 4200/15855, Loss: 4.4114\n",
            "Epoch 4/8, Batch 4250/15855, Loss: 5.0715\n",
            "Epoch 4/8, Batch 4300/15855, Loss: 5.6862\n",
            "Epoch 4/8, Batch 4350/15855, Loss: 5.4982\n",
            "Epoch 4/8, Batch 4400/15855, Loss: 5.7720\n",
            "Epoch 4/8, Batch 4450/15855, Loss: 5.1641\n",
            "Epoch 4/8, Batch 4500/15855, Loss: 5.5949\n",
            "Epoch 4/8, Batch 4550/15855, Loss: 4.9890\n",
            "Epoch 4/8, Batch 4600/15855, Loss: 5.7834\n",
            "Epoch 4/8, Batch 4650/15855, Loss: 5.2648\n",
            "Epoch 4/8, Batch 4700/15855, Loss: 5.9688\n",
            "Epoch 4/8, Batch 4750/15855, Loss: 4.8465\n",
            "Epoch 4/8, Batch 4800/15855, Loss: 5.3431\n",
            "Epoch 4/8, Batch 4850/15855, Loss: 5.7036\n",
            "Epoch 4/8, Batch 4900/15855, Loss: 5.1270\n",
            "Epoch 4/8, Batch 4950/15855, Loss: 5.4815\n",
            "Epoch 4/8, Batch 5000/15855, Loss: 5.0885\n",
            "Epoch 4/8, Batch 5050/15855, Loss: 4.9814\n",
            "Epoch 4/8, Batch 5100/15855, Loss: 4.7908\n",
            "Epoch 4/8, Batch 5150/15855, Loss: 5.5625\n",
            "Epoch 4/8, Batch 5200/15855, Loss: 4.4740\n",
            "Epoch 4/8, Batch 5250/15855, Loss: 5.2124\n",
            "Epoch 4/8, Batch 5300/15855, Loss: 4.0368\n",
            "Epoch 4/8, Batch 5350/15855, Loss: 5.2804\n",
            "Epoch 4/8, Batch 5400/15855, Loss: 5.8190\n",
            "Epoch 4/8, Batch 5450/15855, Loss: 5.3460\n",
            "Epoch 4/8, Batch 5500/15855, Loss: 4.3894\n",
            "Epoch 4/8, Batch 5550/15855, Loss: 5.9153\n",
            "Epoch 4/8, Batch 5600/15855, Loss: 4.9838\n",
            "Epoch 4/8, Batch 5650/15855, Loss: 5.0514\n",
            "Epoch 4/8, Batch 5700/15855, Loss: 4.9591\n",
            "Epoch 4/8, Batch 5750/15855, Loss: 5.2743\n",
            "Epoch 4/8, Batch 5800/15855, Loss: 5.6141\n",
            "Epoch 4/8, Batch 5850/15855, Loss: 5.8229\n",
            "Epoch 4/8, Batch 5900/15855, Loss: 5.4669\n",
            "Epoch 4/8, Batch 5950/15855, Loss: 5.3756\n",
            "Epoch 4/8, Batch 6000/15855, Loss: 5.4163\n",
            "Epoch 4/8, Batch 6050/15855, Loss: 5.5807\n",
            "Epoch 4/8, Batch 6100/15855, Loss: 5.6765\n",
            "Epoch 4/8, Batch 6150/15855, Loss: 4.6765\n",
            "Epoch 4/8, Batch 6200/15855, Loss: 5.3715\n",
            "Epoch 4/8, Batch 6250/15855, Loss: 4.6732\n",
            "Epoch 4/8, Batch 6300/15855, Loss: 4.9579\n",
            "Epoch 4/8, Batch 6350/15855, Loss: 4.9750\n",
            "Epoch 4/8, Batch 6400/15855, Loss: 4.1422\n",
            "Epoch 4/8, Batch 6450/15855, Loss: 5.1968\n",
            "Epoch 4/8, Batch 6500/15855, Loss: 4.9763\n",
            "Epoch 4/8, Batch 6550/15855, Loss: 4.8076\n",
            "Epoch 4/8, Batch 6600/15855, Loss: 5.2745\n",
            "Epoch 4/8, Batch 6650/15855, Loss: 5.2253\n",
            "Epoch 4/8, Batch 6700/15855, Loss: 4.8833\n",
            "Epoch 4/8, Batch 6750/15855, Loss: 5.1728\n",
            "Epoch 4/8, Batch 6800/15855, Loss: 4.8979\n",
            "Epoch 4/8, Batch 6850/15855, Loss: 4.3239\n",
            "Epoch 4/8, Batch 6900/15855, Loss: 5.6144\n",
            "Epoch 4/8, Batch 6950/15855, Loss: 6.0705\n",
            "Epoch 4/8, Batch 7000/15855, Loss: 5.4945\n",
            "Epoch 4/8, Batch 7050/15855, Loss: 4.8808\n",
            "Epoch 4/8, Batch 7100/15855, Loss: 4.8470\n",
            "Epoch 4/8, Batch 7150/15855, Loss: 5.4318\n",
            "Epoch 4/8, Batch 7200/15855, Loss: 6.0199\n",
            "Epoch 4/8, Batch 7250/15855, Loss: 5.6113\n",
            "Epoch 4/8, Batch 7300/15855, Loss: 5.1783\n",
            "Epoch 4/8, Batch 7350/15855, Loss: 4.9282\n",
            "Epoch 4/8, Batch 7400/15855, Loss: 4.7882\n",
            "Epoch 4/8, Batch 7450/15855, Loss: 5.2499\n",
            "Epoch 4/8, Batch 7500/15855, Loss: 5.4735\n",
            "Epoch 4/8, Batch 7550/15855, Loss: 5.2165\n",
            "Epoch 4/8, Batch 7600/15855, Loss: 4.8840\n",
            "Epoch 4/8, Batch 7650/15855, Loss: 6.0412\n",
            "Epoch 4/8, Batch 7700/15855, Loss: 5.2844\n",
            "Epoch 4/8, Batch 7750/15855, Loss: 5.4068\n",
            "Epoch 4/8, Batch 7800/15855, Loss: 5.2958\n",
            "Epoch 4/8, Batch 7850/15855, Loss: 4.9081\n",
            "Epoch 4/8, Batch 7900/15855, Loss: 5.3849\n",
            "Epoch 4/8, Batch 7950/15855, Loss: 4.8924\n",
            "Epoch 4/8, Batch 8000/15855, Loss: 5.8564\n",
            "Epoch 4/8, Batch 8050/15855, Loss: 4.9823\n",
            "Epoch 4/8, Batch 8100/15855, Loss: 5.3871\n",
            "Epoch 4/8, Batch 8150/15855, Loss: 5.2846\n",
            "Epoch 4/8, Batch 8200/15855, Loss: 5.4271\n",
            "Epoch 4/8, Batch 8250/15855, Loss: 4.8649\n",
            "Epoch 4/8, Batch 8300/15855, Loss: 4.7090\n",
            "Epoch 4/8, Batch 8350/15855, Loss: 4.9726\n",
            "Epoch 4/8, Batch 8400/15855, Loss: 5.0370\n",
            "Epoch 4/8, Batch 8450/15855, Loss: 5.8836\n",
            "Epoch 4/8, Batch 8500/15855, Loss: 5.5314\n",
            "Epoch 4/8, Batch 8550/15855, Loss: 5.7260\n",
            "Epoch 4/8, Batch 8600/15855, Loss: 5.2990\n",
            "Epoch 4/8, Batch 8650/15855, Loss: 5.2190\n",
            "Epoch 4/8, Batch 8700/15855, Loss: 5.1930\n",
            "Epoch 4/8, Batch 8750/15855, Loss: 4.5014\n",
            "Epoch 4/8, Batch 8800/15855, Loss: 6.0064\n",
            "Epoch 4/8, Batch 8850/15855, Loss: 5.7707\n",
            "Epoch 4/8, Batch 8900/15855, Loss: 5.4343\n",
            "Epoch 4/8, Batch 8950/15855, Loss: 5.1301\n",
            "Epoch 4/8, Batch 9000/15855, Loss: 6.3185\n",
            "Epoch 4/8, Batch 9050/15855, Loss: 5.1261\n",
            "Epoch 4/8, Batch 9100/15855, Loss: 4.9158\n",
            "Epoch 4/8, Batch 9150/15855, Loss: 5.0811\n",
            "Epoch 4/8, Batch 9200/15855, Loss: 5.0470\n",
            "Epoch 4/8, Batch 9250/15855, Loss: 5.1486\n",
            "Epoch 4/8, Batch 9300/15855, Loss: 5.0940\n",
            "Epoch 4/8, Batch 9350/15855, Loss: 5.2673\n",
            "Epoch 4/8, Batch 9400/15855, Loss: 5.1371\n",
            "Epoch 4/8, Batch 9450/15855, Loss: 4.7028\n",
            "Epoch 4/8, Batch 9500/15855, Loss: 5.5829\n",
            "Epoch 4/8, Batch 9550/15855, Loss: 5.2849\n",
            "Epoch 4/8, Batch 9600/15855, Loss: 6.0474\n",
            "Epoch 4/8, Batch 9650/15855, Loss: 5.7319\n",
            "Epoch 4/8, Batch 9700/15855, Loss: 6.3475\n",
            "Epoch 4/8, Batch 9750/15855, Loss: 5.1516\n",
            "Epoch 4/8, Batch 9800/15855, Loss: 5.2660\n",
            "Epoch 4/8, Batch 9850/15855, Loss: 4.7001\n",
            "Epoch 4/8, Batch 9900/15855, Loss: 5.7279\n",
            "Epoch 4/8, Batch 9950/15855, Loss: 5.2371\n",
            "Epoch 4/8, Batch 10000/15855, Loss: 5.1456\n",
            "Epoch 4/8, Batch 10050/15855, Loss: 5.6546\n",
            "Epoch 4/8, Batch 10100/15855, Loss: 4.9078\n",
            "Epoch 4/8, Batch 10150/15855, Loss: 5.3711\n",
            "Epoch 4/8, Batch 10200/15855, Loss: 5.1723\n",
            "Epoch 4/8, Batch 10250/15855, Loss: 5.7144\n",
            "Epoch 4/8, Batch 10300/15855, Loss: 4.4764\n",
            "Epoch 4/8, Batch 10350/15855, Loss: 5.4597\n",
            "Epoch 4/8, Batch 10400/15855, Loss: 4.9250\n",
            "Epoch 4/8, Batch 10450/15855, Loss: 5.3796\n",
            "Epoch 4/8, Batch 10500/15855, Loss: 6.1853\n",
            "Epoch 4/8, Batch 10550/15855, Loss: 5.0366\n",
            "Epoch 4/8, Batch 10600/15855, Loss: 4.9333\n",
            "Epoch 4/8, Batch 10650/15855, Loss: 4.4914\n",
            "Epoch 4/8, Batch 10700/15855, Loss: 4.9171\n",
            "Epoch 4/8, Batch 10750/15855, Loss: 5.5690\n",
            "Epoch 4/8, Batch 10800/15855, Loss: 6.0275\n",
            "Epoch 4/8, Batch 10850/15855, Loss: 5.5723\n",
            "Epoch 4/8, Batch 10900/15855, Loss: 4.7369\n",
            "Epoch 4/8, Batch 10950/15855, Loss: 4.5415\n",
            "Epoch 4/8, Batch 11000/15855, Loss: 5.7003\n",
            "Epoch 4/8, Batch 11050/15855, Loss: 5.3930\n",
            "Epoch 4/8, Batch 11100/15855, Loss: 5.0402\n",
            "Epoch 4/8, Batch 11150/15855, Loss: 4.8175\n",
            "Epoch 4/8, Batch 11200/15855, Loss: 4.5907\n",
            "Epoch 4/8, Batch 11250/15855, Loss: 5.4290\n",
            "Epoch 4/8, Batch 11300/15855, Loss: 4.8015\n",
            "Epoch 4/8, Batch 11350/15855, Loss: 5.0735\n",
            "Epoch 4/8, Batch 11400/15855, Loss: 6.0460\n",
            "Epoch 4/8, Batch 11450/15855, Loss: 5.3524\n",
            "Epoch 4/8, Batch 11500/15855, Loss: 5.0820\n",
            "Epoch 4/8, Batch 11550/15855, Loss: 4.8709\n",
            "Epoch 4/8, Batch 11600/15855, Loss: 5.1172\n",
            "Epoch 4/8, Batch 11650/15855, Loss: 5.7516\n",
            "Epoch 4/8, Batch 11700/15855, Loss: 4.9895\n",
            "Epoch 4/8, Batch 11750/15855, Loss: 5.0536\n",
            "Epoch 4/8, Batch 11800/15855, Loss: 5.1541\n",
            "Epoch 4/8, Batch 11850/15855, Loss: 5.8448\n",
            "Epoch 4/8, Batch 11900/15855, Loss: 5.3165\n",
            "Epoch 4/8, Batch 11950/15855, Loss: 5.2253\n",
            "Epoch 4/8, Batch 12000/15855, Loss: 5.3289\n",
            "Epoch 4/8, Batch 12050/15855, Loss: 5.9387\n",
            "Epoch 4/8, Batch 12100/15855, Loss: 4.3669\n",
            "Epoch 4/8, Batch 12150/15855, Loss: 5.4049\n",
            "Epoch 4/8, Batch 12200/15855, Loss: 5.4162\n",
            "Epoch 4/8, Batch 12250/15855, Loss: 5.6192\n",
            "Epoch 4/8, Batch 12300/15855, Loss: 5.6258\n",
            "Epoch 4/8, Batch 12350/15855, Loss: 4.6926\n",
            "Epoch 4/8, Batch 12400/15855, Loss: 5.0711\n",
            "Epoch 4/8, Batch 12450/15855, Loss: 5.3710\n",
            "Epoch 4/8, Batch 12500/15855, Loss: 4.9366\n",
            "Epoch 4/8, Batch 12550/15855, Loss: 4.7746\n",
            "Epoch 4/8, Batch 12600/15855, Loss: 5.0993\n",
            "Epoch 4/8, Batch 12650/15855, Loss: 4.9324\n",
            "Epoch 4/8, Batch 12700/15855, Loss: 5.4953\n",
            "Epoch 4/8, Batch 12750/15855, Loss: 5.4042\n",
            "Epoch 4/8, Batch 12800/15855, Loss: 5.7605\n",
            "Epoch 4/8, Batch 12850/15855, Loss: 5.9806\n",
            "Epoch 4/8, Batch 12900/15855, Loss: 4.4559\n",
            "Epoch 4/8, Batch 12950/15855, Loss: 4.9589\n",
            "Epoch 4/8, Batch 13000/15855, Loss: 5.8082\n",
            "Epoch 4/8, Batch 13050/15855, Loss: 5.8194\n",
            "Epoch 4/8, Batch 13100/15855, Loss: 4.8705\n",
            "Epoch 4/8, Batch 13150/15855, Loss: 5.6821\n",
            "Epoch 4/8, Batch 13200/15855, Loss: 5.1519\n",
            "Epoch 4/8, Batch 13250/15855, Loss: 4.7771\n",
            "Epoch 4/8, Batch 13300/15855, Loss: 4.9873\n",
            "Epoch 4/8, Batch 13350/15855, Loss: 4.8899\n",
            "Epoch 4/8, Batch 13400/15855, Loss: 5.1610\n",
            "Epoch 4/8, Batch 13450/15855, Loss: 5.7647\n",
            "Epoch 4/8, Batch 13500/15855, Loss: 5.2202\n",
            "Epoch 4/8, Batch 13550/15855, Loss: 5.3246\n",
            "Epoch 4/8, Batch 13600/15855, Loss: 5.2013\n",
            "Epoch 4/8, Batch 13650/15855, Loss: 5.4912\n",
            "Epoch 4/8, Batch 13700/15855, Loss: 5.4423\n",
            "Epoch 4/8, Batch 13750/15855, Loss: 5.1638\n",
            "Epoch 4/8, Batch 13800/15855, Loss: 4.9605\n",
            "Epoch 4/8, Batch 13850/15855, Loss: 6.1267\n",
            "Epoch 4/8, Batch 13900/15855, Loss: 5.8587\n",
            "Epoch 4/8, Batch 13950/15855, Loss: 5.8060\n",
            "Epoch 4/8, Batch 14000/15855, Loss: 5.3967\n",
            "Epoch 4/8, Batch 14050/15855, Loss: 5.1815\n",
            "Epoch 4/8, Batch 14100/15855, Loss: 5.4622\n",
            "Epoch 4/8, Batch 14150/15855, Loss: 5.0445\n",
            "Epoch 4/8, Batch 14200/15855, Loss: 5.5537\n",
            "Epoch 4/8, Batch 14250/15855, Loss: 5.5055\n",
            "Epoch 4/8, Batch 14300/15855, Loss: 5.4747\n",
            "Epoch 4/8, Batch 14350/15855, Loss: 5.4316\n",
            "Epoch 4/8, Batch 14400/15855, Loss: 5.2996\n",
            "Epoch 4/8, Batch 14450/15855, Loss: 5.6775\n",
            "Epoch 4/8, Batch 14500/15855, Loss: 5.1187\n",
            "Epoch 4/8, Batch 14550/15855, Loss: 5.3692\n",
            "Epoch 4/8, Batch 14600/15855, Loss: 5.5030\n",
            "Epoch 4/8, Batch 14650/15855, Loss: 5.8223\n",
            "Epoch 4/8, Batch 14700/15855, Loss: 4.7431\n",
            "Epoch 4/8, Batch 14750/15855, Loss: 5.4060\n",
            "Epoch 4/8, Batch 14800/15855, Loss: 5.4446\n",
            "Epoch 4/8, Batch 14850/15855, Loss: 4.4688\n",
            "Epoch 4/8, Batch 14900/15855, Loss: 5.6586\n",
            "Epoch 4/8, Batch 14950/15855, Loss: 5.6920\n",
            "Epoch 4/8, Batch 15000/15855, Loss: 4.9362\n",
            "Epoch 4/8, Batch 15050/15855, Loss: 5.2552\n",
            "Epoch 4/8, Batch 15100/15855, Loss: 5.3582\n",
            "Epoch 4/8, Batch 15150/15855, Loss: 5.5219\n",
            "Epoch 4/8, Batch 15200/15855, Loss: 4.8246\n",
            "Epoch 4/8, Batch 15250/15855, Loss: 4.8745\n",
            "Epoch 4/8, Batch 15300/15855, Loss: 6.3312\n",
            "Epoch 4/8, Batch 15350/15855, Loss: 5.6533\n",
            "Epoch 4/8, Batch 15400/15855, Loss: 5.4980\n",
            "Epoch 4/8, Batch 15450/15855, Loss: 5.0079\n",
            "Epoch 4/8, Batch 15500/15855, Loss: 6.0176\n",
            "Epoch 4/8, Batch 15550/15855, Loss: 5.5470\n",
            "Epoch 4/8, Batch 15600/15855, Loss: 4.7106\n",
            "Epoch 4/8, Batch 15650/15855, Loss: 5.4076\n",
            "Epoch 4/8, Batch 15700/15855, Loss: 4.8074\n",
            "Epoch 4/8, Batch 15750/15855, Loss: 5.9376\n",
            "Epoch 4/8, Batch 15800/15855, Loss: 5.7833\n",
            "Epoch 4/8, Batch 15850/15855, Loss: 5.6033\n",
            "Epoch 4/8 - Train Loss: 5.2608, Val Loss: 5.2084\n",
            "Exemple g√©n√©r√©: \"harry was doing that it didn't be that he had been able to make out the attempt to hear him.\"\n",
            "\n",
            "Epoch 5/8, Batch 0/15855, Loss: 4.9285\n",
            "Epoch 5/8, Batch 50/15855, Loss: 4.9770\n",
            "Epoch 5/8, Batch 100/15855, Loss: 4.8467\n",
            "Epoch 5/8, Batch 150/15855, Loss: 5.5238\n",
            "Epoch 5/8, Batch 200/15855, Loss: 4.7995\n",
            "Epoch 5/8, Batch 250/15855, Loss: 5.2573\n",
            "Epoch 5/8, Batch 300/15855, Loss: 5.7894\n",
            "Epoch 5/8, Batch 350/15855, Loss: 5.1210\n",
            "Epoch 5/8, Batch 400/15855, Loss: 4.5000\n",
            "Epoch 5/8, Batch 450/15855, Loss: 5.0316\n",
            "Epoch 5/8, Batch 500/15855, Loss: 5.2472\n",
            "Epoch 5/8, Batch 550/15855, Loss: 5.3780\n",
            "Epoch 5/8, Batch 600/15855, Loss: 5.3410\n",
            "Epoch 5/8, Batch 650/15855, Loss: 4.9736\n",
            "Epoch 5/8, Batch 700/15855, Loss: 4.8012\n",
            "Epoch 5/8, Batch 750/15855, Loss: 4.6862\n",
            "Epoch 5/8, Batch 800/15855, Loss: 4.8914\n",
            "Epoch 5/8, Batch 850/15855, Loss: 4.9307\n",
            "Epoch 5/8, Batch 900/15855, Loss: 5.4187\n",
            "Epoch 5/8, Batch 950/15855, Loss: 5.0187\n",
            "Epoch 5/8, Batch 1000/15855, Loss: 4.7018\n",
            "Epoch 5/8, Batch 1050/15855, Loss: 4.6989\n",
            "Epoch 5/8, Batch 1100/15855, Loss: 4.9217\n",
            "Epoch 5/8, Batch 1150/15855, Loss: 4.8279\n",
            "Epoch 5/8, Batch 1200/15855, Loss: 5.5028\n",
            "Epoch 5/8, Batch 1250/15855, Loss: 5.2121\n",
            "Epoch 5/8, Batch 1300/15855, Loss: 5.3484\n",
            "Epoch 5/8, Batch 1350/15855, Loss: 4.7673\n",
            "Epoch 5/8, Batch 1400/15855, Loss: 5.1838\n",
            "Epoch 5/8, Batch 1450/15855, Loss: 4.8544\n",
            "Epoch 5/8, Batch 1500/15855, Loss: 5.0696\n",
            "Epoch 5/8, Batch 1550/15855, Loss: 4.8041\n",
            "Epoch 5/8, Batch 1600/15855, Loss: 5.3049\n",
            "Epoch 5/8, Batch 1650/15855, Loss: 4.6581\n",
            "Epoch 5/8, Batch 1700/15855, Loss: 4.6654\n",
            "Epoch 5/8, Batch 1750/15855, Loss: 5.4135\n",
            "Epoch 5/8, Batch 1800/15855, Loss: 5.7997\n",
            "Epoch 5/8, Batch 1850/15855, Loss: 5.9754\n",
            "Epoch 5/8, Batch 1900/15855, Loss: 5.6384\n",
            "Epoch 5/8, Batch 1950/15855, Loss: 4.3942\n",
            "Epoch 5/8, Batch 2000/15855, Loss: 4.8749\n",
            "Epoch 5/8, Batch 2050/15855, Loss: 5.1419\n",
            "Epoch 5/8, Batch 2100/15855, Loss: 5.2757\n",
            "Epoch 5/8, Batch 2150/15855, Loss: 5.2708\n",
            "Epoch 5/8, Batch 2200/15855, Loss: 5.1222\n",
            "Epoch 5/8, Batch 2250/15855, Loss: 4.9737\n",
            "Epoch 5/8, Batch 2300/15855, Loss: 5.2751\n",
            "Epoch 5/8, Batch 2350/15855, Loss: 5.6002\n",
            "Epoch 5/8, Batch 2400/15855, Loss: 5.0394\n",
            "Epoch 5/8, Batch 2450/15855, Loss: 4.7097\n",
            "Epoch 5/8, Batch 2500/15855, Loss: 4.8641\n",
            "Epoch 5/8, Batch 2550/15855, Loss: 5.5781\n",
            "Epoch 5/8, Batch 2600/15855, Loss: 4.7651\n",
            "Epoch 5/8, Batch 2650/15855, Loss: 5.6140\n",
            "Epoch 5/8, Batch 2700/15855, Loss: 4.8151\n",
            "Epoch 5/8, Batch 2750/15855, Loss: 5.9661\n",
            "Epoch 5/8, Batch 2800/15855, Loss: 4.7512\n",
            "Epoch 5/8, Batch 2850/15855, Loss: 4.6071\n",
            "Epoch 5/8, Batch 2900/15855, Loss: 4.9290\n",
            "Epoch 5/8, Batch 2950/15855, Loss: 5.2817\n",
            "Epoch 5/8, Batch 3000/15855, Loss: 4.5596\n",
            "Epoch 5/8, Batch 3050/15855, Loss: 4.6482\n",
            "Epoch 5/8, Batch 3100/15855, Loss: 5.7456\n",
            "Epoch 5/8, Batch 3150/15855, Loss: 5.6345\n",
            "Epoch 5/8, Batch 3200/15855, Loss: 5.0721\n",
            "Epoch 5/8, Batch 3250/15855, Loss: 4.4051\n",
            "Epoch 5/8, Batch 3300/15855, Loss: 5.0273\n",
            "Epoch 5/8, Batch 3350/15855, Loss: 5.4731\n",
            "Epoch 5/8, Batch 3400/15855, Loss: 4.8479\n",
            "Epoch 5/8, Batch 3450/15855, Loss: 5.2503\n",
            "Epoch 5/8, Batch 3500/15855, Loss: 5.7560\n",
            "Epoch 5/8, Batch 3550/15855, Loss: 4.4310\n",
            "Epoch 5/8, Batch 3600/15855, Loss: 5.2033\n",
            "Epoch 5/8, Batch 3650/15855, Loss: 4.8058\n",
            "Epoch 5/8, Batch 3700/15855, Loss: 4.7736\n",
            "Epoch 5/8, Batch 3750/15855, Loss: 5.2883\n",
            "Epoch 5/8, Batch 3800/15855, Loss: 4.9914\n",
            "Epoch 5/8, Batch 3850/15855, Loss: 5.3180\n",
            "Epoch 5/8, Batch 3900/15855, Loss: 5.5876\n",
            "Epoch 5/8, Batch 3950/15855, Loss: 4.8582\n",
            "Epoch 5/8, Batch 4000/15855, Loss: 4.6188\n",
            "Epoch 5/8, Batch 4050/15855, Loss: 5.0628\n",
            "Epoch 5/8, Batch 4100/15855, Loss: 5.5357\n",
            "Epoch 5/8, Batch 4150/15855, Loss: 4.7700\n",
            "Epoch 5/8, Batch 4200/15855, Loss: 4.9920\n",
            "Epoch 5/8, Batch 4250/15855, Loss: 5.4200\n",
            "Epoch 5/8, Batch 4300/15855, Loss: 4.8276\n",
            "Epoch 5/8, Batch 4350/15855, Loss: 4.9714\n",
            "Epoch 5/8, Batch 4400/15855, Loss: 4.7369\n",
            "Epoch 5/8, Batch 4450/15855, Loss: 5.1126\n",
            "Epoch 5/8, Batch 4500/15855, Loss: 5.5319\n",
            "Epoch 5/8, Batch 4550/15855, Loss: 5.0554\n",
            "Epoch 5/8, Batch 4600/15855, Loss: 4.4666\n",
            "Epoch 5/8, Batch 4650/15855, Loss: 5.0393\n",
            "Epoch 5/8, Batch 4700/15855, Loss: 5.5509\n",
            "Epoch 5/8, Batch 4750/15855, Loss: 4.9424\n",
            "Epoch 5/8, Batch 4800/15855, Loss: 5.2651\n",
            "Epoch 5/8, Batch 4850/15855, Loss: 5.0946\n",
            "Epoch 5/8, Batch 4900/15855, Loss: 4.8394\n",
            "Epoch 5/8, Batch 4950/15855, Loss: 4.9940\n",
            "Epoch 5/8, Batch 5000/15855, Loss: 5.6557\n",
            "Epoch 5/8, Batch 5050/15855, Loss: 5.2774\n",
            "Epoch 5/8, Batch 5100/15855, Loss: 4.7214\n",
            "Epoch 5/8, Batch 5150/15855, Loss: 5.4083\n",
            "Epoch 5/8, Batch 5200/15855, Loss: 4.8496\n",
            "Epoch 5/8, Batch 5250/15855, Loss: 4.9562\n",
            "Epoch 5/8, Batch 5300/15855, Loss: 4.5893\n",
            "Epoch 5/8, Batch 5350/15855, Loss: 5.8308\n",
            "Epoch 5/8, Batch 5400/15855, Loss: 5.6503\n",
            "Epoch 5/8, Batch 5450/15855, Loss: 5.0725\n",
            "Epoch 5/8, Batch 5500/15855, Loss: 4.8633\n",
            "Epoch 5/8, Batch 5550/15855, Loss: 5.3934\n",
            "Epoch 5/8, Batch 5600/15855, Loss: 5.0075\n",
            "Epoch 5/8, Batch 5650/15855, Loss: 5.0470\n",
            "Epoch 5/8, Batch 5700/15855, Loss: 5.0457\n",
            "Epoch 5/8, Batch 5750/15855, Loss: 4.8944\n",
            "Epoch 5/8, Batch 5800/15855, Loss: 4.8641\n",
            "Epoch 5/8, Batch 5850/15855, Loss: 5.0159\n",
            "Epoch 5/8, Batch 5900/15855, Loss: 5.0790\n",
            "Epoch 5/8, Batch 5950/15855, Loss: 4.4743\n",
            "Epoch 5/8, Batch 6000/15855, Loss: 4.9050\n",
            "Epoch 5/8, Batch 6050/15855, Loss: 5.6075\n",
            "Epoch 5/8, Batch 6100/15855, Loss: 5.0279\n",
            "Epoch 5/8, Batch 6150/15855, Loss: 4.3789\n",
            "Epoch 5/8, Batch 6200/15855, Loss: 5.3082\n",
            "Epoch 5/8, Batch 6250/15855, Loss: 5.0005\n",
            "Epoch 5/8, Batch 6300/15855, Loss: 5.2773\n",
            "Epoch 5/8, Batch 6350/15855, Loss: 5.2431\n",
            "Epoch 5/8, Batch 6400/15855, Loss: 5.9264\n",
            "Epoch 5/8, Batch 6450/15855, Loss: 5.5818\n",
            "Epoch 5/8, Batch 6500/15855, Loss: 5.0170\n",
            "Epoch 5/8, Batch 6550/15855, Loss: 5.1888\n",
            "Epoch 5/8, Batch 6600/15855, Loss: 5.6476\n",
            "Epoch 5/8, Batch 6650/15855, Loss: 5.6650\n",
            "Epoch 5/8, Batch 6700/15855, Loss: 4.9526\n",
            "Epoch 5/8, Batch 6750/15855, Loss: 4.9045\n",
            "Epoch 5/8, Batch 6800/15855, Loss: 5.0828\n",
            "Epoch 5/8, Batch 6850/15855, Loss: 5.1312\n",
            "Epoch 5/8, Batch 6900/15855, Loss: 4.8601\n",
            "Epoch 5/8, Batch 6950/15855, Loss: 5.3027\n",
            "Epoch 5/8, Batch 7000/15855, Loss: 5.1560\n",
            "Epoch 5/8, Batch 7050/15855, Loss: 5.5336\n",
            "Epoch 5/8, Batch 7100/15855, Loss: 4.5446\n",
            "Epoch 5/8, Batch 7150/15855, Loss: 4.9040\n",
            "Epoch 5/8, Batch 7200/15855, Loss: 5.0155\n",
            "Epoch 5/8, Batch 7250/15855, Loss: 5.0046\n",
            "Epoch 5/8, Batch 7300/15855, Loss: 5.4964\n",
            "Epoch 5/8, Batch 7350/15855, Loss: 4.7997\n",
            "Epoch 5/8, Batch 7400/15855, Loss: 5.4611\n",
            "Epoch 5/8, Batch 7450/15855, Loss: 5.8389\n",
            "Epoch 5/8, Batch 7500/15855, Loss: 5.9674\n",
            "Epoch 5/8, Batch 7550/15855, Loss: 4.9428\n",
            "Epoch 5/8, Batch 7600/15855, Loss: 4.9040\n",
            "Epoch 5/8, Batch 7650/15855, Loss: 5.1451\n",
            "Epoch 5/8, Batch 7700/15855, Loss: 4.6175\n",
            "Epoch 5/8, Batch 7750/15855, Loss: 5.0506\n",
            "Epoch 5/8, Batch 7800/15855, Loss: 5.3262\n",
            "Epoch 5/8, Batch 7850/15855, Loss: 5.1697\n",
            "Epoch 5/8, Batch 7900/15855, Loss: 4.7326\n",
            "Epoch 5/8, Batch 7950/15855, Loss: 5.0903\n",
            "Epoch 5/8, Batch 8000/15855, Loss: 5.3299\n",
            "Epoch 5/8, Batch 8050/15855, Loss: 4.9829\n",
            "Epoch 5/8, Batch 8100/15855, Loss: 4.6699\n",
            "Epoch 5/8, Batch 8150/15855, Loss: 5.1648\n",
            "Epoch 5/8, Batch 8200/15855, Loss: 4.8250\n",
            "Epoch 5/8, Batch 8250/15855, Loss: 5.2360\n",
            "Epoch 5/8, Batch 8300/15855, Loss: 5.4166\n",
            "Epoch 5/8, Batch 8350/15855, Loss: 4.9351\n",
            "Epoch 5/8, Batch 8400/15855, Loss: 5.9977\n",
            "Epoch 5/8, Batch 8450/15855, Loss: 4.7429\n",
            "Epoch 5/8, Batch 8500/15855, Loss: 5.4210\n",
            "Epoch 5/8, Batch 8550/15855, Loss: 4.6563\n",
            "Epoch 5/8, Batch 8600/15855, Loss: 5.4762\n",
            "Epoch 5/8, Batch 8650/15855, Loss: 4.5846\n",
            "Epoch 5/8, Batch 8700/15855, Loss: 5.5635\n",
            "Epoch 5/8, Batch 8750/15855, Loss: 5.0329\n",
            "Epoch 5/8, Batch 8800/15855, Loss: 4.9711\n",
            "Epoch 5/8, Batch 8850/15855, Loss: 4.8268\n",
            "Epoch 5/8, Batch 8900/15855, Loss: 5.2799\n",
            "Epoch 5/8, Batch 8950/15855, Loss: 5.4715\n",
            "Epoch 5/8, Batch 9000/15855, Loss: 5.5330\n",
            "Epoch 5/8, Batch 9050/15855, Loss: 5.0563\n",
            "Epoch 5/8, Batch 9100/15855, Loss: 5.5756\n",
            "Epoch 5/8, Batch 9150/15855, Loss: 5.0254\n",
            "Epoch 5/8, Batch 9200/15855, Loss: 5.3334\n",
            "Epoch 5/8, Batch 9250/15855, Loss: 4.6871\n",
            "Epoch 5/8, Batch 9300/15855, Loss: 5.5183\n",
            "Epoch 5/8, Batch 9350/15855, Loss: 5.1590\n",
            "Epoch 5/8, Batch 9400/15855, Loss: 4.6379\n",
            "Epoch 5/8, Batch 9450/15855, Loss: 4.4657\n",
            "Epoch 5/8, Batch 9500/15855, Loss: 5.0705\n",
            "Epoch 5/8, Batch 9550/15855, Loss: 5.5501\n",
            "Epoch 5/8, Batch 9600/15855, Loss: 5.3340\n",
            "Epoch 5/8, Batch 9650/15855, Loss: 5.3404\n",
            "Epoch 5/8, Batch 9700/15855, Loss: 5.4376\n",
            "Epoch 5/8, Batch 9750/15855, Loss: 5.3420\n",
            "Epoch 5/8, Batch 9800/15855, Loss: 4.8059\n",
            "Epoch 5/8, Batch 9850/15855, Loss: 5.6900\n",
            "Epoch 5/8, Batch 9900/15855, Loss: 4.8176\n",
            "Epoch 5/8, Batch 9950/15855, Loss: 4.8657\n",
            "Epoch 5/8, Batch 10000/15855, Loss: 4.3265\n",
            "Epoch 5/8, Batch 10050/15855, Loss: 5.8245\n",
            "Epoch 5/8, Batch 10100/15855, Loss: 5.6133\n",
            "Epoch 5/8, Batch 10150/15855, Loss: 5.1247\n",
            "Epoch 5/8, Batch 10200/15855, Loss: 5.7863\n",
            "Epoch 5/8, Batch 10250/15855, Loss: 4.9969\n",
            "Epoch 5/8, Batch 10300/15855, Loss: 5.8340\n",
            "Epoch 5/8, Batch 10350/15855, Loss: 6.0247\n",
            "Epoch 5/8, Batch 10400/15855, Loss: 5.1693\n",
            "Epoch 5/8, Batch 10450/15855, Loss: 4.6455\n",
            "Epoch 5/8, Batch 10500/15855, Loss: 5.9488\n",
            "Epoch 5/8, Batch 10550/15855, Loss: 4.2913\n",
            "Epoch 5/8, Batch 10600/15855, Loss: 4.9454\n",
            "Epoch 5/8, Batch 10650/15855, Loss: 4.8402\n",
            "Epoch 5/8, Batch 10700/15855, Loss: 5.5292\n",
            "Epoch 5/8, Batch 10750/15855, Loss: 4.7089\n",
            "Epoch 5/8, Batch 10800/15855, Loss: 6.3677\n",
            "Epoch 5/8, Batch 10850/15855, Loss: 5.4700\n",
            "Epoch 5/8, Batch 10900/15855, Loss: 4.6420\n",
            "Epoch 5/8, Batch 10950/15855, Loss: 4.8045\n",
            "Epoch 5/8, Batch 11000/15855, Loss: 5.4342\n",
            "Epoch 5/8, Batch 11050/15855, Loss: 4.7765\n",
            "Epoch 5/8, Batch 11100/15855, Loss: 5.1273\n",
            "Epoch 5/8, Batch 11150/15855, Loss: 4.7760\n",
            "Epoch 5/8, Batch 11200/15855, Loss: 5.2547\n",
            "Epoch 5/8, Batch 11250/15855, Loss: 5.4925\n",
            "Epoch 5/8, Batch 11300/15855, Loss: 5.0884\n",
            "Epoch 5/8, Batch 11350/15855, Loss: 5.1474\n",
            "Epoch 5/8, Batch 11400/15855, Loss: 4.5263\n",
            "Epoch 5/8, Batch 11450/15855, Loss: 5.5229\n",
            "Epoch 5/8, Batch 11500/15855, Loss: 4.2512\n",
            "Epoch 5/8, Batch 11550/15855, Loss: 5.4516\n",
            "Epoch 5/8, Batch 11600/15855, Loss: 5.2944\n",
            "Epoch 5/8, Batch 11650/15855, Loss: 5.5305\n",
            "Epoch 5/8, Batch 11700/15855, Loss: 5.1295\n",
            "Epoch 5/8, Batch 11750/15855, Loss: 5.7359\n",
            "Epoch 5/8, Batch 11800/15855, Loss: 5.0892\n",
            "Epoch 5/8, Batch 11850/15855, Loss: 4.8441\n",
            "Epoch 5/8, Batch 11900/15855, Loss: 5.1029\n",
            "Epoch 5/8, Batch 11950/15855, Loss: 5.1862\n",
            "Epoch 5/8, Batch 12000/15855, Loss: 5.5670\n",
            "Epoch 5/8, Batch 12050/15855, Loss: 5.5946\n",
            "Epoch 5/8, Batch 12100/15855, Loss: 5.4153\n",
            "Epoch 5/8, Batch 12150/15855, Loss: 4.8803\n",
            "Epoch 5/8, Batch 12200/15855, Loss: 4.9220\n",
            "Epoch 5/8, Batch 12250/15855, Loss: 5.2878\n",
            "Epoch 5/8, Batch 12300/15855, Loss: 4.9144\n",
            "Epoch 5/8, Batch 12350/15855, Loss: 5.1127\n",
            "Epoch 5/8, Batch 12400/15855, Loss: 5.4884\n",
            "Epoch 5/8, Batch 12450/15855, Loss: 5.1845\n",
            "Epoch 5/8, Batch 12500/15855, Loss: 5.2262\n",
            "Epoch 5/8, Batch 12550/15855, Loss: 5.0491\n",
            "Epoch 5/8, Batch 12600/15855, Loss: 4.8782\n",
            "Epoch 5/8, Batch 12650/15855, Loss: 5.0101\n",
            "Epoch 5/8, Batch 12700/15855, Loss: 5.5521\n",
            "Epoch 5/8, Batch 12750/15855, Loss: 5.4151\n",
            "Epoch 5/8, Batch 12800/15855, Loss: 5.3589\n",
            "Epoch 5/8, Batch 12850/15855, Loss: 5.0715\n",
            "Epoch 5/8, Batch 12900/15855, Loss: 4.7292\n",
            "Epoch 5/8, Batch 12950/15855, Loss: 5.1836\n",
            "Epoch 5/8, Batch 13000/15855, Loss: 4.9085\n",
            "Epoch 5/8, Batch 13050/15855, Loss: 5.1498\n",
            "Epoch 5/8, Batch 13100/15855, Loss: 5.3464\n",
            "Epoch 5/8, Batch 13150/15855, Loss: 5.7303\n",
            "Epoch 5/8, Batch 13200/15855, Loss: 5.0476\n",
            "Epoch 5/8, Batch 13250/15855, Loss: 5.0081\n",
            "Epoch 5/8, Batch 13300/15855, Loss: 4.4428\n",
            "Epoch 5/8, Batch 13350/15855, Loss: 5.2922\n",
            "Epoch 5/8, Batch 13400/15855, Loss: 4.4764\n",
            "Epoch 5/8, Batch 13450/15855, Loss: 5.4589\n",
            "Epoch 5/8, Batch 13500/15855, Loss: 5.5826\n",
            "Epoch 5/8, Batch 13550/15855, Loss: 5.0738\n",
            "Epoch 5/8, Batch 13600/15855, Loss: 5.2262\n",
            "Epoch 5/8, Batch 13650/15855, Loss: 5.3405\n",
            "Epoch 5/8, Batch 13700/15855, Loss: 5.4980\n",
            "Epoch 5/8, Batch 13750/15855, Loss: 4.9644\n",
            "Epoch 5/8, Batch 13800/15855, Loss: 4.5552\n",
            "Epoch 5/8, Batch 13850/15855, Loss: 5.5388\n",
            "Epoch 5/8, Batch 13900/15855, Loss: 4.6724\n",
            "Epoch 5/8, Batch 13950/15855, Loss: 5.4367\n",
            "Epoch 5/8, Batch 14000/15855, Loss: 4.9984\n",
            "Epoch 5/8, Batch 14050/15855, Loss: 4.5025\n",
            "Epoch 5/8, Batch 14100/15855, Loss: 5.4869\n",
            "Epoch 5/8, Batch 14150/15855, Loss: 5.2825\n",
            "Epoch 5/8, Batch 14200/15855, Loss: 5.4153\n",
            "Epoch 5/8, Batch 14250/15855, Loss: 5.4688\n",
            "Epoch 5/8, Batch 14300/15855, Loss: 5.8913\n",
            "Epoch 5/8, Batch 14350/15855, Loss: 5.1171\n",
            "Epoch 5/8, Batch 14400/15855, Loss: 5.0250\n",
            "Epoch 5/8, Batch 14450/15855, Loss: 5.1878\n",
            "Epoch 5/8, Batch 14500/15855, Loss: 5.2716\n",
            "Epoch 5/8, Batch 14550/15855, Loss: 4.9209\n",
            "Epoch 5/8, Batch 14600/15855, Loss: 5.2764\n",
            "Epoch 5/8, Batch 14650/15855, Loss: 4.9935\n",
            "Epoch 5/8, Batch 14700/15855, Loss: 4.6603\n",
            "Epoch 5/8, Batch 14750/15855, Loss: 5.7936\n",
            "Epoch 5/8, Batch 14800/15855, Loss: 5.3159\n",
            "Epoch 5/8, Batch 14850/15855, Loss: 5.1085\n",
            "Epoch 5/8, Batch 14900/15855, Loss: 5.0432\n",
            "Epoch 5/8, Batch 14950/15855, Loss: 5.3231\n",
            "Epoch 5/8, Batch 15000/15855, Loss: 4.7121\n",
            "Epoch 5/8, Batch 15050/15855, Loss: 5.0021\n",
            "Epoch 5/8, Batch 15100/15855, Loss: 5.2277\n",
            "Epoch 5/8, Batch 15150/15855, Loss: 6.0595\n",
            "Epoch 5/8, Batch 15200/15855, Loss: 5.6696\n",
            "Epoch 5/8, Batch 15250/15855, Loss: 4.6073\n",
            "Epoch 5/8, Batch 15300/15855, Loss: 4.5252\n",
            "Epoch 5/8, Batch 15350/15855, Loss: 5.4297\n",
            "Epoch 5/8, Batch 15400/15855, Loss: 5.0537\n",
            "Epoch 5/8, Batch 15450/15855, Loss: 5.5993\n",
            "Epoch 5/8, Batch 15500/15855, Loss: 5.2316\n",
            "Epoch 5/8, Batch 15550/15855, Loss: 6.1988\n",
            "Epoch 5/8, Batch 15600/15855, Loss: 5.5768\n",
            "Epoch 5/8, Batch 15650/15855, Loss: 5.4407\n",
            "Epoch 5/8, Batch 15700/15855, Loss: 5.4339\n",
            "Epoch 5/8, Batch 15750/15855, Loss: 4.7141\n",
            "Epoch 5/8, Batch 15800/15855, Loss: 5.6304\n",
            "Epoch 5/8, Batch 15850/15855, Loss: 5.2423\n",
            "Epoch 5/8 - Train Loss: 5.1791, Val Loss: 5.1536\n",
            "Epoch 6/8, Batch 0/15855, Loss: 5.2793\n",
            "Epoch 6/8, Batch 50/15855, Loss: 4.4295\n",
            "Epoch 6/8, Batch 100/15855, Loss: 5.1577\n",
            "Epoch 6/8, Batch 150/15855, Loss: 5.0126\n",
            "Epoch 6/8, Batch 200/15855, Loss: 5.1563\n",
            "Epoch 6/8, Batch 250/15855, Loss: 4.6203\n",
            "Epoch 6/8, Batch 300/15855, Loss: 5.0415\n",
            "Epoch 6/8, Batch 350/15855, Loss: 5.7709\n",
            "Epoch 6/8, Batch 400/15855, Loss: 4.3043\n",
            "Epoch 6/8, Batch 450/15855, Loss: 5.8059\n",
            "Epoch 6/8, Batch 500/15855, Loss: 5.3370\n",
            "Epoch 6/8, Batch 550/15855, Loss: 5.2207\n",
            "Epoch 6/8, Batch 600/15855, Loss: 4.7023\n",
            "Epoch 6/8, Batch 650/15855, Loss: 4.6156\n",
            "Epoch 6/8, Batch 700/15855, Loss: 4.5913\n",
            "Epoch 6/8, Batch 750/15855, Loss: 5.1146\n",
            "Epoch 6/8, Batch 800/15855, Loss: 4.7631\n",
            "Epoch 6/8, Batch 850/15855, Loss: 5.0742\n",
            "Epoch 6/8, Batch 900/15855, Loss: 4.8711\n",
            "Epoch 6/8, Batch 950/15855, Loss: 5.4721\n",
            "Epoch 6/8, Batch 1000/15855, Loss: 5.4634\n",
            "Epoch 6/8, Batch 1050/15855, Loss: 4.8608\n",
            "Epoch 6/8, Batch 1100/15855, Loss: 4.5801\n",
            "Epoch 6/8, Batch 1150/15855, Loss: 5.1689\n",
            "Epoch 6/8, Batch 1200/15855, Loss: 4.1568\n",
            "Epoch 6/8, Batch 1250/15855, Loss: 5.1558\n",
            "Epoch 6/8, Batch 1300/15855, Loss: 4.6199\n",
            "Epoch 6/8, Batch 1350/15855, Loss: 5.9374\n",
            "Epoch 6/8, Batch 1400/15855, Loss: 5.0781\n",
            "Epoch 6/8, Batch 1450/15855, Loss: 5.3822\n",
            "Epoch 6/8, Batch 1500/15855, Loss: 4.8953\n",
            "Epoch 6/8, Batch 1550/15855, Loss: 4.7889\n",
            "Epoch 6/8, Batch 1600/15855, Loss: 5.7490\n",
            "Epoch 6/8, Batch 1650/15855, Loss: 4.7890\n",
            "Epoch 6/8, Batch 1700/15855, Loss: 5.4501\n",
            "Epoch 6/8, Batch 1750/15855, Loss: 5.2363\n",
            "Epoch 6/8, Batch 1800/15855, Loss: 5.2548\n",
            "Epoch 6/8, Batch 1850/15855, Loss: 5.0282\n",
            "Epoch 6/8, Batch 1900/15855, Loss: 4.5061\n",
            "Epoch 6/8, Batch 1950/15855, Loss: 5.2580\n",
            "Epoch 6/8, Batch 2000/15855, Loss: 4.8072\n",
            "Epoch 6/8, Batch 2050/15855, Loss: 5.1931\n",
            "Epoch 6/8, Batch 2100/15855, Loss: 5.1454\n",
            "Epoch 6/8, Batch 2150/15855, Loss: 4.8339\n",
            "Epoch 6/8, Batch 2200/15855, Loss: 4.3708\n",
            "Epoch 6/8, Batch 2250/15855, Loss: 4.8733\n",
            "Epoch 6/8, Batch 2300/15855, Loss: 5.3131\n",
            "Epoch 6/8, Batch 2350/15855, Loss: 4.6994\n",
            "Epoch 6/8, Batch 2400/15855, Loss: 4.9059\n",
            "Epoch 6/8, Batch 2450/15855, Loss: 5.1965\n",
            "Epoch 6/8, Batch 2500/15855, Loss: 5.3588\n",
            "Epoch 6/8, Batch 2550/15855, Loss: 5.5201\n",
            "Epoch 6/8, Batch 2600/15855, Loss: 5.4273\n",
            "Epoch 6/8, Batch 2650/15855, Loss: 4.8278\n",
            "Epoch 6/8, Batch 2700/15855, Loss: 5.3440\n",
            "Epoch 6/8, Batch 2750/15855, Loss: 4.2860\n",
            "Epoch 6/8, Batch 2800/15855, Loss: 5.6108\n",
            "Epoch 6/8, Batch 2850/15855, Loss: 5.0309\n",
            "Epoch 6/8, Batch 2900/15855, Loss: 4.7677\n",
            "Epoch 6/8, Batch 2950/15855, Loss: 5.0314\n",
            "Epoch 6/8, Batch 3000/15855, Loss: 4.8671\n",
            "Epoch 6/8, Batch 3050/15855, Loss: 4.8335\n",
            "Epoch 6/8, Batch 3100/15855, Loss: 5.4101\n",
            "Epoch 6/8, Batch 3150/15855, Loss: 5.4083\n",
            "Epoch 6/8, Batch 3200/15855, Loss: 5.5250\n",
            "Epoch 6/8, Batch 3250/15855, Loss: 4.7290\n",
            "Epoch 6/8, Batch 3300/15855, Loss: 5.4791\n",
            "Epoch 6/8, Batch 3350/15855, Loss: 5.0279\n",
            "Epoch 6/8, Batch 3400/15855, Loss: 4.6096\n",
            "Epoch 6/8, Batch 3450/15855, Loss: 5.5704\n",
            "Epoch 6/8, Batch 3500/15855, Loss: 5.4641\n",
            "Epoch 6/8, Batch 3550/15855, Loss: 4.7591\n",
            "Epoch 6/8, Batch 3600/15855, Loss: 5.1247\n",
            "Epoch 6/8, Batch 3650/15855, Loss: 5.6319\n",
            "Epoch 6/8, Batch 3700/15855, Loss: 4.9960\n",
            "Epoch 6/8, Batch 3750/15855, Loss: 5.0723\n",
            "Epoch 6/8, Batch 3800/15855, Loss: 5.4089\n",
            "Epoch 6/8, Batch 3850/15855, Loss: 5.8872\n",
            "Epoch 6/8, Batch 3900/15855, Loss: 5.7375\n",
            "Epoch 6/8, Batch 3950/15855, Loss: 5.5560\n",
            "Epoch 6/8, Batch 4000/15855, Loss: 4.4456\n",
            "Epoch 6/8, Batch 4050/15855, Loss: 4.8371\n",
            "Epoch 6/8, Batch 4100/15855, Loss: 5.3576\n",
            "Epoch 6/8, Batch 4150/15855, Loss: 5.5320\n",
            "Epoch 6/8, Batch 4200/15855, Loss: 4.9371\n",
            "Epoch 6/8, Batch 4250/15855, Loss: 4.4616\n",
            "Epoch 6/8, Batch 4300/15855, Loss: 4.5498\n",
            "Epoch 6/8, Batch 4350/15855, Loss: 5.3949\n",
            "Epoch 6/8, Batch 4400/15855, Loss: 5.0186\n",
            "Epoch 6/8, Batch 4450/15855, Loss: 4.7043\n",
            "Epoch 6/8, Batch 4500/15855, Loss: 5.5227\n",
            "Epoch 6/8, Batch 4550/15855, Loss: 5.0342\n",
            "Epoch 6/8, Batch 4600/15855, Loss: 5.8214\n",
            "Epoch 6/8, Batch 4650/15855, Loss: 5.0751\n",
            "Epoch 6/8, Batch 4700/15855, Loss: 5.0450\n",
            "Epoch 6/8, Batch 4750/15855, Loss: 5.0663\n",
            "Epoch 6/8, Batch 4800/15855, Loss: 4.6670\n",
            "Epoch 6/8, Batch 4850/15855, Loss: 4.8337\n",
            "Epoch 6/8, Batch 4900/15855, Loss: 5.0018\n",
            "Epoch 6/8, Batch 4950/15855, Loss: 4.9473\n",
            "Epoch 6/8, Batch 5000/15855, Loss: 5.0893\n",
            "Epoch 6/8, Batch 5050/15855, Loss: 4.8596\n",
            "Epoch 6/8, Batch 5100/15855, Loss: 5.4200\n",
            "Epoch 6/8, Batch 5150/15855, Loss: 5.7682\n",
            "Epoch 6/8, Batch 5200/15855, Loss: 4.3793\n",
            "Epoch 6/8, Batch 5250/15855, Loss: 5.0220\n",
            "Epoch 6/8, Batch 5300/15855, Loss: 4.9921\n",
            "Epoch 6/8, Batch 5350/15855, Loss: 4.5956\n",
            "Epoch 6/8, Batch 5400/15855, Loss: 4.5254\n",
            "Epoch 6/8, Batch 5450/15855, Loss: 5.5986\n",
            "Epoch 6/8, Batch 5500/15855, Loss: 5.3797\n",
            "Epoch 6/8, Batch 5550/15855, Loss: 5.5527\n",
            "Epoch 6/8, Batch 5600/15855, Loss: 5.0707\n",
            "Epoch 6/8, Batch 5650/15855, Loss: 4.8459\n",
            "Epoch 6/8, Batch 5700/15855, Loss: 5.2427\n",
            "Epoch 6/8, Batch 5750/15855, Loss: 4.7258\n",
            "Epoch 6/8, Batch 5800/15855, Loss: 4.6303\n",
            "Epoch 6/8, Batch 5850/15855, Loss: 5.4811\n",
            "Epoch 6/8, Batch 5900/15855, Loss: 4.8345\n",
            "Epoch 6/8, Batch 5950/15855, Loss: 4.9166\n",
            "Epoch 6/8, Batch 6000/15855, Loss: 5.4037\n",
            "Epoch 6/8, Batch 6050/15855, Loss: 5.3747\n",
            "Epoch 6/8, Batch 6100/15855, Loss: 4.9168\n",
            "Epoch 6/8, Batch 6150/15855, Loss: 4.5177\n",
            "Epoch 6/8, Batch 6200/15855, Loss: 4.6067\n",
            "Epoch 6/8, Batch 6250/15855, Loss: 4.4534\n",
            "Epoch 6/8, Batch 6300/15855, Loss: 4.9981\n",
            "Epoch 6/8, Batch 6350/15855, Loss: 4.6215\n",
            "Epoch 6/8, Batch 6400/15855, Loss: 4.9043\n",
            "Epoch 6/8, Batch 6450/15855, Loss: 5.5002\n",
            "Epoch 6/8, Batch 6500/15855, Loss: 5.5000\n",
            "Epoch 6/8, Batch 6550/15855, Loss: 4.2662\n",
            "Epoch 6/8, Batch 6600/15855, Loss: 4.9369\n",
            "Epoch 6/8, Batch 6650/15855, Loss: 4.9713\n",
            "Epoch 6/8, Batch 6700/15855, Loss: 5.2059\n",
            "Epoch 6/8, Batch 6750/15855, Loss: 4.9348\n",
            "Epoch 6/8, Batch 6800/15855, Loss: 5.4117\n",
            "Epoch 6/8, Batch 6850/15855, Loss: 5.0069\n",
            "Epoch 6/8, Batch 6900/15855, Loss: 5.4363\n",
            "Epoch 6/8, Batch 6950/15855, Loss: 5.3655\n",
            "Epoch 6/8, Batch 7000/15855, Loss: 5.8630\n",
            "Epoch 6/8, Batch 7050/15855, Loss: 5.0860\n",
            "Epoch 6/8, Batch 7100/15855, Loss: 5.4302\n",
            "Epoch 6/8, Batch 7150/15855, Loss: 5.7984\n",
            "Epoch 6/8, Batch 7200/15855, Loss: 5.1308\n",
            "Epoch 6/8, Batch 7250/15855, Loss: 4.5120\n",
            "Epoch 6/8, Batch 7300/15855, Loss: 4.6193\n",
            "Epoch 6/8, Batch 7350/15855, Loss: 5.4009\n",
            "Epoch 6/8, Batch 7400/15855, Loss: 4.8898\n",
            "Epoch 6/8, Batch 7450/15855, Loss: 4.6134\n",
            "Epoch 6/8, Batch 7500/15855, Loss: 4.6657\n",
            "Epoch 6/8, Batch 7550/15855, Loss: 4.9837\n",
            "Epoch 6/8, Batch 7600/15855, Loss: 4.6546\n",
            "Epoch 6/8, Batch 7650/15855, Loss: 5.1604\n",
            "Epoch 6/8, Batch 7700/15855, Loss: 5.1038\n",
            "Epoch 6/8, Batch 7750/15855, Loss: 5.3806\n",
            "Epoch 6/8, Batch 7800/15855, Loss: 5.1908\n",
            "Epoch 6/8, Batch 7850/15855, Loss: 5.3581\n",
            "Epoch 6/8, Batch 7900/15855, Loss: 5.2294\n",
            "Epoch 6/8, Batch 7950/15855, Loss: 5.1979\n",
            "Epoch 6/8, Batch 8000/15855, Loss: 5.8135\n",
            "Epoch 6/8, Batch 8050/15855, Loss: 4.7625\n",
            "Epoch 6/8, Batch 8100/15855, Loss: 5.0507\n",
            "Epoch 6/8, Batch 8150/15855, Loss: 5.6979\n",
            "Epoch 6/8, Batch 8200/15855, Loss: 5.0475\n",
            "Epoch 6/8, Batch 8250/15855, Loss: 5.3177\n",
            "Epoch 6/8, Batch 8300/15855, Loss: 5.6233\n",
            "Epoch 6/8, Batch 8350/15855, Loss: 5.0534\n",
            "Epoch 6/8, Batch 8400/15855, Loss: 5.8290\n",
            "Epoch 6/8, Batch 8450/15855, Loss: 4.4878\n",
            "Epoch 6/8, Batch 8500/15855, Loss: 5.1503\n",
            "Epoch 6/8, Batch 8550/15855, Loss: 4.9600\n",
            "Epoch 6/8, Batch 8600/15855, Loss: 4.6036\n",
            "Epoch 6/8, Batch 8650/15855, Loss: 4.9533\n",
            "Epoch 6/8, Batch 8700/15855, Loss: 4.7944\n",
            "Epoch 6/8, Batch 8750/15855, Loss: 5.2452\n",
            "Epoch 6/8, Batch 8800/15855, Loss: 5.4260\n",
            "Epoch 6/8, Batch 8850/15855, Loss: 4.7349\n",
            "Epoch 6/8, Batch 8900/15855, Loss: 5.1602\n",
            "Epoch 6/8, Batch 8950/15855, Loss: 4.6291\n",
            "Epoch 6/8, Batch 9000/15855, Loss: 5.5218\n",
            "Epoch 6/8, Batch 9050/15855, Loss: 5.2217\n",
            "Epoch 6/8, Batch 9100/15855, Loss: 4.6364\n",
            "Epoch 6/8, Batch 9150/15855, Loss: 4.9234\n",
            "Epoch 6/8, Batch 9200/15855, Loss: 5.5066\n",
            "Epoch 6/8, Batch 9250/15855, Loss: 5.2909\n",
            "Epoch 6/8, Batch 9300/15855, Loss: 6.0867\n",
            "Epoch 6/8, Batch 9350/15855, Loss: 4.6894\n",
            "Epoch 6/8, Batch 9400/15855, Loss: 4.6694\n",
            "Epoch 6/8, Batch 9450/15855, Loss: 4.5949\n",
            "Epoch 6/8, Batch 9500/15855, Loss: 4.6899\n",
            "Epoch 6/8, Batch 9550/15855, Loss: 5.9600\n",
            "Epoch 6/8, Batch 9600/15855, Loss: 4.9615\n",
            "Epoch 6/8, Batch 9650/15855, Loss: 5.8019\n",
            "Epoch 6/8, Batch 9700/15855, Loss: 5.5905\n",
            "Epoch 6/8, Batch 9750/15855, Loss: 5.0836\n",
            "Epoch 6/8, Batch 9800/15855, Loss: 5.4480\n",
            "Epoch 6/8, Batch 9850/15855, Loss: 4.7558\n",
            "Epoch 6/8, Batch 9900/15855, Loss: 5.1928\n",
            "Epoch 6/8, Batch 9950/15855, Loss: 4.5856\n",
            "Epoch 6/8, Batch 10000/15855, Loss: 5.5908\n",
            "Epoch 6/8, Batch 10050/15855, Loss: 4.7007\n",
            "Epoch 6/8, Batch 10100/15855, Loss: 5.1020\n",
            "Epoch 6/8, Batch 10150/15855, Loss: 5.8057\n",
            "Epoch 6/8, Batch 10200/15855, Loss: 5.4110\n",
            "Epoch 6/8, Batch 10250/15855, Loss: 5.0548\n",
            "Epoch 6/8, Batch 10300/15855, Loss: 4.7698\n",
            "Epoch 6/8, Batch 10350/15855, Loss: 4.4339\n",
            "Epoch 6/8, Batch 10400/15855, Loss: 4.9718\n",
            "Epoch 6/8, Batch 10450/15855, Loss: 5.2387\n",
            "Epoch 6/8, Batch 10500/15855, Loss: 5.7053\n",
            "Epoch 6/8, Batch 10550/15855, Loss: 4.9865\n",
            "Epoch 6/8, Batch 10600/15855, Loss: 5.3360\n",
            "Epoch 6/8, Batch 10650/15855, Loss: 5.1333\n",
            "Epoch 6/8, Batch 10700/15855, Loss: 5.1822\n",
            "Epoch 6/8, Batch 10750/15855, Loss: 4.5400\n",
            "Epoch 6/8, Batch 10800/15855, Loss: 5.8784\n",
            "Epoch 6/8, Batch 10850/15855, Loss: 5.0426\n",
            "Epoch 6/8, Batch 10900/15855, Loss: 5.2409\n",
            "Epoch 6/8, Batch 10950/15855, Loss: 5.3198\n",
            "Epoch 6/8, Batch 11000/15855, Loss: 5.0727\n",
            "Epoch 6/8, Batch 11050/15855, Loss: 5.1933\n",
            "Epoch 6/8, Batch 11100/15855, Loss: 5.1534\n",
            "Epoch 6/8, Batch 11150/15855, Loss: 4.6065\n",
            "Epoch 6/8, Batch 11200/15855, Loss: 4.5518\n",
            "Epoch 6/8, Batch 11250/15855, Loss: 5.3090\n",
            "Epoch 6/8, Batch 11300/15855, Loss: 5.1790\n",
            "Epoch 6/8, Batch 11350/15855, Loss: 5.5875\n",
            "Epoch 6/8, Batch 11400/15855, Loss: 5.1561\n",
            "Epoch 6/8, Batch 11450/15855, Loss: 5.2458\n",
            "Epoch 6/8, Batch 11500/15855, Loss: 5.2377\n",
            "Epoch 6/8, Batch 11550/15855, Loss: 5.3881\n",
            "Epoch 6/8, Batch 11600/15855, Loss: 5.6645\n",
            "Epoch 6/8, Batch 11650/15855, Loss: 4.8946\n",
            "Epoch 6/8, Batch 11700/15855, Loss: 6.2212\n",
            "Epoch 6/8, Batch 11750/15855, Loss: 5.0042\n",
            "Epoch 6/8, Batch 11800/15855, Loss: 5.4913\n",
            "Epoch 6/8, Batch 11850/15855, Loss: 5.3964\n",
            "Epoch 6/8, Batch 11900/15855, Loss: 4.5849\n",
            "Epoch 6/8, Batch 11950/15855, Loss: 4.9110\n",
            "Epoch 6/8, Batch 12000/15855, Loss: 4.7800\n",
            "Epoch 6/8, Batch 12050/15855, Loss: 5.0105\n",
            "Epoch 6/8, Batch 12100/15855, Loss: 4.4777\n",
            "Epoch 6/8, Batch 12150/15855, Loss: 5.3758\n",
            "Epoch 6/8, Batch 12200/15855, Loss: 4.5469\n",
            "Epoch 6/8, Batch 12250/15855, Loss: 5.4273\n",
            "Epoch 6/8, Batch 12300/15855, Loss: 4.9543\n",
            "Epoch 6/8, Batch 12350/15855, Loss: 5.4235\n",
            "Epoch 6/8, Batch 12400/15855, Loss: 5.0566\n",
            "Epoch 6/8, Batch 12450/15855, Loss: 4.9436\n",
            "Epoch 6/8, Batch 12500/15855, Loss: 5.2975\n",
            "Epoch 6/8, Batch 12550/15855, Loss: 5.6573\n",
            "Epoch 6/8, Batch 12600/15855, Loss: 5.7640\n",
            "Epoch 6/8, Batch 12650/15855, Loss: 4.8474\n",
            "Epoch 6/8, Batch 12700/15855, Loss: 5.5859\n",
            "Epoch 6/8, Batch 12750/15855, Loss: 5.4966\n",
            "Epoch 6/8, Batch 12800/15855, Loss: 4.9443\n",
            "Epoch 6/8, Batch 12850/15855, Loss: 4.9312\n",
            "Epoch 6/8, Batch 12900/15855, Loss: 5.5236\n",
            "Epoch 6/8, Batch 12950/15855, Loss: 4.7173\n",
            "Epoch 6/8, Batch 13000/15855, Loss: 4.8241\n",
            "Epoch 6/8, Batch 13050/15855, Loss: 4.5228\n",
            "Epoch 6/8, Batch 13100/15855, Loss: 4.9207\n",
            "Epoch 6/8, Batch 13150/15855, Loss: 4.8176\n",
            "Epoch 6/8, Batch 13200/15855, Loss: 4.7874\n",
            "Epoch 6/8, Batch 13250/15855, Loss: 5.2712\n",
            "Epoch 6/8, Batch 13300/15855, Loss: 4.9791\n",
            "Epoch 6/8, Batch 13350/15855, Loss: 4.9343\n",
            "Epoch 6/8, Batch 13400/15855, Loss: 5.1846\n",
            "Epoch 6/8, Batch 13450/15855, Loss: 5.1663\n",
            "Epoch 6/8, Batch 13500/15855, Loss: 5.2280\n",
            "Epoch 6/8, Batch 13550/15855, Loss: 4.9745\n",
            "Epoch 6/8, Batch 13600/15855, Loss: 5.2875\n",
            "Epoch 6/8, Batch 13650/15855, Loss: 4.8600\n",
            "Epoch 6/8, Batch 13700/15855, Loss: 5.1378\n",
            "Epoch 6/8, Batch 13750/15855, Loss: 4.9690\n",
            "Epoch 6/8, Batch 13800/15855, Loss: 4.6641\n",
            "Epoch 6/8, Batch 13850/15855, Loss: 5.3673\n",
            "Epoch 6/8, Batch 13900/15855, Loss: 5.4374\n",
            "Epoch 6/8, Batch 13950/15855, Loss: 5.3297\n",
            "Epoch 6/8, Batch 14000/15855, Loss: 4.9474\n",
            "Epoch 6/8, Batch 14050/15855, Loss: 4.9374\n",
            "Epoch 6/8, Batch 14100/15855, Loss: 5.2504\n",
            "Epoch 6/8, Batch 14150/15855, Loss: 5.7389\n",
            "Epoch 6/8, Batch 14200/15855, Loss: 5.1446\n",
            "Epoch 6/8, Batch 14250/15855, Loss: 5.0105\n",
            "Epoch 6/8, Batch 14300/15855, Loss: 4.6647\n",
            "Epoch 6/8, Batch 14350/15855, Loss: 5.2523\n",
            "Epoch 6/8, Batch 14400/15855, Loss: 5.3857\n",
            "Epoch 6/8, Batch 14450/15855, Loss: 4.4207\n",
            "Epoch 6/8, Batch 14500/15855, Loss: 4.4386\n",
            "Epoch 6/8, Batch 14550/15855, Loss: 5.1825\n",
            "Epoch 6/8, Batch 14600/15855, Loss: 5.4613\n",
            "Epoch 6/8, Batch 14650/15855, Loss: 5.0092\n",
            "Epoch 6/8, Batch 14700/15855, Loss: 5.0275\n",
            "Epoch 6/8, Batch 14750/15855, Loss: 5.4863\n",
            "Epoch 6/8, Batch 14800/15855, Loss: 4.8431\n",
            "Epoch 6/8, Batch 14850/15855, Loss: 5.5558\n",
            "Epoch 6/8, Batch 14900/15855, Loss: 5.0239\n",
            "Epoch 6/8, Batch 14950/15855, Loss: 5.0324\n",
            "Epoch 6/8, Batch 15000/15855, Loss: 5.3389\n",
            "Epoch 6/8, Batch 15050/15855, Loss: 3.8172\n",
            "Epoch 6/8, Batch 15100/15855, Loss: 5.0839\n",
            "Epoch 6/8, Batch 15150/15855, Loss: 5.4612\n",
            "Epoch 6/8, Batch 15200/15855, Loss: 5.7190\n",
            "Epoch 6/8, Batch 15250/15855, Loss: 4.9291\n",
            "Epoch 6/8, Batch 15300/15855, Loss: 4.7293\n",
            "Epoch 6/8, Batch 15350/15855, Loss: 5.2572\n",
            "Epoch 6/8, Batch 15400/15855, Loss: 4.2983\n",
            "Epoch 6/8, Batch 15450/15855, Loss: 5.3636\n",
            "Epoch 6/8, Batch 15500/15855, Loss: 5.2029\n",
            "Epoch 6/8, Batch 15550/15855, Loss: 4.9809\n",
            "Epoch 6/8, Batch 15600/15855, Loss: 5.2003\n",
            "Epoch 6/8, Batch 15650/15855, Loss: 5.1389\n",
            "Epoch 6/8, Batch 15700/15855, Loss: 4.8154\n",
            "Epoch 6/8, Batch 15750/15855, Loss: 4.5803\n",
            "Epoch 6/8, Batch 15800/15855, Loss: 4.9039\n",
            "Epoch 6/8, Batch 15850/15855, Loss: 5.1488\n",
            "Epoch 6/8 - Train Loss: 5.1159, Val Loss: 5.1227\n",
            "Exemple g√©n√©r√©: \"harry potter - they inside him there was a point on his own <UNK> he handed himself to settle back\"\n",
            "\n",
            "Epoch 7/8, Batch 0/15855, Loss: 5.1917\n",
            "Epoch 7/8, Batch 50/15855, Loss: 4.5559\n",
            "Epoch 7/8, Batch 100/15855, Loss: 5.2589\n",
            "Epoch 7/8, Batch 150/15855, Loss: 5.1674\n",
            "Epoch 7/8, Batch 200/15855, Loss: 4.6220\n",
            "Epoch 7/8, Batch 250/15855, Loss: 5.0491\n",
            "Epoch 7/8, Batch 300/15855, Loss: 4.2443\n",
            "Epoch 7/8, Batch 350/15855, Loss: 5.4378\n",
            "Epoch 7/8, Batch 400/15855, Loss: 5.2998\n",
            "Epoch 7/8, Batch 450/15855, Loss: 4.9958\n",
            "Epoch 7/8, Batch 500/15855, Loss: 4.7336\n",
            "Epoch 7/8, Batch 550/15855, Loss: 4.9049\n",
            "Epoch 7/8, Batch 600/15855, Loss: 5.0055\n",
            "Epoch 7/8, Batch 650/15855, Loss: 4.2991\n",
            "Epoch 7/8, Batch 700/15855, Loss: 5.5066\n",
            "Epoch 7/8, Batch 750/15855, Loss: 4.3274\n",
            "Epoch 7/8, Batch 800/15855, Loss: 5.1474\n",
            "Epoch 7/8, Batch 850/15855, Loss: 4.8630\n",
            "Epoch 7/8, Batch 900/15855, Loss: 4.6974\n",
            "Epoch 7/8, Batch 950/15855, Loss: 4.9049\n",
            "Epoch 7/8, Batch 1000/15855, Loss: 4.5830\n",
            "Epoch 7/8, Batch 1050/15855, Loss: 4.7844\n",
            "Epoch 7/8, Batch 1100/15855, Loss: 4.9939\n",
            "Epoch 7/8, Batch 1150/15855, Loss: 4.8433\n",
            "Epoch 7/8, Batch 1200/15855, Loss: 5.5184\n",
            "Epoch 7/8, Batch 1250/15855, Loss: 4.9809\n",
            "Epoch 7/8, Batch 1300/15855, Loss: 4.8921\n",
            "Epoch 7/8, Batch 1350/15855, Loss: 4.7535\n",
            "Epoch 7/8, Batch 1400/15855, Loss: 4.1765\n",
            "Epoch 7/8, Batch 1450/15855, Loss: 5.0462\n",
            "Epoch 7/8, Batch 1500/15855, Loss: 5.5182\n",
            "Epoch 7/8, Batch 1550/15855, Loss: 4.4328\n",
            "Epoch 7/8, Batch 1600/15855, Loss: 5.3542\n",
            "Epoch 7/8, Batch 1650/15855, Loss: 5.8923\n",
            "Epoch 7/8, Batch 1700/15855, Loss: 4.6548\n",
            "Epoch 7/8, Batch 1750/15855, Loss: 5.3647\n",
            "Epoch 7/8, Batch 1800/15855, Loss: 5.6665\n",
            "Epoch 7/8, Batch 1850/15855, Loss: 5.0231\n",
            "Epoch 7/8, Batch 1900/15855, Loss: 4.8950\n",
            "Epoch 7/8, Batch 1950/15855, Loss: 5.5096\n",
            "Epoch 7/8, Batch 2000/15855, Loss: 4.9077\n",
            "Epoch 7/8, Batch 2050/15855, Loss: 5.1208\n",
            "Epoch 7/8, Batch 2100/15855, Loss: 4.7424\n",
            "Epoch 7/8, Batch 2150/15855, Loss: 5.1693\n",
            "Epoch 7/8, Batch 2200/15855, Loss: 4.3359\n",
            "Epoch 7/8, Batch 2250/15855, Loss: 5.8885\n",
            "Epoch 7/8, Batch 2300/15855, Loss: 5.2657\n",
            "Epoch 7/8, Batch 2350/15855, Loss: 5.1697\n",
            "Epoch 7/8, Batch 2400/15855, Loss: 5.1047\n",
            "Epoch 7/8, Batch 2450/15855, Loss: 5.6904\n",
            "Epoch 7/8, Batch 2500/15855, Loss: 5.3057\n",
            "Epoch 7/8, Batch 2550/15855, Loss: 5.2698\n",
            "Epoch 7/8, Batch 2600/15855, Loss: 4.5221\n",
            "Epoch 7/8, Batch 2650/15855, Loss: 4.3238\n",
            "Epoch 7/8, Batch 2700/15855, Loss: 5.1377\n",
            "Epoch 7/8, Batch 2750/15855, Loss: 4.6681\n",
            "Epoch 7/8, Batch 2800/15855, Loss: 4.6342\n",
            "Epoch 7/8, Batch 2850/15855, Loss: 5.0824\n",
            "Epoch 7/8, Batch 2900/15855, Loss: 4.4831\n",
            "Epoch 7/8, Batch 2950/15855, Loss: 5.0841\n",
            "Epoch 7/8, Batch 3000/15855, Loss: 4.7117\n",
            "Epoch 7/8, Batch 3050/15855, Loss: 5.4096\n",
            "Epoch 7/8, Batch 3100/15855, Loss: 5.8248\n",
            "Epoch 7/8, Batch 3150/15855, Loss: 4.8189\n",
            "Epoch 7/8, Batch 3200/15855, Loss: 5.3784\n",
            "Epoch 7/8, Batch 3250/15855, Loss: 5.1851\n",
            "Epoch 7/8, Batch 3300/15855, Loss: 4.4645\n",
            "Epoch 7/8, Batch 3350/15855, Loss: 5.2417\n",
            "Epoch 7/8, Batch 3400/15855, Loss: 4.8435\n",
            "Epoch 7/8, Batch 3450/15855, Loss: 4.8581\n",
            "Epoch 7/8, Batch 3500/15855, Loss: 4.4229\n",
            "Epoch 7/8, Batch 3550/15855, Loss: 5.7742\n",
            "Epoch 7/8, Batch 3600/15855, Loss: 5.0555\n",
            "Epoch 7/8, Batch 3650/15855, Loss: 5.4821\n",
            "Epoch 7/8, Batch 3700/15855, Loss: 5.1283\n",
            "Epoch 7/8, Batch 3750/15855, Loss: 5.1420\n",
            "Epoch 7/8, Batch 3800/15855, Loss: 4.4331\n",
            "Epoch 7/8, Batch 3850/15855, Loss: 5.0882\n",
            "Epoch 7/8, Batch 3900/15855, Loss: 5.5089\n",
            "Epoch 7/8, Batch 3950/15855, Loss: 4.9444\n",
            "Epoch 7/8, Batch 4000/15855, Loss: 4.9885\n",
            "Epoch 7/8, Batch 4050/15855, Loss: 5.2798\n",
            "Epoch 7/8, Batch 4100/15855, Loss: 5.1317\n",
            "Epoch 7/8, Batch 4150/15855, Loss: 3.8665\n",
            "Epoch 7/8, Batch 4200/15855, Loss: 4.8092\n",
            "Epoch 7/8, Batch 4250/15855, Loss: 5.3828\n",
            "Epoch 7/8, Batch 4300/15855, Loss: 5.4678\n",
            "Epoch 7/8, Batch 4350/15855, Loss: 5.1651\n",
            "Epoch 7/8, Batch 4400/15855, Loss: 4.9734\n",
            "Epoch 7/8, Batch 4450/15855, Loss: 4.6340\n",
            "Epoch 7/8, Batch 4500/15855, Loss: 5.1082\n",
            "Epoch 7/8, Batch 4550/15855, Loss: 5.1062\n",
            "Epoch 7/8, Batch 4600/15855, Loss: 4.7376\n",
            "Epoch 7/8, Batch 4650/15855, Loss: 5.0524\n",
            "Epoch 7/8, Batch 4700/15855, Loss: 5.2965\n",
            "Epoch 7/8, Batch 4750/15855, Loss: 4.9534\n",
            "Epoch 7/8, Batch 4800/15855, Loss: 4.7927\n",
            "Epoch 7/8, Batch 4850/15855, Loss: 4.9771\n",
            "Epoch 7/8, Batch 4900/15855, Loss: 4.6634\n",
            "Epoch 7/8, Batch 4950/15855, Loss: 4.8288\n",
            "Epoch 7/8, Batch 5000/15855, Loss: 5.1446\n",
            "Epoch 7/8, Batch 5050/15855, Loss: 4.7646\n",
            "Epoch 7/8, Batch 5100/15855, Loss: 4.6595\n",
            "Epoch 7/8, Batch 5150/15855, Loss: 5.7807\n",
            "Epoch 7/8, Batch 5200/15855, Loss: 5.3672\n",
            "Epoch 7/8, Batch 5250/15855, Loss: 5.2485\n",
            "Epoch 7/8, Batch 5300/15855, Loss: 6.5682\n",
            "Epoch 7/8, Batch 5350/15855, Loss: 4.8739\n",
            "Epoch 7/8, Batch 5400/15855, Loss: 5.2266\n",
            "Epoch 7/8, Batch 5450/15855, Loss: 5.0812\n",
            "Epoch 7/8, Batch 5500/15855, Loss: 4.5598\n",
            "Epoch 7/8, Batch 5550/15855, Loss: 4.9961\n",
            "Epoch 7/8, Batch 5600/15855, Loss: 4.7858\n",
            "Epoch 7/8, Batch 5650/15855, Loss: 5.0192\n",
            "Epoch 7/8, Batch 5700/15855, Loss: 5.4149\n",
            "Epoch 7/8, Batch 5750/15855, Loss: 5.0426\n",
            "Epoch 7/8, Batch 5800/15855, Loss: 4.3850\n",
            "Epoch 7/8, Batch 5850/15855, Loss: 4.4436\n",
            "Epoch 7/8, Batch 5900/15855, Loss: 4.4077\n",
            "Epoch 7/8, Batch 5950/15855, Loss: 5.8183\n",
            "Epoch 7/8, Batch 6000/15855, Loss: 4.2988\n",
            "Epoch 7/8, Batch 6050/15855, Loss: 4.6979\n",
            "Epoch 7/8, Batch 6100/15855, Loss: 5.0404\n",
            "Epoch 7/8, Batch 6150/15855, Loss: 4.8811\n",
            "Epoch 7/8, Batch 6200/15855, Loss: 4.9992\n",
            "Epoch 7/8, Batch 6250/15855, Loss: 4.8148\n",
            "Epoch 7/8, Batch 6300/15855, Loss: 4.5147\n",
            "Epoch 7/8, Batch 6350/15855, Loss: 4.6327\n",
            "Epoch 7/8, Batch 6400/15855, Loss: 5.6615\n",
            "Epoch 7/8, Batch 6450/15855, Loss: 4.9946\n",
            "Epoch 7/8, Batch 6500/15855, Loss: 5.7223\n",
            "Epoch 7/8, Batch 6550/15855, Loss: 4.4894\n",
            "Epoch 7/8, Batch 6600/15855, Loss: 4.9885\n",
            "Epoch 7/8, Batch 6650/15855, Loss: 5.5263\n",
            "Epoch 7/8, Batch 6700/15855, Loss: 5.4171\n",
            "Epoch 7/8, Batch 6750/15855, Loss: 5.2380\n",
            "Epoch 7/8, Batch 6800/15855, Loss: 4.9300\n",
            "Epoch 7/8, Batch 6850/15855, Loss: 6.1279\n",
            "Epoch 7/8, Batch 6900/15855, Loss: 5.5583\n",
            "Epoch 7/8, Batch 6950/15855, Loss: 5.8192\n",
            "Epoch 7/8, Batch 7000/15855, Loss: 5.4125\n",
            "Epoch 7/8, Batch 7050/15855, Loss: 5.0155\n",
            "Epoch 7/8, Batch 7100/15855, Loss: 5.0464\n",
            "Epoch 7/8, Batch 7150/15855, Loss: 4.8688\n",
            "Epoch 7/8, Batch 7200/15855, Loss: 5.0819\n",
            "Epoch 7/8, Batch 7250/15855, Loss: 5.5271\n",
            "Epoch 7/8, Batch 7300/15855, Loss: 4.9454\n",
            "Epoch 7/8, Batch 7350/15855, Loss: 4.7957\n",
            "Epoch 7/8, Batch 7400/15855, Loss: 5.6993\n",
            "Epoch 7/8, Batch 7450/15855, Loss: 5.4651\n",
            "Epoch 7/8, Batch 7500/15855, Loss: 5.4507\n",
            "Epoch 7/8, Batch 7550/15855, Loss: 4.7517\n",
            "Epoch 7/8, Batch 7600/15855, Loss: 5.4451\n",
            "Epoch 7/8, Batch 7650/15855, Loss: 5.7686\n",
            "Epoch 7/8, Batch 7700/15855, Loss: 4.9353\n",
            "Epoch 7/8, Batch 7750/15855, Loss: 5.3385\n",
            "Epoch 7/8, Batch 7800/15855, Loss: 5.2184\n",
            "Epoch 7/8, Batch 7850/15855, Loss: 4.7734\n",
            "Epoch 7/8, Batch 7900/15855, Loss: 5.3782\n",
            "Epoch 7/8, Batch 7950/15855, Loss: 4.7245\n",
            "Epoch 7/8, Batch 8000/15855, Loss: 4.9311\n",
            "Epoch 7/8, Batch 8050/15855, Loss: 5.8156\n",
            "Epoch 7/8, Batch 8100/15855, Loss: 5.2138\n",
            "Epoch 7/8, Batch 8150/15855, Loss: 5.4657\n",
            "Epoch 7/8, Batch 8200/15855, Loss: 4.9037\n",
            "Epoch 7/8, Batch 8250/15855, Loss: 5.6917\n",
            "Epoch 7/8, Batch 8300/15855, Loss: 5.0850\n",
            "Epoch 7/8, Batch 8350/15855, Loss: 5.5665\n",
            "Epoch 7/8, Batch 8400/15855, Loss: 5.0535\n",
            "Epoch 7/8, Batch 8450/15855, Loss: 5.0614\n",
            "Epoch 7/8, Batch 8500/15855, Loss: 5.1004\n",
            "Epoch 7/8, Batch 8550/15855, Loss: 5.5647\n",
            "Epoch 7/8, Batch 8600/15855, Loss: 5.4345\n",
            "Epoch 7/8, Batch 8650/15855, Loss: 5.2319\n",
            "Epoch 7/8, Batch 8700/15855, Loss: 4.8067\n",
            "Epoch 7/8, Batch 8750/15855, Loss: 4.9199\n",
            "Epoch 7/8, Batch 8800/15855, Loss: 5.1902\n",
            "Epoch 7/8, Batch 8850/15855, Loss: 4.9706\n",
            "Epoch 7/8, Batch 8900/15855, Loss: 4.8439\n",
            "Epoch 7/8, Batch 8950/15855, Loss: 4.8387\n",
            "Epoch 7/8, Batch 9000/15855, Loss: 5.1652\n",
            "Epoch 7/8, Batch 9050/15855, Loss: 4.4723\n",
            "Epoch 7/8, Batch 9100/15855, Loss: 5.6325\n",
            "Epoch 7/8, Batch 9150/15855, Loss: 5.5376\n",
            "Epoch 7/8, Batch 9200/15855, Loss: 4.5292\n",
            "Epoch 7/8, Batch 9250/15855, Loss: 5.4410\n",
            "Epoch 7/8, Batch 9300/15855, Loss: 4.7527\n",
            "Epoch 7/8, Batch 9350/15855, Loss: 5.5649\n",
            "Epoch 7/8, Batch 9400/15855, Loss: 5.2908\n",
            "Epoch 7/8, Batch 9450/15855, Loss: 4.7444\n",
            "Epoch 7/8, Batch 9500/15855, Loss: 4.7951\n",
            "Epoch 7/8, Batch 9550/15855, Loss: 5.1600\n",
            "Epoch 7/8, Batch 9600/15855, Loss: 4.8172\n",
            "Epoch 7/8, Batch 9650/15855, Loss: 5.0282\n",
            "Epoch 7/8, Batch 9700/15855, Loss: 5.2814\n",
            "Epoch 7/8, Batch 9750/15855, Loss: 5.5470\n",
            "Epoch 7/8, Batch 9800/15855, Loss: 5.2173\n",
            "Epoch 7/8, Batch 9850/15855, Loss: 5.5055\n",
            "Epoch 7/8, Batch 9900/15855, Loss: 4.3154\n",
            "Epoch 7/8, Batch 9950/15855, Loss: 4.5401\n",
            "Epoch 7/8, Batch 10000/15855, Loss: 5.4466\n",
            "Epoch 7/8, Batch 10050/15855, Loss: 5.7410\n",
            "Epoch 7/8, Batch 10100/15855, Loss: 4.5842\n",
            "Epoch 7/8, Batch 10150/15855, Loss: 3.9875\n",
            "Epoch 7/8, Batch 10200/15855, Loss: 5.1756\n",
            "Epoch 7/8, Batch 10250/15855, Loss: 5.6223\n",
            "Epoch 7/8, Batch 10300/15855, Loss: 5.3589\n",
            "Epoch 7/8, Batch 10350/15855, Loss: 4.8667\n",
            "Epoch 7/8, Batch 10400/15855, Loss: 4.8674\n",
            "Epoch 7/8, Batch 10450/15855, Loss: 4.5747\n",
            "Epoch 7/8, Batch 10500/15855, Loss: 5.3421\n",
            "Epoch 7/8, Batch 10550/15855, Loss: 4.9698\n",
            "Epoch 7/8, Batch 10600/15855, Loss: 4.2003\n",
            "Epoch 7/8, Batch 10650/15855, Loss: 5.1898\n",
            "Epoch 7/8, Batch 10700/15855, Loss: 5.0250\n",
            "Epoch 7/8, Batch 10750/15855, Loss: 5.3546\n",
            "Epoch 7/8, Batch 10800/15855, Loss: 5.2336\n",
            "Epoch 7/8, Batch 10850/15855, Loss: 5.6670\n",
            "Epoch 7/8, Batch 10900/15855, Loss: 5.5068\n",
            "Epoch 7/8, Batch 10950/15855, Loss: 5.5831\n",
            "Epoch 7/8, Batch 11000/15855, Loss: 4.7975\n",
            "Epoch 7/8, Batch 11050/15855, Loss: 4.8556\n",
            "Epoch 7/8, Batch 11100/15855, Loss: 4.8776\n",
            "Epoch 7/8, Batch 11150/15855, Loss: 4.5570\n",
            "Epoch 7/8, Batch 11200/15855, Loss: 4.9229\n",
            "Epoch 7/8, Batch 11250/15855, Loss: 5.3475\n",
            "Epoch 7/8, Batch 11300/15855, Loss: 4.8488\n",
            "Epoch 7/8, Batch 11350/15855, Loss: 5.0116\n",
            "Epoch 7/8, Batch 11400/15855, Loss: 4.8454\n",
            "Epoch 7/8, Batch 11450/15855, Loss: 5.1587\n",
            "Epoch 7/8, Batch 11500/15855, Loss: 4.7180\n",
            "Epoch 7/8, Batch 11550/15855, Loss: 4.7516\n",
            "Epoch 7/8, Batch 11600/15855, Loss: 4.8637\n",
            "Epoch 7/8, Batch 11650/15855, Loss: 5.4129\n",
            "Epoch 7/8, Batch 11700/15855, Loss: 4.8848\n",
            "Epoch 7/8, Batch 11750/15855, Loss: 4.7540\n",
            "Epoch 7/8, Batch 11800/15855, Loss: 5.3899\n",
            "Epoch 7/8, Batch 11850/15855, Loss: 5.0907\n",
            "Epoch 7/8, Batch 11900/15855, Loss: 4.9856\n",
            "Epoch 7/8, Batch 11950/15855, Loss: 4.9147\n",
            "Epoch 7/8, Batch 12000/15855, Loss: 4.9561\n",
            "Epoch 7/8, Batch 12050/15855, Loss: 4.9370\n",
            "Epoch 7/8, Batch 12100/15855, Loss: 5.2641\n",
            "Epoch 7/8, Batch 12150/15855, Loss: 5.1941\n",
            "Epoch 7/8, Batch 12200/15855, Loss: 5.7387\n",
            "Epoch 7/8, Batch 12250/15855, Loss: 4.7999\n",
            "Epoch 7/8, Batch 12300/15855, Loss: 5.2146\n",
            "Epoch 7/8, Batch 12350/15855, Loss: 4.8963\n",
            "Epoch 7/8, Batch 12400/15855, Loss: 4.6344\n",
            "Epoch 7/8, Batch 12450/15855, Loss: 5.1303\n",
            "Epoch 7/8, Batch 12500/15855, Loss: 5.7125\n",
            "Epoch 7/8, Batch 12550/15855, Loss: 4.4401\n",
            "Epoch 7/8, Batch 12600/15855, Loss: 5.3687\n",
            "Epoch 7/8, Batch 12650/15855, Loss: 4.9093\n",
            "Epoch 7/8, Batch 12700/15855, Loss: 4.7525\n",
            "Epoch 7/8, Batch 12750/15855, Loss: 4.9091\n",
            "Epoch 7/8, Batch 12800/15855, Loss: 5.3669\n",
            "Epoch 7/8, Batch 12850/15855, Loss: 5.4037\n",
            "Epoch 7/8, Batch 12900/15855, Loss: 4.7130\n",
            "Epoch 7/8, Batch 12950/15855, Loss: 5.3681\n",
            "Epoch 7/8, Batch 13000/15855, Loss: 4.9727\n",
            "Epoch 7/8, Batch 13050/15855, Loss: 4.2271\n",
            "Epoch 7/8, Batch 13100/15855, Loss: 5.5393\n",
            "Epoch 7/8, Batch 13150/15855, Loss: 5.2341\n",
            "Epoch 7/8, Batch 13200/15855, Loss: 5.3989\n",
            "Epoch 7/8, Batch 13250/15855, Loss: 5.2042\n",
            "Epoch 7/8, Batch 13300/15855, Loss: 5.1646\n",
            "Epoch 7/8, Batch 13350/15855, Loss: 4.5722\n",
            "Epoch 7/8, Batch 13400/15855, Loss: 5.0260\n",
            "Epoch 7/8, Batch 13450/15855, Loss: 5.2277\n",
            "Epoch 7/8, Batch 13500/15855, Loss: 5.3378\n",
            "Epoch 7/8, Batch 13550/15855, Loss: 5.5023\n",
            "Epoch 7/8, Batch 13600/15855, Loss: 4.7163\n",
            "Epoch 7/8, Batch 13650/15855, Loss: 4.8113\n",
            "Epoch 7/8, Batch 13700/15855, Loss: 5.2667\n",
            "Epoch 7/8, Batch 13750/15855, Loss: 4.9579\n",
            "Epoch 7/8, Batch 13800/15855, Loss: 5.0759\n",
            "Epoch 7/8, Batch 13850/15855, Loss: 4.9035\n",
            "Epoch 7/8, Batch 13900/15855, Loss: 4.7456\n",
            "Epoch 7/8, Batch 13950/15855, Loss: 4.6515\n",
            "Epoch 7/8, Batch 14000/15855, Loss: 5.3642\n",
            "Epoch 7/8, Batch 14050/15855, Loss: 4.4828\n",
            "Epoch 7/8, Batch 14100/15855, Loss: 4.8560\n",
            "Epoch 7/8, Batch 14150/15855, Loss: 5.3242\n",
            "Epoch 7/8, Batch 14200/15855, Loss: 4.7040\n",
            "Epoch 7/8, Batch 14250/15855, Loss: 4.6187\n",
            "Epoch 7/8, Batch 14300/15855, Loss: 4.8853\n",
            "Epoch 7/8, Batch 14350/15855, Loss: 5.9609\n",
            "Epoch 7/8, Batch 14400/15855, Loss: 5.8041\n",
            "Epoch 7/8, Batch 14450/15855, Loss: 5.6094\n",
            "Epoch 7/8, Batch 14500/15855, Loss: 5.3701\n",
            "Epoch 7/8, Batch 14550/15855, Loss: 4.6468\n",
            "Epoch 7/8, Batch 14600/15855, Loss: 5.1705\n",
            "Epoch 7/8, Batch 14650/15855, Loss: 6.0909\n",
            "Epoch 7/8, Batch 14700/15855, Loss: 5.5022\n",
            "Epoch 7/8, Batch 14750/15855, Loss: 4.8771\n",
            "Epoch 7/8, Batch 14800/15855, Loss: 5.0951\n",
            "Epoch 7/8, Batch 14850/15855, Loss: 5.1716\n",
            "Epoch 7/8, Batch 14900/15855, Loss: 4.0275\n",
            "Epoch 7/8, Batch 14950/15855, Loss: 5.0554\n",
            "Epoch 7/8, Batch 15000/15855, Loss: 5.1054\n",
            "Epoch 7/8, Batch 15050/15855, Loss: 5.0424\n",
            "Epoch 7/8, Batch 15100/15855, Loss: 4.4408\n",
            "Epoch 7/8, Batch 15150/15855, Loss: 5.1122\n",
            "Epoch 7/8, Batch 15200/15855, Loss: 4.7609\n",
            "Epoch 7/8, Batch 15250/15855, Loss: 4.6905\n",
            "Epoch 7/8, Batch 15300/15855, Loss: 5.1088\n",
            "Epoch 7/8, Batch 15350/15855, Loss: 5.0779\n",
            "Epoch 7/8, Batch 15400/15855, Loss: 4.8228\n",
            "Epoch 7/8, Batch 15450/15855, Loss: 4.8620\n",
            "Epoch 7/8, Batch 15500/15855, Loss: 5.1830\n",
            "Epoch 7/8, Batch 15550/15855, Loss: 4.5054\n",
            "Epoch 7/8, Batch 15600/15855, Loss: 5.4127\n",
            "Epoch 7/8, Batch 15650/15855, Loss: 5.5587\n",
            "Epoch 7/8, Batch 15700/15855, Loss: 5.1900\n",
            "Epoch 7/8, Batch 15750/15855, Loss: 4.8771\n",
            "Epoch 7/8, Batch 15800/15855, Loss: 5.0854\n",
            "Epoch 7/8, Batch 15850/15855, Loss: 4.6304\n",
            "Epoch 7/8 - Train Loss: 5.0672, Val Loss: 5.1009\n",
            "Epoch 8/8, Batch 0/15855, Loss: 5.5457\n",
            "Epoch 8/8, Batch 50/15855, Loss: 4.5658\n",
            "Epoch 8/8, Batch 100/15855, Loss: 5.1637\n",
            "Epoch 8/8, Batch 150/15855, Loss: 5.2191\n",
            "Epoch 8/8, Batch 200/15855, Loss: 4.9823\n",
            "Epoch 8/8, Batch 250/15855, Loss: 4.3605\n",
            "Epoch 8/8, Batch 300/15855, Loss: 5.2166\n",
            "Epoch 8/8, Batch 350/15855, Loss: 4.9753\n",
            "Epoch 8/8, Batch 400/15855, Loss: 5.2937\n",
            "Epoch 8/8, Batch 450/15855, Loss: 5.0541\n",
            "Epoch 8/8, Batch 500/15855, Loss: 4.9668\n",
            "Epoch 8/8, Batch 550/15855, Loss: 4.6288\n",
            "Epoch 8/8, Batch 600/15855, Loss: 4.6430\n",
            "Epoch 8/8, Batch 650/15855, Loss: 4.5168\n",
            "Epoch 8/8, Batch 700/15855, Loss: 5.1813\n",
            "Epoch 8/8, Batch 750/15855, Loss: 4.9583\n",
            "Epoch 8/8, Batch 800/15855, Loss: 5.6288\n",
            "Epoch 8/8, Batch 850/15855, Loss: 5.1265\n",
            "Epoch 8/8, Batch 900/15855, Loss: 4.7091\n",
            "Epoch 8/8, Batch 950/15855, Loss: 5.2149\n",
            "Epoch 8/8, Batch 1000/15855, Loss: 4.5962\n",
            "Epoch 8/8, Batch 1050/15855, Loss: 4.8019\n",
            "Epoch 8/8, Batch 1100/15855, Loss: 4.5405\n",
            "Epoch 8/8, Batch 1150/15855, Loss: 4.4427\n",
            "Epoch 8/8, Batch 1200/15855, Loss: 4.0052\n",
            "Epoch 8/8, Batch 1250/15855, Loss: 4.7886\n",
            "Epoch 8/8, Batch 1300/15855, Loss: 4.4866\n",
            "Epoch 8/8, Batch 1350/15855, Loss: 4.7684\n",
            "Epoch 8/8, Batch 1400/15855, Loss: 5.1560\n",
            "Epoch 8/8, Batch 1450/15855, Loss: 4.5819\n",
            "Epoch 8/8, Batch 1500/15855, Loss: 5.6301\n",
            "Epoch 8/8, Batch 1550/15855, Loss: 4.0430\n",
            "Epoch 8/8, Batch 1600/15855, Loss: 5.4284\n",
            "Epoch 8/8, Batch 1650/15855, Loss: 4.8716\n",
            "Epoch 8/8, Batch 1700/15855, Loss: 5.0884\n",
            "Epoch 8/8, Batch 1750/15855, Loss: 4.8221\n",
            "Epoch 8/8, Batch 1800/15855, Loss: 5.1595\n",
            "Epoch 8/8, Batch 1850/15855, Loss: 4.3966\n",
            "Epoch 8/8, Batch 1900/15855, Loss: 5.2967\n",
            "Epoch 8/8, Batch 1950/15855, Loss: 4.8722\n",
            "Epoch 8/8, Batch 2000/15855, Loss: 5.8274\n",
            "Epoch 8/8, Batch 2050/15855, Loss: 4.5360\n",
            "Epoch 8/8, Batch 2100/15855, Loss: 5.1215\n",
            "Epoch 8/8, Batch 2150/15855, Loss: 5.1567\n",
            "Epoch 8/8, Batch 2200/15855, Loss: 5.1226\n",
            "Epoch 8/8, Batch 2250/15855, Loss: 5.6065\n",
            "Epoch 8/8, Batch 2300/15855, Loss: 5.3349\n",
            "Epoch 8/8, Batch 2350/15855, Loss: 5.2120\n",
            "Epoch 8/8, Batch 2400/15855, Loss: 5.7372\n",
            "Epoch 8/8, Batch 2450/15855, Loss: 4.7246\n",
            "Epoch 8/8, Batch 2500/15855, Loss: 5.2452\n",
            "Epoch 8/8, Batch 2550/15855, Loss: 4.8211\n",
            "Epoch 8/8, Batch 2600/15855, Loss: 4.6087\n",
            "Epoch 8/8, Batch 2650/15855, Loss: 5.1656\n",
            "Epoch 8/8, Batch 2700/15855, Loss: 5.1913\n",
            "Epoch 8/8, Batch 2750/15855, Loss: 5.0365\n",
            "Epoch 8/8, Batch 2800/15855, Loss: 5.2786\n",
            "Epoch 8/8, Batch 2850/15855, Loss: 4.3656\n",
            "Epoch 8/8, Batch 2900/15855, Loss: 5.3166\n",
            "Epoch 8/8, Batch 2950/15855, Loss: 4.8429\n",
            "Epoch 8/8, Batch 3000/15855, Loss: 4.6262\n",
            "Epoch 8/8, Batch 3050/15855, Loss: 5.1097\n",
            "Epoch 8/8, Batch 3100/15855, Loss: 4.9431\n",
            "Epoch 8/8, Batch 3150/15855, Loss: 4.8076\n",
            "Epoch 8/8, Batch 3200/15855, Loss: 4.8563\n",
            "Epoch 8/8, Batch 3250/15855, Loss: 4.1913\n",
            "Epoch 8/8, Batch 3300/15855, Loss: 4.9549\n",
            "Epoch 8/8, Batch 3350/15855, Loss: 4.7738\n",
            "Epoch 8/8, Batch 3400/15855, Loss: 4.5109\n",
            "Epoch 8/8, Batch 3450/15855, Loss: 4.8608\n",
            "Epoch 8/8, Batch 3500/15855, Loss: 5.0899\n",
            "Epoch 8/8, Batch 3550/15855, Loss: 5.1972\n",
            "Epoch 8/8, Batch 3600/15855, Loss: 5.3215\n",
            "Epoch 8/8, Batch 3650/15855, Loss: 4.7871\n",
            "Epoch 8/8, Batch 3700/15855, Loss: 4.4388\n",
            "Epoch 8/8, Batch 3750/15855, Loss: 5.5192\n",
            "Epoch 8/8, Batch 3800/15855, Loss: 4.9446\n",
            "Epoch 8/8, Batch 3850/15855, Loss: 5.8422\n",
            "Epoch 8/8, Batch 3900/15855, Loss: 4.6502\n",
            "Epoch 8/8, Batch 3950/15855, Loss: 5.4354\n",
            "Epoch 8/8, Batch 4000/15855, Loss: 4.6747\n",
            "Epoch 8/8, Batch 4050/15855, Loss: 4.9155\n",
            "Epoch 8/8, Batch 4100/15855, Loss: 4.9233\n",
            "Epoch 8/8, Batch 4150/15855, Loss: 5.0699\n",
            "Epoch 8/8, Batch 4200/15855, Loss: 5.0065\n",
            "Epoch 8/8, Batch 4250/15855, Loss: 5.2010\n",
            "Epoch 8/8, Batch 4300/15855, Loss: 4.5741\n",
            "Epoch 8/8, Batch 4350/15855, Loss: 5.7460\n",
            "Epoch 8/8, Batch 4400/15855, Loss: 4.8530\n",
            "Epoch 8/8, Batch 4450/15855, Loss: 4.2386\n",
            "Epoch 8/8, Batch 4500/15855, Loss: 5.0600\n",
            "Epoch 8/8, Batch 4550/15855, Loss: 4.5844\n",
            "Epoch 8/8, Batch 4600/15855, Loss: 4.9479\n",
            "Epoch 8/8, Batch 4650/15855, Loss: 5.5035\n",
            "Epoch 8/8, Batch 4700/15855, Loss: 4.7626\n",
            "Epoch 8/8, Batch 4750/15855, Loss: 4.9797\n",
            "Epoch 8/8, Batch 4800/15855, Loss: 5.1216\n",
            "Epoch 8/8, Batch 4850/15855, Loss: 5.2225\n",
            "Epoch 8/8, Batch 4900/15855, Loss: 5.1661\n",
            "Epoch 8/8, Batch 4950/15855, Loss: 5.7200\n",
            "Epoch 8/8, Batch 5000/15855, Loss: 6.1901\n",
            "Epoch 8/8, Batch 5050/15855, Loss: 4.6468\n",
            "Epoch 8/8, Batch 5100/15855, Loss: 4.7702\n",
            "Epoch 8/8, Batch 5150/15855, Loss: 5.0740\n",
            "Epoch 8/8, Batch 5200/15855, Loss: 4.1875\n",
            "Epoch 8/8, Batch 5250/15855, Loss: 4.9106\n",
            "Epoch 8/8, Batch 5300/15855, Loss: 4.9136\n",
            "Epoch 8/8, Batch 5350/15855, Loss: 4.8632\n",
            "Epoch 8/8, Batch 5400/15855, Loss: 4.6503\n",
            "Epoch 8/8, Batch 5450/15855, Loss: 4.8341\n",
            "Epoch 8/8, Batch 5500/15855, Loss: 4.7895\n",
            "Epoch 8/8, Batch 5550/15855, Loss: 4.4040\n",
            "Epoch 8/8, Batch 5600/15855, Loss: 5.3113\n",
            "Epoch 8/8, Batch 5650/15855, Loss: 5.3170\n",
            "Epoch 8/8, Batch 5700/15855, Loss: 5.1328\n",
            "Epoch 8/8, Batch 5750/15855, Loss: 4.5505\n",
            "Epoch 8/8, Batch 5800/15855, Loss: 5.4767\n",
            "Epoch 8/8, Batch 5850/15855, Loss: 5.4994\n",
            "Epoch 8/8, Batch 5900/15855, Loss: 4.9461\n",
            "Epoch 8/8, Batch 5950/15855, Loss: 5.5480\n",
            "Epoch 8/8, Batch 6000/15855, Loss: 4.4365\n",
            "Epoch 8/8, Batch 6050/15855, Loss: 4.3534\n",
            "Epoch 8/8, Batch 6100/15855, Loss: 5.0120\n",
            "Epoch 8/8, Batch 6150/15855, Loss: 5.4322\n",
            "Epoch 8/8, Batch 6200/15855, Loss: 4.4450\n",
            "Epoch 8/8, Batch 6250/15855, Loss: 5.2320\n",
            "Epoch 8/8, Batch 6300/15855, Loss: 5.5948\n",
            "Epoch 8/8, Batch 6350/15855, Loss: 5.1611\n",
            "Epoch 8/8, Batch 6400/15855, Loss: 4.8865\n",
            "Epoch 8/8, Batch 6450/15855, Loss: 5.1958\n",
            "Epoch 8/8, Batch 6500/15855, Loss: 4.8810\n",
            "Epoch 8/8, Batch 6550/15855, Loss: 5.1061\n",
            "Epoch 8/8, Batch 6600/15855, Loss: 4.5820\n",
            "Epoch 8/8, Batch 6650/15855, Loss: 4.8012\n",
            "Epoch 8/8, Batch 6700/15855, Loss: 4.9329\n",
            "Epoch 8/8, Batch 6750/15855, Loss: 5.7557\n",
            "Epoch 8/8, Batch 6800/15855, Loss: 4.9743\n",
            "Epoch 8/8, Batch 6850/15855, Loss: 4.7354\n",
            "Epoch 8/8, Batch 6900/15855, Loss: 5.1433\n",
            "Epoch 8/8, Batch 6950/15855, Loss: 5.2151\n",
            "Epoch 8/8, Batch 7000/15855, Loss: 4.5386\n",
            "Epoch 8/8, Batch 7050/15855, Loss: 5.0581\n",
            "Epoch 8/8, Batch 7100/15855, Loss: 5.2297\n",
            "Epoch 8/8, Batch 7150/15855, Loss: 4.7902\n",
            "Epoch 8/8, Batch 7200/15855, Loss: 4.7458\n",
            "Epoch 8/8, Batch 7250/15855, Loss: 4.4744\n",
            "Epoch 8/8, Batch 7300/15855, Loss: 4.8648\n",
            "Epoch 8/8, Batch 7350/15855, Loss: 5.3290\n",
            "Epoch 8/8, Batch 7400/15855, Loss: 5.2829\n",
            "Epoch 8/8, Batch 7450/15855, Loss: 4.9930\n",
            "Epoch 8/8, Batch 7500/15855, Loss: 5.6163\n",
            "Epoch 8/8, Batch 7550/15855, Loss: 5.0362\n",
            "Epoch 8/8, Batch 7600/15855, Loss: 4.3221\n",
            "Epoch 8/8, Batch 7650/15855, Loss: 4.8425\n",
            "Epoch 8/8, Batch 7700/15855, Loss: 5.6489\n",
            "Epoch 8/8, Batch 7750/15855, Loss: 5.1748\n",
            "Epoch 8/8, Batch 7800/15855, Loss: 4.9402\n",
            "Epoch 8/8, Batch 7850/15855, Loss: 5.4193\n",
            "Epoch 8/8, Batch 7900/15855, Loss: 5.5281\n",
            "Epoch 8/8, Batch 7950/15855, Loss: 4.5714\n",
            "Epoch 8/8, Batch 8000/15855, Loss: 5.4133\n",
            "Epoch 8/8, Batch 8050/15855, Loss: 4.9344\n",
            "Epoch 8/8, Batch 8100/15855, Loss: 6.0205\n",
            "Epoch 8/8, Batch 8150/15855, Loss: 5.1645\n",
            "Epoch 8/8, Batch 8200/15855, Loss: 4.9335\n",
            "Epoch 8/8, Batch 8250/15855, Loss: 5.2557\n",
            "Epoch 8/8, Batch 8300/15855, Loss: 5.8204\n",
            "Epoch 8/8, Batch 8350/15855, Loss: 4.8147\n",
            "Epoch 8/8, Batch 8400/15855, Loss: 5.2682\n",
            "Epoch 8/8, Batch 8450/15855, Loss: 5.4463\n",
            "Epoch 8/8, Batch 8500/15855, Loss: 4.6915\n",
            "Epoch 8/8, Batch 8550/15855, Loss: 4.6042\n",
            "Epoch 8/8, Batch 8600/15855, Loss: 4.8956\n",
            "Epoch 8/8, Batch 8650/15855, Loss: 5.1701\n",
            "Epoch 8/8, Batch 8700/15855, Loss: 5.1712\n",
            "Epoch 8/8, Batch 8750/15855, Loss: 5.5928\n",
            "Epoch 8/8, Batch 8800/15855, Loss: 5.6075\n",
            "Epoch 8/8, Batch 8850/15855, Loss: 4.2221\n",
            "Epoch 8/8, Batch 8900/15855, Loss: 5.7341\n",
            "Epoch 8/8, Batch 8950/15855, Loss: 4.7552\n",
            "Epoch 8/8, Batch 9000/15855, Loss: 5.5475\n",
            "Epoch 8/8, Batch 9050/15855, Loss: 5.9119\n",
            "Epoch 8/8, Batch 9100/15855, Loss: 5.1428\n",
            "Epoch 8/8, Batch 9150/15855, Loss: 4.3901\n",
            "Epoch 8/8, Batch 9200/15855, Loss: 4.9838\n",
            "Epoch 8/8, Batch 9250/15855, Loss: 4.5166\n",
            "Epoch 8/8, Batch 9300/15855, Loss: 4.8721\n",
            "Epoch 8/8, Batch 9350/15855, Loss: 4.8659\n",
            "Epoch 8/8, Batch 9400/15855, Loss: 4.7129\n",
            "Epoch 8/8, Batch 9450/15855, Loss: 5.2480\n",
            "Epoch 8/8, Batch 9500/15855, Loss: 4.4724\n",
            "Epoch 8/8, Batch 9550/15855, Loss: 4.4286\n",
            "Epoch 8/8, Batch 9600/15855, Loss: 5.0933\n",
            "Epoch 8/8, Batch 9650/15855, Loss: 4.8317\n",
            "Epoch 8/8, Batch 9700/15855, Loss: 4.9855\n",
            "Epoch 8/8, Batch 9750/15855, Loss: 5.3107\n",
            "Epoch 8/8, Batch 9800/15855, Loss: 5.1300\n",
            "Epoch 8/8, Batch 9850/15855, Loss: 5.2542\n",
            "Epoch 8/8, Batch 9900/15855, Loss: 5.1349\n",
            "Epoch 8/8, Batch 9950/15855, Loss: 5.2683\n",
            "Epoch 8/8, Batch 10000/15855, Loss: 4.5382\n",
            "Epoch 8/8, Batch 10050/15855, Loss: 5.1247\n",
            "Epoch 8/8, Batch 10100/15855, Loss: 4.8512\n",
            "Epoch 8/8, Batch 10150/15855, Loss: 4.6640\n",
            "Epoch 8/8, Batch 10200/15855, Loss: 5.1076\n",
            "Epoch 8/8, Batch 10250/15855, Loss: 4.9371\n",
            "Epoch 8/8, Batch 10300/15855, Loss: 5.6460\n",
            "Epoch 8/8, Batch 10350/15855, Loss: 5.1833\n",
            "Epoch 8/8, Batch 10400/15855, Loss: 4.5446\n",
            "Epoch 8/8, Batch 10450/15855, Loss: 4.7576\n",
            "Epoch 8/8, Batch 10500/15855, Loss: 5.0583\n",
            "Epoch 8/8, Batch 10550/15855, Loss: 5.4133\n",
            "Epoch 8/8, Batch 10600/15855, Loss: 4.3113\n",
            "Epoch 8/8, Batch 10650/15855, Loss: 5.1231\n",
            "Epoch 8/8, Batch 10700/15855, Loss: 5.3099\n",
            "Epoch 8/8, Batch 10750/15855, Loss: 5.1530\n",
            "Epoch 8/8, Batch 10800/15855, Loss: 5.0929\n",
            "Epoch 8/8, Batch 10850/15855, Loss: 4.9104\n",
            "Epoch 8/8, Batch 10900/15855, Loss: 5.2508\n",
            "Epoch 8/8, Batch 10950/15855, Loss: 5.4182\n",
            "Epoch 8/8, Batch 11000/15855, Loss: 4.5938\n",
            "Epoch 8/8, Batch 11050/15855, Loss: 5.1280\n",
            "Epoch 8/8, Batch 11100/15855, Loss: 4.6120\n",
            "Epoch 8/8, Batch 11150/15855, Loss: 4.8349\n",
            "Epoch 8/8, Batch 11200/15855, Loss: 6.0177\n",
            "Epoch 8/8, Batch 11250/15855, Loss: 5.7271\n",
            "Epoch 8/8, Batch 11300/15855, Loss: 5.1369\n",
            "Epoch 8/8, Batch 11350/15855, Loss: 5.6693\n",
            "Epoch 8/8, Batch 11400/15855, Loss: 5.3265\n",
            "Epoch 8/8, Batch 11450/15855, Loss: 5.4071\n",
            "Epoch 8/8, Batch 11500/15855, Loss: 4.9608\n",
            "Epoch 8/8, Batch 11550/15855, Loss: 5.1298\n",
            "Epoch 8/8, Batch 11600/15855, Loss: 4.8815\n",
            "Epoch 8/8, Batch 11650/15855, Loss: 4.9384\n",
            "Epoch 8/8, Batch 11700/15855, Loss: 5.0178\n",
            "Epoch 8/8, Batch 11750/15855, Loss: 5.0947\n",
            "Epoch 8/8, Batch 11800/15855, Loss: 4.4896\n",
            "Epoch 8/8, Batch 11850/15855, Loss: 4.6832\n",
            "Epoch 8/8, Batch 11900/15855, Loss: 4.3095\n",
            "Epoch 8/8, Batch 11950/15855, Loss: 4.6981\n",
            "Epoch 8/8, Batch 12000/15855, Loss: 4.9729\n",
            "Epoch 8/8, Batch 12050/15855, Loss: 5.1546\n",
            "Epoch 8/8, Batch 12100/15855, Loss: 4.5443\n",
            "Epoch 8/8, Batch 12150/15855, Loss: 5.3680\n",
            "Epoch 8/8, Batch 12200/15855, Loss: 5.0313\n",
            "Epoch 8/8, Batch 12250/15855, Loss: 4.9644\n",
            "Epoch 8/8, Batch 12300/15855, Loss: 4.5714\n",
            "Epoch 8/8, Batch 12350/15855, Loss: 5.6236\n",
            "Epoch 8/8, Batch 12400/15855, Loss: 4.9159\n",
            "Epoch 8/8, Batch 12450/15855, Loss: 4.7457\n",
            "Epoch 8/8, Batch 12500/15855, Loss: 5.0666\n",
            "Epoch 8/8, Batch 12550/15855, Loss: 4.7846\n",
            "Epoch 8/8, Batch 12600/15855, Loss: 4.8104\n",
            "Epoch 8/8, Batch 12650/15855, Loss: 5.3345\n",
            "Epoch 8/8, Batch 12700/15855, Loss: 5.8385\n",
            "Epoch 8/8, Batch 12750/15855, Loss: 4.9299\n",
            "Epoch 8/8, Batch 12800/15855, Loss: 4.7338\n",
            "Epoch 8/8, Batch 12850/15855, Loss: 5.1991\n",
            "Epoch 8/8, Batch 12900/15855, Loss: 5.8260\n",
            "Epoch 8/8, Batch 12950/15855, Loss: 5.5444\n",
            "Epoch 8/8, Batch 13000/15855, Loss: 4.2978\n",
            "Epoch 8/8, Batch 13050/15855, Loss: 5.1805\n",
            "Epoch 8/8, Batch 13100/15855, Loss: 5.3248\n",
            "Epoch 8/8, Batch 13150/15855, Loss: 5.2470\n",
            "Epoch 8/8, Batch 13200/15855, Loss: 4.9038\n",
            "Epoch 8/8, Batch 13250/15855, Loss: 4.5626\n",
            "Epoch 8/8, Batch 13300/15855, Loss: 5.3705\n",
            "Epoch 8/8, Batch 13350/15855, Loss: 5.5004\n",
            "Epoch 8/8, Batch 13400/15855, Loss: 5.3308\n",
            "Epoch 8/8, Batch 13450/15855, Loss: 4.8837\n",
            "Epoch 8/8, Batch 13500/15855, Loss: 5.2455\n",
            "Epoch 8/8, Batch 13550/15855, Loss: 5.3205\n",
            "Epoch 8/8, Batch 13600/15855, Loss: 5.6038\n",
            "Epoch 8/8, Batch 13650/15855, Loss: 4.6229\n",
            "Epoch 8/8, Batch 13700/15855, Loss: 4.4761\n",
            "Epoch 8/8, Batch 13750/15855, Loss: 4.7344\n",
            "Epoch 8/8, Batch 13800/15855, Loss: 5.7488\n",
            "Epoch 8/8, Batch 13850/15855, Loss: 4.9590\n",
            "Epoch 8/8, Batch 13900/15855, Loss: 5.7449\n",
            "Epoch 8/8, Batch 13950/15855, Loss: 5.1175\n",
            "Epoch 8/8, Batch 14000/15855, Loss: 5.1393\n",
            "Epoch 8/8, Batch 14050/15855, Loss: 5.5266\n",
            "Epoch 8/8, Batch 14100/15855, Loss: 4.7952\n",
            "Epoch 8/8, Batch 14150/15855, Loss: 4.9297\n",
            "Epoch 8/8, Batch 14200/15855, Loss: 5.1283\n",
            "Epoch 8/8, Batch 14250/15855, Loss: 4.7695\n",
            "Epoch 8/8, Batch 14300/15855, Loss: 5.0129\n",
            "Epoch 8/8, Batch 14350/15855, Loss: 4.0274\n",
            "Epoch 8/8, Batch 14400/15855, Loss: 5.8150\n",
            "Epoch 8/8, Batch 14450/15855, Loss: 4.2013\n",
            "Epoch 8/8, Batch 14500/15855, Loss: 4.5820\n",
            "Epoch 8/8, Batch 14550/15855, Loss: 5.2457\n",
            "Epoch 8/8, Batch 14600/15855, Loss: 4.9190\n",
            "Epoch 8/8, Batch 14650/15855, Loss: 5.0700\n",
            "Epoch 8/8, Batch 14700/15855, Loss: 5.2152\n",
            "Epoch 8/8, Batch 14750/15855, Loss: 4.9776\n",
            "Epoch 8/8, Batch 14800/15855, Loss: 4.7839\n",
            "Epoch 8/8, Batch 14850/15855, Loss: 5.8330\n",
            "Epoch 8/8, Batch 14900/15855, Loss: 4.8144\n",
            "Epoch 8/8, Batch 14950/15855, Loss: 4.9217\n",
            "Epoch 8/8, Batch 15000/15855, Loss: 4.4701\n",
            "Epoch 8/8, Batch 15050/15855, Loss: 5.6868\n",
            "Epoch 8/8, Batch 15100/15855, Loss: 5.3219\n",
            "Epoch 8/8, Batch 15150/15855, Loss: 4.9366\n",
            "Epoch 8/8, Batch 15200/15855, Loss: 5.3437\n",
            "Epoch 8/8, Batch 15250/15855, Loss: 4.9671\n",
            "Epoch 8/8, Batch 15300/15855, Loss: 4.3116\n",
            "Epoch 8/8, Batch 15350/15855, Loss: 4.8019\n",
            "Epoch 8/8, Batch 15400/15855, Loss: 5.3838\n",
            "Epoch 8/8, Batch 15450/15855, Loss: 5.8592\n",
            "Epoch 8/8, Batch 15500/15855, Loss: 4.8465\n",
            "Epoch 8/8, Batch 15550/15855, Loss: 5.3177\n",
            "Epoch 8/8, Batch 15600/15855, Loss: 6.0161\n",
            "Epoch 8/8, Batch 15650/15855, Loss: 5.3566\n",
            "Epoch 8/8, Batch 15700/15855, Loss: 5.2661\n",
            "Epoch 8/8, Batch 15750/15855, Loss: 4.3404\n",
            "Epoch 8/8, Batch 15800/15855, Loss: 4.6656\n",
            "Epoch 8/8, Batch 15850/15855, Loss: 4.8450\n",
            "Epoch 8/8 - Train Loss: 5.0307, Val Loss: 5.0810\n",
            "Exemple g√©n√©r√©: \"harry hadn't left the match to use their master's team. . . . he had just told that he had\"\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def train_model(model, train_loader, val_loader, num_epochs=10, learning_rate=0.001):\n",
        "    \"\"\"Entra√Æne le mod√®le\"\"\"\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    \n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        \n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            output, _ = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_loss += loss.item()\n",
        "            \n",
        "            if batch_idx % 50 == 0:\n",
        "                print(f'Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}')\n",
        "        \n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data, target in val_loader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                output, _ = model(data)\n",
        "                val_loss += criterion(output, target).item()\n",
        "        \n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        \n",
        "        train_losses.append(avg_train_loss)\n",
        "        val_losses.append(avg_val_loss)\n",
        "        \n",
        "        print(f'Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
        "        \n",
        "        if (epoch + 1) % 2 == 0:\n",
        "            sample_text = generate_text(model, tokenizer, \"harry\", max_length=20, temperature=0.8)\n",
        "            print(f'Exemple g√©n√©r√©: \"{sample_text}\"\\n')\n",
        "    \n",
        "    return train_losses, val_losses\n",
        "\n",
        "print(\"D√©but de l'entra√Ænement...\")\n",
        "train_losses, val_losses = train_model(model, train_loader, val_loader, num_epochs=8, learning_rate=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('√âvolution des pertes pendant l\\'entra√Ænement')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Mod√®le sauvegard√© dans 'harry_potter_model.pth'\n"
          ]
        }
      ],
      "source": [
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'tokenizer': tokenizer,\n",
        "    'model_config': {\n",
        "        'vocab_size': tokenizer.vocab_size,\n",
        "        'embedding_dim': 128,\n",
        "        'hidden_dim': 256,\n",
        "        'num_layers': 2,\n",
        "        'dropout': 0.3\n",
        "    },\n",
        "    'sequence_length': SEQUENCE_LENGTH\n",
        "}, 'harry_potter_model.pth')\n",
        "\n",
        "print(\"‚úÖ Mod√®le sauvegard√© dans 'harry_potter_model.pth'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Lancement de l'interface Gradio...\n",
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def gradio_generate_text(start_word, max_length, temperature):\n",
        "    \"\"\"Fonction pour l'interface Gradio\"\"\"\n",
        "    try:\n",
        "        generated = generate_text(model, tokenizer, start_word, \n",
        "                                max_length=int(max_length), \n",
        "                                temperature=float(temperature))\n",
        "        return generated\n",
        "    except Exception as e:\n",
        "        return f\"Erreur: {str(e)}\"\n",
        "\n",
        "with gr.Blocks(title=\"ü™Ñ G√©n√©rateur Harry Potter\") as demo:\n",
        "    gr.HTML(\"\"\"\n",
        "    <h1 style=\"text-align: center;\">ü™Ñ G√©n√©rateur de Texte Harry Potter</h1>\n",
        "    <p style=\"text-align: center;\">Entrez un mot et le mod√®le g√©n√©rera une suite dans le style Harry Potter!</p>\n",
        "    \"\"\")\n",
        "    \n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            start_word_input = gr.Textbox(\n",
        "                label=\"Mot de d√©part\",\n",
        "                placeholder=\"Ex: harry, magic, wand, hogwarts...\",\n",
        "                value=\"harry\"\n",
        "            )\n",
        "            \n",
        "            max_length_slider = gr.Slider(\n",
        "                minimum=5,\n",
        "                maximum=100,\n",
        "                value=30,\n",
        "                step=5,\n",
        "                label=\"Longueur maximale\"\n",
        "            )\n",
        "            \n",
        "            temperature_slider = gr.Slider(\n",
        "                minimum=0.1,\n",
        "                maximum=2.0,\n",
        "                value=0.8,\n",
        "                step=0.1,\n",
        "                label=\"Cr√©ativit√© (temp√©rature)\"\n",
        "            )\n",
        "            \n",
        "            generate_btn = gr.Button(\"ü™Ñ G√©n√©rer du texte\", variant=\"primary\")\n",
        "        \n",
        "        with gr.Column():\n",
        "            output_text = gr.Textbox(\n",
        "                label=\"Texte g√©n√©r√©\",\n",
        "                lines=5,\n",
        "                interactive=False\n",
        "            )\n",
        "    \n",
        "    gr.Examples(\n",
        "        examples=[\n",
        "            [\"harry\", 25, 0.8],\n",
        "            [\"hermione\", 30, 0.7],\n",
        "            [\"magic\", 20, 1.0],\n",
        "            [\"wand\", 35, 0.6],\n",
        "            [\"hogwarts\", 40, 0.9]\n",
        "        ],\n",
        "        inputs=[start_word_input, max_length_slider, temperature_slider]\n",
        "    )\n",
        "    \n",
        "    generate_btn.click(\n",
        "        fn=gradio_generate_text,\n",
        "        inputs=[start_word_input, max_length_slider, temperature_slider],\n",
        "        outputs=output_text\n",
        "    )\n",
        "    \n",
        "    gr.HTML(\"\"\"\n",
        "    <div style=\"text-align: center; margin-top: 20px;\">\n",
        "        <p><em>üí° Conseil: Une temp√©rature basse (0.3-0.7) donne un texte plus coh√©rent, \n",
        "        une temp√©rature haute (0.8-1.5) donne un texte plus cr√©atif!</em></p>\n",
        "    </div>\n",
        "    \"\"\")\n",
        "\n",
        "print(\"üöÄ Lancement de l'interface Gradio...\")\n",
        "demo.launch(share=True, debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Top 10 mots pr√©dits apr√®s 'harry':\n",
            " 1. was             (7.3%)\n",
            " 2. had             (6.3%)\n",
            " 3. and             (3.5%)\n",
            " 4. <UNK>           (3.4%)\n",
            " 5. told            (3.3%)\n",
            " 6. got             (3.0%)\n",
            " 7. could           (2.8%)\n",
            " 8. saw             (2.6%)\n",
            " 9. knew            (2.3%)\n",
            "10. thought         (2.1%)\n",
            "\n",
            "üîç Top 10 mots pr√©dits apr√®s 'magic':\n",
            " 1. -               (7.6%)\n",
            " 2. <UNK>           (3.6%)\n",
            " 3. .               (3.1%)\n",
            " 4. is              (3.1%)\n",
            " 5. was             (2.7%)\n",
            " 6. can             (2.6%)\n",
            " 7. and             (2.4%)\n",
            " 8. has             (2.4%)\n",
            " 9. would           (1.7%)\n",
            "10. had             (1.4%)\n",
            "\n",
            "üîç Top 10 mots pr√©dits apr√®s 'wand':\n",
            " 1. <UNK>           (5.0%)\n",
            " 2. -               (4.3%)\n",
            " 3. was             (3.1%)\n",
            " 4. is              (2.0%)\n",
            " 5. had             (1.9%)\n",
            " 6. and             (1.7%)\n",
            " 7. .               (1.5%)\n",
            " 8. \"               (1.2%)\n",
            " 9. has             (1.2%)\n",
            "10. said            (1.0%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def analyze_model_predictions(model, tokenizer, word, top_k=10):\n",
        "    \"\"\"Analyse les pr√©dictions du mod√®le pour un mot donn√©\"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    if word.lower() not in tokenizer.word_to_idx:\n",
        "        print(f\"Le mot '{word}' n'est pas dans le vocabulaire.\")\n",
        "        return\n",
        "    \n",
        "    sequence = [tokenizer.word_to_idx['<PAD>']] * (SEQUENCE_LENGTH - 1) + [tokenizer.word_to_idx[word.lower()]]\n",
        "    input_seq = torch.tensor(sequence).unsqueeze(0).to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        output, _ = model(input_seq)\n",
        "        probabilities = torch.softmax(output, dim=1)\n",
        "        \n",
        "        top_probs, top_indices = torch.topk(probabilities, top_k)\n",
        "        \n",
        "        print(f\"üîç Top {top_k} mots pr√©dits apr√®s '{word}':\")\n",
        "        for i in range(top_k):\n",
        "            idx = top_indices[0][i].item()\n",
        "            prob = top_probs[0][i].item()\n",
        "            word_pred = tokenizer.idx_to_word[idx]\n",
        "            print(f\"{i+1:2d}. {word_pred:<15} ({prob:.1%})\")\n",
        "\n",
        "test_analysis_words = ['harry', 'magic', 'wand']\n",
        "for word in test_analysis_words:\n",
        "    analyze_model_predictions(model, tokenizer, word)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä STATISTIQUES DU MOD√àLE\n",
            "==================================================\n",
            "üìö Taille du vocabulaire: 20,098 mots\n",
            "üìñ Longueur du corpus: 1,127,457 tokens\n",
            "üî¢ S√©quences d'entra√Ænement: 1,127,427\n",
            "\n",
            "üß† Param√®tres totaux: 8,659,330\n",
            "üèãÔ∏è Param√®tres entra√Ænables: 8,659,330\n",
            "üíæ Taille estim√©e: 33.0 MB\n",
            "\n",
            "‚öôÔ∏è Configuration:\n",
            "   - Longueur de s√©quence: 30\n",
            "   - Taille de batch: 64\n",
            "   - Dimension embedding: 128\n",
            "   - Dimension cach√©e: 256\n",
            "   - Nombre de couches: 2\n",
            "\n",
            "üéØ Device utilis√©: cuda\n"
          ]
        }
      ],
      "source": [
        "def model_statistics():\n",
        "    \"\"\"Affiche des statistiques sur le mod√®le et les donn√©es\"\"\"\n",
        "    print(\"üìä STATISTIQUES DU MOD√àLE\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    print(f\"üìö Taille du vocabulaire: {tokenizer.vocab_size:,} mots\")\n",
        "    print(f\"üìñ Longueur du corpus: {len(encoded_text):,} tokens\")\n",
        "    print(f\"üî¢ S√©quences d'entra√Ænement: {len(dataset):,}\")\n",
        "    \n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "    print(f\"\\nüß† Param√®tres totaux: {total_params:,}\")\n",
        "    print(f\"üèãÔ∏è Param√®tres entra√Ænables: {trainable_params:,}\")\n",
        "    \n",
        "    model_size_mb = total_params * 4 / (1024 * 1024)\n",
        "    print(f\"üíæ Taille estim√©e: {model_size_mb:.1f} MB\")\n",
        "    \n",
        "    print(f\"\\n‚öôÔ∏è Configuration:\")\n",
        "    print(f\"   - Longueur de s√©quence: {SEQUENCE_LENGTH}\")\n",
        "    print(f\"   - Taille de batch: {BATCH_SIZE}\")\n",
        "    print(f\"   - Dimension embedding: 128\")\n",
        "    print(f\"   - Dimension cach√©e: 256\")\n",
        "    print(f\"   - Nombre de couches: 2\")\n",
        "    \n",
        "    print(f\"\\nüéØ Device utilis√©: {device}\")\n",
        "\n",
        "model_statistics()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
